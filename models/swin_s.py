import torch
from torch import tensor
import torch.nn as nn
from torch.nn import *
import torchvision
import torchvision.models as models
from torchvision.ops.stochastic_depth import stochastic_depth
import time
import builtins
import operator

class M(torch.nn.Module):
    def __init__(self):
        super(M, self).__init__()
        self.conv2d0 = Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        self.layernorm0 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.layernorm1 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.layernorm2 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.linear0 = Linear(in_features=96, out_features=384, bias=True)
        self.gelu0 = GELU(approximate='none')
        self.dropout0 = Dropout(p=0.0, inplace=False)
        self.linear1 = Linear(in_features=384, out_features=96, bias=True)
        self.dropout1 = Dropout(p=0.0, inplace=False)
        self.layernorm3 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.layernorm4 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.linear2 = Linear(in_features=96, out_features=384, bias=True)
        self.gelu1 = GELU(approximate='none')
        self.dropout2 = Dropout(p=0.0, inplace=False)
        self.linear3 = Linear(in_features=384, out_features=96, bias=True)
        self.dropout3 = Dropout(p=0.0, inplace=False)
        self.layernorm5 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear4 = Linear(in_features=384, out_features=192, bias=False)
        self.layernorm6 = LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        self.layernorm7 = LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        self.linear5 = Linear(in_features=192, out_features=768, bias=True)
        self.gelu2 = GELU(approximate='none')
        self.dropout4 = Dropout(p=0.0, inplace=False)
        self.linear6 = Linear(in_features=768, out_features=192, bias=True)
        self.dropout5 = Dropout(p=0.0, inplace=False)
        self.layernorm8 = LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        self.layernorm9 = LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        self.linear7 = Linear(in_features=192, out_features=768, bias=True)
        self.gelu3 = GELU(approximate='none')
        self.dropout6 = Dropout(p=0.0, inplace=False)
        self.linear8 = Linear(in_features=768, out_features=192, bias=True)
        self.dropout7 = Dropout(p=0.0, inplace=False)
        self.layernorm10 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.linear9 = Linear(in_features=768, out_features=384, bias=False)
        self.layernorm11 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm12 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear10 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu4 = GELU(approximate='none')
        self.dropout8 = Dropout(p=0.0, inplace=False)
        self.linear11 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout9 = Dropout(p=0.0, inplace=False)
        self.layernorm13 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm14 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear12 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu5 = GELU(approximate='none')
        self.dropout10 = Dropout(p=0.0, inplace=False)
        self.linear13 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout11 = Dropout(p=0.0, inplace=False)
        self.layernorm15 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm16 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear14 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu6 = GELU(approximate='none')
        self.dropout12 = Dropout(p=0.0, inplace=False)
        self.linear15 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout13 = Dropout(p=0.0, inplace=False)
        self.layernorm17 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm18 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear16 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu7 = GELU(approximate='none')
        self.dropout14 = Dropout(p=0.0, inplace=False)
        self.linear17 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout15 = Dropout(p=0.0, inplace=False)
        self.layernorm19 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm20 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear18 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu8 = GELU(approximate='none')
        self.dropout16 = Dropout(p=0.0, inplace=False)
        self.linear19 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout17 = Dropout(p=0.0, inplace=False)
        self.layernorm21 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm22 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear20 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu9 = GELU(approximate='none')
        self.dropout18 = Dropout(p=0.0, inplace=False)
        self.linear21 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout19 = Dropout(p=0.0, inplace=False)
        self.layernorm23 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm24 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear22 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu10 = GELU(approximate='none')
        self.dropout20 = Dropout(p=0.0, inplace=False)
        self.linear23 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout21 = Dropout(p=0.0, inplace=False)
        self.layernorm25 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm26 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear24 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu11 = GELU(approximate='none')
        self.dropout22 = Dropout(p=0.0, inplace=False)
        self.linear25 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout23 = Dropout(p=0.0, inplace=False)
        self.layernorm27 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm28 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear26 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu12 = GELU(approximate='none')
        self.dropout24 = Dropout(p=0.0, inplace=False)
        self.linear27 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout25 = Dropout(p=0.0, inplace=False)
        self.layernorm29 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm30 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear28 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu13 = GELU(approximate='none')
        self.dropout26 = Dropout(p=0.0, inplace=False)
        self.linear29 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout27 = Dropout(p=0.0, inplace=False)
        self.layernorm31 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm32 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear30 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu14 = GELU(approximate='none')
        self.dropout28 = Dropout(p=0.0, inplace=False)
        self.linear31 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout29 = Dropout(p=0.0, inplace=False)
        self.layernorm33 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm34 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear32 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu15 = GELU(approximate='none')
        self.dropout30 = Dropout(p=0.0, inplace=False)
        self.linear33 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout31 = Dropout(p=0.0, inplace=False)
        self.layernorm35 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm36 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear34 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu16 = GELU(approximate='none')
        self.dropout32 = Dropout(p=0.0, inplace=False)
        self.linear35 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout33 = Dropout(p=0.0, inplace=False)
        self.layernorm37 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm38 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear36 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu17 = GELU(approximate='none')
        self.dropout34 = Dropout(p=0.0, inplace=False)
        self.linear37 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout35 = Dropout(p=0.0, inplace=False)
        self.layernorm39 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm40 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear38 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu18 = GELU(approximate='none')
        self.dropout36 = Dropout(p=0.0, inplace=False)
        self.linear39 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout37 = Dropout(p=0.0, inplace=False)
        self.layernorm41 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm42 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear40 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu19 = GELU(approximate='none')
        self.dropout38 = Dropout(p=0.0, inplace=False)
        self.linear41 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout39 = Dropout(p=0.0, inplace=False)
        self.layernorm43 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm44 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear42 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu20 = GELU(approximate='none')
        self.dropout40 = Dropout(p=0.0, inplace=False)
        self.linear43 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout41 = Dropout(p=0.0, inplace=False)
        self.layernorm45 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm46 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear44 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu21 = GELU(approximate='none')
        self.dropout42 = Dropout(p=0.0, inplace=False)
        self.linear45 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout43 = Dropout(p=0.0, inplace=False)
        self.layernorm47 = LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        self.linear46 = Linear(in_features=1536, out_features=768, bias=False)
        self.layernorm48 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.layernorm49 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.linear47 = Linear(in_features=768, out_features=3072, bias=True)
        self.gelu22 = GELU(approximate='none')
        self.dropout44 = Dropout(p=0.0, inplace=False)
        self.linear48 = Linear(in_features=3072, out_features=768, bias=True)
        self.dropout45 = Dropout(p=0.0, inplace=False)
        self.layernorm50 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.layernorm51 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.linear49 = Linear(in_features=768, out_features=3072, bias=True)
        self.gelu23 = GELU(approximate='none')
        self.dropout46 = Dropout(p=0.0, inplace=False)
        self.linear50 = Linear(in_features=3072, out_features=768, bias=True)
        self.dropout47 = Dropout(p=0.0, inplace=False)
        self.layernorm52 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.adaptiveavgpool2d0 = AdaptiveAvgPool2d(output_size=1)
        self.linear51 = Linear(in_features=768, out_features=1000, bias=True)
        self.relative_position_bias_table0 = torch.rand(torch.Size([169, 3])).to(torch.float32)
        self.relative_position_index0 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight0 = torch.rand(torch.Size([288, 96])).to(torch.float32)
        self.weight1 = torch.rand(torch.Size([96, 96])).to(torch.float32)
        self.bias0 = torch.rand(torch.Size([288])).to(torch.float32)
        self.bias1 = torch.rand(torch.Size([96])).to(torch.float32)
        self.relative_position_bias_table1 = torch.rand(torch.Size([169, 3])).to(torch.float32)
        self.relative_position_index1 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight2 = torch.rand(torch.Size([288, 96])).to(torch.float32)
        self.weight3 = torch.rand(torch.Size([96, 96])).to(torch.float32)
        self.bias2 = torch.rand(torch.Size([288])).to(torch.float32)
        self.bias3 = torch.rand(torch.Size([96])).to(torch.float32)
        self.relative_position_bias_table2 = torch.rand(torch.Size([169, 6])).to(torch.float32)
        self.relative_position_index2 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight4 = torch.rand(torch.Size([576, 192])).to(torch.float32)
        self.weight5 = torch.rand(torch.Size([192, 192])).to(torch.float32)
        self.bias4 = torch.rand(torch.Size([576])).to(torch.float32)
        self.bias5 = torch.rand(torch.Size([192])).to(torch.float32)
        self.relative_position_bias_table3 = torch.rand(torch.Size([169, 6])).to(torch.float32)
        self.relative_position_index3 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight6 = torch.rand(torch.Size([576, 192])).to(torch.float32)
        self.weight7 = torch.rand(torch.Size([192, 192])).to(torch.float32)
        self.bias6 = torch.rand(torch.Size([576])).to(torch.float32)
        self.bias7 = torch.rand(torch.Size([192])).to(torch.float32)
        self.relative_position_bias_table4 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index4 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight8 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight9 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias8 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias9 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table5 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index5 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight10 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight11 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias10 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias11 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table6 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index6 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight12 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight13 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias12 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias13 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table7 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index7 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight14 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight15 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias14 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias15 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table8 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index8 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight16 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight17 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias16 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias17 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table9 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index9 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight18 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight19 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias18 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias19 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table10 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index10 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight20 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight21 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias20 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias21 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table11 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index11 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight22 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight23 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias22 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias23 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table12 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index12 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight24 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight25 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias24 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias25 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table13 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index13 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight26 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight27 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias26 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias27 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table14 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index14 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight28 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight29 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias28 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias29 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table15 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index15 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight30 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight31 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias30 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias31 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table16 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index16 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight32 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight33 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias32 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias33 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table17 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index17 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight34 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight35 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias34 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias35 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table18 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index18 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight36 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight37 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias36 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias37 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table19 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index19 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight38 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight39 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias38 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias39 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table20 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index20 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight40 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight41 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias40 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias41 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table21 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index21 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight42 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight43 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias42 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias43 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table22 = torch.rand(torch.Size([169, 24])).to(torch.float32)
        self.relative_position_index22 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight44 = torch.rand(torch.Size([2304, 768])).to(torch.float32)
        self.weight45 = torch.rand(torch.Size([768, 768])).to(torch.float32)
        self.bias44 = torch.rand(torch.Size([2304])).to(torch.float32)
        self.bias45 = torch.rand(torch.Size([768])).to(torch.float32)
        self.relative_position_bias_table23 = torch.rand(torch.Size([169, 24])).to(torch.float32)
        self.relative_position_index23 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight46 = torch.rand(torch.Size([2304, 768])).to(torch.float32)
        self.weight47 = torch.rand(torch.Size([768, 768])).to(torch.float32)
        self.bias46 = torch.rand(torch.Size([2304])).to(torch.float32)
        self.bias47 = torch.rand(torch.Size([768])).to(torch.float32)

    def forward(self, x):
        x0=x
        x1=self.conv2d0(x0)
        x2=torch.permute(x1, [0, 2, 3, 1])
        x3=self.layernorm0(x2)
        x4=self.layernorm1(x3)
        x7=operator.getitem(self.relative_position_bias_table0, self.relative_position_index0)
        x8=x7.view(49, 49, -1)
        x9=x8.permute(2, 0, 1)
        x10=x9.contiguous()
        x11=x10.unsqueeze(0)
        x16=torchvision.models.swin_transformer.shifted_window_attention(x4, self.weight0, self.weight1, x11, [7, 7], 3,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias0, proj_bias=self.bias1)
        x17=stochastic_depth(x16, 0.0, 'row', False)
        x18=operator.add(x3, x17)
        x19=self.layernorm2(x18)
        x20=self.linear0(x19)
        x21=self.gelu0(x20)
        x22=self.dropout0(x21)
        x23=self.linear1(x22)
        x24=self.dropout1(x23)
        x25=stochastic_depth(x24, 0.0, 'row', False)
        x26=operator.add(x18, x25)
        x27=self.layernorm3(x26)
        x30=operator.getitem(self.relative_position_bias_table1, self.relative_position_index1)
        x31=x30.view(49, 49, -1)
        x32=x31.permute(2, 0, 1)
        x33=x32.contiguous()
        x34=x33.unsqueeze(0)
        x39=torchvision.models.swin_transformer.shifted_window_attention(x27, self.weight2, self.weight3, x34, [7, 7], 3,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias2, proj_bias=self.bias3)
        x40=stochastic_depth(x39, 0.013043478260869565, 'row', False)
        x41=operator.add(x26, x40)
        x42=self.layernorm4(x41)
        x43=self.linear2(x42)
        x44=self.gelu1(x43)
        x45=self.dropout2(x44)
        x46=self.linear3(x45)
        x47=self.dropout3(x46)
        x48=stochastic_depth(x47, 0.013043478260869565, 'row', False)
        x49=operator.add(x41, x48)
        x50=builtins.getattr(x49, 'shape')
        x51=operator.getitem(x50, slice(-3, None, None))
        x52=operator.getitem(x51, 0)
        x53=operator.getitem(x51, 1)
        x54=operator.getitem(x51, 2)
        x55=operator.mod(x53, 2)
        x56=operator.mod(x52, 2)
        x57=torch.nn.functional.pad(x49, (0, 0, 0, x55, 0, x56))
        x58=operator.getitem(x57, (Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None, None, None)))
        x59=operator.getitem(x57, (Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None, None, None)))
        x60=operator.getitem(x57, (Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None, None, None)))
        x61=operator.getitem(x57, (Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None, None, None)))
        x62=torch.cat([x58, x59, x60, x61], -1)
        x63=self.layernorm5(x62)
        x64=self.linear4(x63)
        x65=self.layernorm6(x64)
        x68=operator.getitem(self.relative_position_bias_table2, self.relative_position_index2)
        x69=x68.view(49, 49, -1)
        x70=x69.permute(2, 0, 1)
        x71=x70.contiguous()
        x72=x71.unsqueeze(0)
        x77=torchvision.models.swin_transformer.shifted_window_attention(x65, self.weight4, self.weight5, x72, [7, 7], 6,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias4, proj_bias=self.bias5)
        x78=stochastic_depth(x77, 0.02608695652173913, 'row', False)
        x79=operator.add(x64, x78)
        x80=self.layernorm7(x79)
        x81=self.linear5(x80)
        x82=self.gelu2(x81)
        x83=self.dropout4(x82)
        x84=self.linear6(x83)
        x85=self.dropout5(x84)
        x86=stochastic_depth(x85, 0.02608695652173913, 'row', False)
        x87=operator.add(x79, x86)
        x88=self.layernorm8(x87)
        x91=operator.getitem(self.relative_position_bias_table3, self.relative_position_index3)
        x92=x91.view(49, 49, -1)
        x93=x92.permute(2, 0, 1)
        x94=x93.contiguous()
        x95=x94.unsqueeze(0)
        x100=torchvision.models.swin_transformer.shifted_window_attention(x88, self.weight6, self.weight7, x95, [7, 7], 6,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias6, proj_bias=self.bias7)
        x101=stochastic_depth(x100, 0.03913043478260869, 'row', False)
        x102=operator.add(x87, x101)
        x103=self.layernorm9(x102)
        x104=self.linear7(x103)
        x105=self.gelu3(x104)
        x106=self.dropout6(x105)
        x107=self.linear8(x106)
        x108=self.dropout7(x107)
        x109=stochastic_depth(x108, 0.03913043478260869, 'row', False)
        x110=operator.add(x102, x109)
        x111=builtins.getattr(x110, 'shape')
        x112=operator.getitem(x111, slice(-3, None, None))
        x113=operator.getitem(x112, 0)
        x114=operator.getitem(x112, 1)
        x115=operator.getitem(x112, 2)
        x116=operator.mod(x114, 2)
        x117=operator.mod(x113, 2)
        x118=torch.nn.functional.pad(x110, (0, 0, 0, x116, 0, x117))
        x119=operator.getitem(x118, (Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None, None, None)))
        x120=operator.getitem(x118, (Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None, None, None)))
        x121=operator.getitem(x118, (Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None, None, None)))
        x122=operator.getitem(x118, (Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None, None, None)))
        x123=torch.cat([x119, x120, x121, x122], -1)
        x124=self.layernorm10(x123)
        x125=self.linear9(x124)
        x126=self.layernorm11(x125)
        x129=operator.getitem(self.relative_position_bias_table4, self.relative_position_index4)
        x130=x129.view(49, 49, -1)
        x131=x130.permute(2, 0, 1)
        x132=x131.contiguous()
        x133=x132.unsqueeze(0)
        x138=torchvision.models.swin_transformer.shifted_window_attention(x126, self.weight8, self.weight9, x133, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias8, proj_bias=self.bias9)
        x139=stochastic_depth(x138, 0.05217391304347826, 'row', False)
        x140=operator.add(x125, x139)
        x141=self.layernorm12(x140)
        x142=self.linear10(x141)
        x143=self.gelu4(x142)
        x144=self.dropout8(x143)
        x145=self.linear11(x144)
        x146=self.dropout9(x145)
        x147=stochastic_depth(x146, 0.05217391304347826, 'row', False)
        x148=operator.add(x140, x147)
        x149=self.layernorm13(x148)
        x152=operator.getitem(self.relative_position_bias_table5, self.relative_position_index5)
        x153=x152.view(49, 49, -1)
        x154=x153.permute(2, 0, 1)
        x155=x154.contiguous()
        x156=x155.unsqueeze(0)
        x161=torchvision.models.swin_transformer.shifted_window_attention(x149, self.weight10, self.weight11, x156, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias10, proj_bias=self.bias11)
        x162=stochastic_depth(x161, 0.06521739130434782, 'row', False)
        x163=operator.add(x148, x162)
        x164=self.layernorm14(x163)
        x165=self.linear12(x164)
        x166=self.gelu5(x165)
        x167=self.dropout10(x166)
        x168=self.linear13(x167)
        x169=self.dropout11(x168)
        x170=stochastic_depth(x169, 0.06521739130434782, 'row', False)
        x171=operator.add(x163, x170)
        x172=self.layernorm15(x171)
        x175=operator.getitem(self.relative_position_bias_table6, self.relative_position_index6)
        x176=x175.view(49, 49, -1)
        x177=x176.permute(2, 0, 1)
        x178=x177.contiguous()
        x179=x178.unsqueeze(0)
        x184=torchvision.models.swin_transformer.shifted_window_attention(x172, self.weight12, self.weight13, x179, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias12, proj_bias=self.bias13)
        x185=stochastic_depth(x184, 0.07826086956521738, 'row', False)
        x186=operator.add(x171, x185)
        x187=self.layernorm16(x186)
        x188=self.linear14(x187)
        x189=self.gelu6(x188)
        x190=self.dropout12(x189)
        x191=self.linear15(x190)
        x192=self.dropout13(x191)
        x193=stochastic_depth(x192, 0.07826086956521738, 'row', False)
        x194=operator.add(x186, x193)
        x195=self.layernorm17(x194)
        x198=operator.getitem(self.relative_position_bias_table7, self.relative_position_index7)
        x199=x198.view(49, 49, -1)
        x200=x199.permute(2, 0, 1)
        x201=x200.contiguous()
        x202=x201.unsqueeze(0)
        x207=torchvision.models.swin_transformer.shifted_window_attention(x195, self.weight14, self.weight15, x202, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias14, proj_bias=self.bias15)
        x208=stochastic_depth(x207, 0.09130434782608696, 'row', False)
        x209=operator.add(x194, x208)
        x210=self.layernorm18(x209)
        x211=self.linear16(x210)
        x212=self.gelu7(x211)
        x213=self.dropout14(x212)
        x214=self.linear17(x213)
        x215=self.dropout15(x214)
        x216=stochastic_depth(x215, 0.09130434782608696, 'row', False)
        x217=operator.add(x209, x216)
        x218=self.layernorm19(x217)
        x221=operator.getitem(self.relative_position_bias_table8, self.relative_position_index8)
        x222=x221.view(49, 49, -1)
        x223=x222.permute(2, 0, 1)
        x224=x223.contiguous()
        x225=x224.unsqueeze(0)
        x230=torchvision.models.swin_transformer.shifted_window_attention(x218, self.weight16, self.weight17, x225, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias16, proj_bias=self.bias17)
        x231=stochastic_depth(x230, 0.10434782608695652, 'row', False)
        x232=operator.add(x217, x231)
        x233=self.layernorm20(x232)
        x234=self.linear18(x233)
        x235=self.gelu8(x234)
        x236=self.dropout16(x235)
        x237=self.linear19(x236)
        x238=self.dropout17(x237)
        x239=stochastic_depth(x238, 0.10434782608695652, 'row', False)
        x240=operator.add(x232, x239)
        x241=self.layernorm21(x240)
        x244=operator.getitem(self.relative_position_bias_table9, self.relative_position_index9)
        x245=x244.view(49, 49, -1)
        x246=x245.permute(2, 0, 1)
        x247=x246.contiguous()
        x248=x247.unsqueeze(0)
        x253=torchvision.models.swin_transformer.shifted_window_attention(x241, self.weight18, self.weight19, x248, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias18, proj_bias=self.bias19)
        x254=stochastic_depth(x253, 0.11739130434782608, 'row', False)
        x255=operator.add(x240, x254)
        x256=self.layernorm22(x255)
        x257=self.linear20(x256)
        x258=self.gelu9(x257)
        x259=self.dropout18(x258)
        x260=self.linear21(x259)
        x261=self.dropout19(x260)
        x262=stochastic_depth(x261, 0.11739130434782608, 'row', False)
        x263=operator.add(x255, x262)
        x264=self.layernorm23(x263)
        x267=operator.getitem(self.relative_position_bias_table10, self.relative_position_index10)
        x268=x267.view(49, 49, -1)
        x269=x268.permute(2, 0, 1)
        x270=x269.contiguous()
        x271=x270.unsqueeze(0)
        x276=torchvision.models.swin_transformer.shifted_window_attention(x264, self.weight20, self.weight21, x271, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias20, proj_bias=self.bias21)
        x277=stochastic_depth(x276, 0.13043478260869565, 'row', False)
        x278=operator.add(x263, x277)
        x279=self.layernorm24(x278)
        x280=self.linear22(x279)
        x281=self.gelu10(x280)
        x282=self.dropout20(x281)
        x283=self.linear23(x282)
        x284=self.dropout21(x283)
        x285=stochastic_depth(x284, 0.13043478260869565, 'row', False)
        x286=operator.add(x278, x285)
        x287=self.layernorm25(x286)
        x290=operator.getitem(self.relative_position_bias_table11, self.relative_position_index11)
        x291=x290.view(49, 49, -1)
        x292=x291.permute(2, 0, 1)
        x293=x292.contiguous()
        x294=x293.unsqueeze(0)
        x299=torchvision.models.swin_transformer.shifted_window_attention(x287, self.weight22, self.weight23, x294, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias22, proj_bias=self.bias23)
        x300=stochastic_depth(x299, 0.14347826086956522, 'row', False)
        x301=operator.add(x286, x300)
        x302=self.layernorm26(x301)
        x303=self.linear24(x302)
        x304=self.gelu11(x303)
        x305=self.dropout22(x304)
        x306=self.linear25(x305)
        x307=self.dropout23(x306)
        x308=stochastic_depth(x307, 0.14347826086956522, 'row', False)
        x309=operator.add(x301, x308)
        x310=self.layernorm27(x309)
        x313=operator.getitem(self.relative_position_bias_table12, self.relative_position_index12)
        x314=x313.view(49, 49, -1)
        x315=x314.permute(2, 0, 1)
        x316=x315.contiguous()
        x317=x316.unsqueeze(0)
        x322=torchvision.models.swin_transformer.shifted_window_attention(x310, self.weight24, self.weight25, x317, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias24, proj_bias=self.bias25)
        x323=stochastic_depth(x322, 0.15652173913043477, 'row', False)
        x324=operator.add(x309, x323)
        x325=self.layernorm28(x324)
        x326=self.linear26(x325)
        x327=self.gelu12(x326)
        x328=self.dropout24(x327)
        x329=self.linear27(x328)
        x330=self.dropout25(x329)
        x331=stochastic_depth(x330, 0.15652173913043477, 'row', False)
        x332=operator.add(x324, x331)
        x333=self.layernorm29(x332)
        x336=operator.getitem(self.relative_position_bias_table13, self.relative_position_index13)
        x337=x336.view(49, 49, -1)
        x338=x337.permute(2, 0, 1)
        x339=x338.contiguous()
        x340=x339.unsqueeze(0)
        x345=torchvision.models.swin_transformer.shifted_window_attention(x333, self.weight26, self.weight27, x340, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias26, proj_bias=self.bias27)
        x346=stochastic_depth(x345, 0.16956521739130434, 'row', False)
        x347=operator.add(x332, x346)
        x348=self.layernorm30(x347)
        x349=self.linear28(x348)
        x350=self.gelu13(x349)
        x351=self.dropout26(x350)
        x352=self.linear29(x351)
        x353=self.dropout27(x352)
        x354=stochastic_depth(x353, 0.16956521739130434, 'row', False)
        x355=operator.add(x347, x354)
        x356=self.layernorm31(x355)
        x359=operator.getitem(self.relative_position_bias_table14, self.relative_position_index14)
        x360=x359.view(49, 49, -1)
        x361=x360.permute(2, 0, 1)
        x362=x361.contiguous()
        x363=x362.unsqueeze(0)
        x368=torchvision.models.swin_transformer.shifted_window_attention(x356, self.weight28, self.weight29, x363, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias28, proj_bias=self.bias29)
        x369=stochastic_depth(x368, 0.1826086956521739, 'row', False)
        x370=operator.add(x355, x369)
        x371=self.layernorm32(x370)
        x372=self.linear30(x371)
        x373=self.gelu14(x372)
        x374=self.dropout28(x373)
        x375=self.linear31(x374)
        x376=self.dropout29(x375)
        x377=stochastic_depth(x376, 0.1826086956521739, 'row', False)
        x378=operator.add(x370, x377)
        x379=self.layernorm33(x378)
        x382=operator.getitem(self.relative_position_bias_table15, self.relative_position_index15)
        x383=x382.view(49, 49, -1)
        x384=x383.permute(2, 0, 1)
        x385=x384.contiguous()
        x386=x385.unsqueeze(0)
        x391=torchvision.models.swin_transformer.shifted_window_attention(x379, self.weight30, self.weight31, x386, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias30, proj_bias=self.bias31)
        x392=stochastic_depth(x391, 0.1956521739130435, 'row', False)
        x393=operator.add(x378, x392)
        x394=self.layernorm34(x393)
        x395=self.linear32(x394)
        x396=self.gelu15(x395)
        x397=self.dropout30(x396)
        x398=self.linear33(x397)
        x399=self.dropout31(x398)
        x400=stochastic_depth(x399, 0.1956521739130435, 'row', False)
        x401=operator.add(x393, x400)
        x402=self.layernorm35(x401)
        x405=operator.getitem(self.relative_position_bias_table16, self.relative_position_index16)
        x406=x405.view(49, 49, -1)
        x407=x406.permute(2, 0, 1)
        x408=x407.contiguous()
        x409=x408.unsqueeze(0)
        x414=torchvision.models.swin_transformer.shifted_window_attention(x402, self.weight32, self.weight33, x409, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias32, proj_bias=self.bias33)
        x415=stochastic_depth(x414, 0.20869565217391303, 'row', False)
        x416=operator.add(x401, x415)
        x417=self.layernorm36(x416)
        x418=self.linear34(x417)
        x419=self.gelu16(x418)
        x420=self.dropout32(x419)
        x421=self.linear35(x420)
        x422=self.dropout33(x421)
        x423=stochastic_depth(x422, 0.20869565217391303, 'row', False)
        x424=operator.add(x416, x423)
        x425=self.layernorm37(x424)
        x428=operator.getitem(self.relative_position_bias_table17, self.relative_position_index17)
        x429=x428.view(49, 49, -1)
        x430=x429.permute(2, 0, 1)
        x431=x430.contiguous()
        x432=x431.unsqueeze(0)
        x437=torchvision.models.swin_transformer.shifted_window_attention(x425, self.weight34, self.weight35, x432, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias34, proj_bias=self.bias35)
        x438=stochastic_depth(x437, 0.2217391304347826, 'row', False)
        x439=operator.add(x424, x438)
        x440=self.layernorm38(x439)
        x441=self.linear36(x440)
        x442=self.gelu17(x441)
        x443=self.dropout34(x442)
        x444=self.linear37(x443)
        x445=self.dropout35(x444)
        x446=stochastic_depth(x445, 0.2217391304347826, 'row', False)
        x447=operator.add(x439, x446)
        x448=self.layernorm39(x447)
        x451=operator.getitem(self.relative_position_bias_table18, self.relative_position_index18)
        x452=x451.view(49, 49, -1)
        x453=x452.permute(2, 0, 1)
        x454=x453.contiguous()
        x455=x454.unsqueeze(0)
        x460=torchvision.models.swin_transformer.shifted_window_attention(x448, self.weight36, self.weight37, x455, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias36, proj_bias=self.bias37)
        x461=stochastic_depth(x460, 0.23478260869565215, 'row', False)
        x462=operator.add(x447, x461)
        x463=self.layernorm40(x462)
        x464=self.linear38(x463)
        x465=self.gelu18(x464)
        x466=self.dropout36(x465)
        x467=self.linear39(x466)
        x468=self.dropout37(x467)
        x469=stochastic_depth(x468, 0.23478260869565215, 'row', False)
        x470=operator.add(x462, x469)
        x471=self.layernorm41(x470)
        x474=operator.getitem(self.relative_position_bias_table19, self.relative_position_index19)
        x475=x474.view(49, 49, -1)
        x476=x475.permute(2, 0, 1)
        x477=x476.contiguous()
        x478=x477.unsqueeze(0)
        x483=torchvision.models.swin_transformer.shifted_window_attention(x471, self.weight38, self.weight39, x478, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias38, proj_bias=self.bias39)
        x484=stochastic_depth(x483, 0.24782608695652175, 'row', False)
        x485=operator.add(x470, x484)
        x486=self.layernorm42(x485)
        x487=self.linear40(x486)
        x488=self.gelu19(x487)
        x489=self.dropout38(x488)
        x490=self.linear41(x489)
        x491=self.dropout39(x490)
        x492=stochastic_depth(x491, 0.24782608695652175, 'row', False)
        x493=operator.add(x485, x492)
        x494=self.layernorm43(x493)
        x497=operator.getitem(self.relative_position_bias_table20, self.relative_position_index20)
        x498=x497.view(49, 49, -1)
        x499=x498.permute(2, 0, 1)
        x500=x499.contiguous()
        x501=x500.unsqueeze(0)
        x506=torchvision.models.swin_transformer.shifted_window_attention(x494, self.weight40, self.weight41, x501, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias40, proj_bias=self.bias41)
        x507=stochastic_depth(x506, 0.2608695652173913, 'row', False)
        x508=operator.add(x493, x507)
        x509=self.layernorm44(x508)
        x510=self.linear42(x509)
        x511=self.gelu20(x510)
        x512=self.dropout40(x511)
        x513=self.linear43(x512)
        x514=self.dropout41(x513)
        x515=stochastic_depth(x514, 0.2608695652173913, 'row', False)
        x516=operator.add(x508, x515)
        x517=self.layernorm45(x516)
        x520=operator.getitem(self.relative_position_bias_table21, self.relative_position_index21)
        x521=x520.view(49, 49, -1)
        x522=x521.permute(2, 0, 1)
        x523=x522.contiguous()
        x524=x523.unsqueeze(0)
        x529=torchvision.models.swin_transformer.shifted_window_attention(x517, self.weight42, self.weight43, x524, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias42, proj_bias=self.bias43)
        x530=stochastic_depth(x529, 0.27391304347826084, 'row', False)
        x531=operator.add(x516, x530)
        x532=self.layernorm46(x531)
        x533=self.linear44(x532)
        x534=self.gelu21(x533)
        x535=self.dropout42(x534)
        x536=self.linear45(x535)
        x537=self.dropout43(x536)
        x538=stochastic_depth(x537, 0.27391304347826084, 'row', False)
        x539=operator.add(x531, x538)
        x540=builtins.getattr(x539, 'shape')
        x541=operator.getitem(x540, slice(-3, None, None))
        x542=operator.getitem(x541, 0)
        x543=operator.getitem(x541, 1)
        x544=operator.getitem(x541, 2)
        x545=operator.mod(x543, 2)
        x546=operator.mod(x542, 2)
        x547=torch.nn.functional.pad(x539, (0, 0, 0, x545, 0, x546))
        x548=operator.getitem(x547, (Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None, None, None)))
        x549=operator.getitem(x547, (Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None, None, None)))
        x550=operator.getitem(x547, (Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None, None, None)))
        x551=operator.getitem(x547, (Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None, None, None)))
        x552=torch.cat([x548, x549, x550, x551], -1)
        x553=self.layernorm47(x552)
        x554=self.linear46(x553)
        x555=self.layernorm48(x554)
        x558=operator.getitem(self.relative_position_bias_table22, self.relative_position_index22)
        x559=x558.view(49, 49, -1)
        x560=x559.permute(2, 0, 1)
        x561=x560.contiguous()
        x562=x561.unsqueeze(0)
        x567=torchvision.models.swin_transformer.shifted_window_attention(x555, self.weight44, self.weight45, x562, [7, 7], 24,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias44, proj_bias=self.bias45)
        x568=stochastic_depth(x567, 0.28695652173913044, 'row', False)
        x569=operator.add(x554, x568)
        x570=self.layernorm49(x569)
        x571=self.linear47(x570)
        x572=self.gelu22(x571)
        x573=self.dropout44(x572)
        x574=self.linear48(x573)
        x575=self.dropout45(x574)
        x576=stochastic_depth(x575, 0.28695652173913044, 'row', False)
        x577=operator.add(x569, x576)
        x578=self.layernorm50(x577)
        x581=operator.getitem(self.relative_position_bias_table23, self.relative_position_index23)
        x582=x581.view(49, 49, -1)
        x583=x582.permute(2, 0, 1)
        x584=x583.contiguous()
        x585=x584.unsqueeze(0)
        x590=torchvision.models.swin_transformer.shifted_window_attention(x578, self.weight46, self.weight47, x585, [7, 7], 24,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias46, proj_bias=self.bias47)
        x591=stochastic_depth(x590, 0.3, 'row', False)
        x592=operator.add(x577, x591)
        x593=self.layernorm51(x592)
        x594=self.linear49(x593)
        x595=self.gelu23(x594)
        x596=self.dropout46(x595)
        x597=self.linear50(x596)
        x598=self.dropout47(x597)
        x599=stochastic_depth(x598, 0.3, 'row', False)
        x600=operator.add(x592, x599)
        x601=self.layernorm52(x600)
        x602=x601.permute(0, 3, 1, 2)
        x603=self.adaptiveavgpool2d0(x602)
        x604=torch.flatten(x603, 1)
        x605=self.linear51(x604)

m = M().eval()
x = torch.randn(1, 3, 224, 224)
start = time.time()
output = m(x)
end = time.time()
print(end-start)
