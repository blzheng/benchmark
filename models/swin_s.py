import torch
from torch import tensor
import torch.nn as nn
from torch.nn import *
import torchvision
import torchvision.models as models
from torchvision.ops.stochastic_depth import stochastic_depth
import time
import builtins
import operator

class M(torch.nn.Module):
    def __init__(self):
        super(M, self).__init__()
        self.conv2d0 = Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        self.layernorm0 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.layernorm1 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.layernorm2 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.linear0 = Linear(in_features=96, out_features=384, bias=True)
        self.gelu0 = GELU(approximate='none')
        self.dropout0 = Dropout(p=0.0, inplace=False)
        self.linear1 = Linear(in_features=384, out_features=96, bias=True)
        self.dropout1 = Dropout(p=0.0, inplace=False)
        self.layernorm3 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.layernorm4 = LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        self.linear2 = Linear(in_features=96, out_features=384, bias=True)
        self.gelu1 = GELU(approximate='none')
        self.dropout2 = Dropout(p=0.0, inplace=False)
        self.linear3 = Linear(in_features=384, out_features=96, bias=True)
        self.dropout3 = Dropout(p=0.0, inplace=False)
        self.layernorm5 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear4 = Linear(in_features=384, out_features=192, bias=False)
        self.layernorm6 = LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        self.layernorm7 = LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        self.linear5 = Linear(in_features=192, out_features=768, bias=True)
        self.gelu2 = GELU(approximate='none')
        self.dropout4 = Dropout(p=0.0, inplace=False)
        self.linear6 = Linear(in_features=768, out_features=192, bias=True)
        self.dropout5 = Dropout(p=0.0, inplace=False)
        self.layernorm8 = LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        self.layernorm9 = LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        self.linear7 = Linear(in_features=192, out_features=768, bias=True)
        self.gelu3 = GELU(approximate='none')
        self.dropout6 = Dropout(p=0.0, inplace=False)
        self.linear8 = Linear(in_features=768, out_features=192, bias=True)
        self.dropout7 = Dropout(p=0.0, inplace=False)
        self.layernorm10 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.linear9 = Linear(in_features=768, out_features=384, bias=False)
        self.layernorm11 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm12 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear10 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu4 = GELU(approximate='none')
        self.dropout8 = Dropout(p=0.0, inplace=False)
        self.linear11 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout9 = Dropout(p=0.0, inplace=False)
        self.layernorm13 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm14 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear12 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu5 = GELU(approximate='none')
        self.dropout10 = Dropout(p=0.0, inplace=False)
        self.linear13 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout11 = Dropout(p=0.0, inplace=False)
        self.layernorm15 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm16 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear14 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu6 = GELU(approximate='none')
        self.dropout12 = Dropout(p=0.0, inplace=False)
        self.linear15 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout13 = Dropout(p=0.0, inplace=False)
        self.layernorm17 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm18 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear16 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu7 = GELU(approximate='none')
        self.dropout14 = Dropout(p=0.0, inplace=False)
        self.linear17 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout15 = Dropout(p=0.0, inplace=False)
        self.layernorm19 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm20 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear18 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu8 = GELU(approximate='none')
        self.dropout16 = Dropout(p=0.0, inplace=False)
        self.linear19 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout17 = Dropout(p=0.0, inplace=False)
        self.layernorm21 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm22 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear20 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu9 = GELU(approximate='none')
        self.dropout18 = Dropout(p=0.0, inplace=False)
        self.linear21 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout19 = Dropout(p=0.0, inplace=False)
        self.layernorm23 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm24 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear22 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu10 = GELU(approximate='none')
        self.dropout20 = Dropout(p=0.0, inplace=False)
        self.linear23 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout21 = Dropout(p=0.0, inplace=False)
        self.layernorm25 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm26 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear24 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu11 = GELU(approximate='none')
        self.dropout22 = Dropout(p=0.0, inplace=False)
        self.linear25 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout23 = Dropout(p=0.0, inplace=False)
        self.layernorm27 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm28 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear26 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu12 = GELU(approximate='none')
        self.dropout24 = Dropout(p=0.0, inplace=False)
        self.linear27 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout25 = Dropout(p=0.0, inplace=False)
        self.layernorm29 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm30 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear28 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu13 = GELU(approximate='none')
        self.dropout26 = Dropout(p=0.0, inplace=False)
        self.linear29 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout27 = Dropout(p=0.0, inplace=False)
        self.layernorm31 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm32 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear30 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu14 = GELU(approximate='none')
        self.dropout28 = Dropout(p=0.0, inplace=False)
        self.linear31 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout29 = Dropout(p=0.0, inplace=False)
        self.layernorm33 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm34 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear32 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu15 = GELU(approximate='none')
        self.dropout30 = Dropout(p=0.0, inplace=False)
        self.linear33 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout31 = Dropout(p=0.0, inplace=False)
        self.layernorm35 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm36 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear34 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu16 = GELU(approximate='none')
        self.dropout32 = Dropout(p=0.0, inplace=False)
        self.linear35 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout33 = Dropout(p=0.0, inplace=False)
        self.layernorm37 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm38 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear36 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu17 = GELU(approximate='none')
        self.dropout34 = Dropout(p=0.0, inplace=False)
        self.linear37 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout35 = Dropout(p=0.0, inplace=False)
        self.layernorm39 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm40 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear38 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu18 = GELU(approximate='none')
        self.dropout36 = Dropout(p=0.0, inplace=False)
        self.linear39 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout37 = Dropout(p=0.0, inplace=False)
        self.layernorm41 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm42 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear40 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu19 = GELU(approximate='none')
        self.dropout38 = Dropout(p=0.0, inplace=False)
        self.linear41 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout39 = Dropout(p=0.0, inplace=False)
        self.layernorm43 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm44 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear42 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu20 = GELU(approximate='none')
        self.dropout40 = Dropout(p=0.0, inplace=False)
        self.linear43 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout41 = Dropout(p=0.0, inplace=False)
        self.layernorm45 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.layernorm46 = LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        self.linear44 = Linear(in_features=384, out_features=1536, bias=True)
        self.gelu21 = GELU(approximate='none')
        self.dropout42 = Dropout(p=0.0, inplace=False)
        self.linear45 = Linear(in_features=1536, out_features=384, bias=True)
        self.dropout43 = Dropout(p=0.0, inplace=False)
        self.layernorm47 = LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        self.linear46 = Linear(in_features=1536, out_features=768, bias=False)
        self.layernorm48 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.layernorm49 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.linear47 = Linear(in_features=768, out_features=3072, bias=True)
        self.gelu22 = GELU(approximate='none')
        self.dropout44 = Dropout(p=0.0, inplace=False)
        self.linear48 = Linear(in_features=3072, out_features=768, bias=True)
        self.dropout45 = Dropout(p=0.0, inplace=False)
        self.layernorm50 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.layernorm51 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.linear49 = Linear(in_features=768, out_features=3072, bias=True)
        self.gelu23 = GELU(approximate='none')
        self.dropout46 = Dropout(p=0.0, inplace=False)
        self.linear50 = Linear(in_features=3072, out_features=768, bias=True)
        self.dropout47 = Dropout(p=0.0, inplace=False)
        self.layernorm52 = LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        self.adaptiveavgpool2d0 = AdaptiveAvgPool2d(output_size=1)
        self.linear51 = Linear(in_features=768, out_features=1000, bias=True)
        self.relative_position_bias_table0 = torch.rand(torch.Size([169, 3])).to(torch.float32)
        self.relative_position_index0 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight0 = torch.rand(torch.Size([288, 96])).to(torch.float32)
        self.weight1 = torch.rand(torch.Size([96, 96])).to(torch.float32)
        self.bias0 = torch.rand(torch.Size([288])).to(torch.float32)
        self.bias1 = torch.rand(torch.Size([96])).to(torch.float32)
        self.relative_position_bias_table1 = torch.rand(torch.Size([169, 3])).to(torch.float32)
        self.relative_position_index1 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight2 = torch.rand(torch.Size([288, 96])).to(torch.float32)
        self.weight3 = torch.rand(torch.Size([96, 96])).to(torch.float32)
        self.bias2 = torch.rand(torch.Size([288])).to(torch.float32)
        self.bias3 = torch.rand(torch.Size([96])).to(torch.float32)
        self.relative_position_bias_table2 = torch.rand(torch.Size([169, 6])).to(torch.float32)
        self.relative_position_index2 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight4 = torch.rand(torch.Size([576, 192])).to(torch.float32)
        self.weight5 = torch.rand(torch.Size([192, 192])).to(torch.float32)
        self.bias4 = torch.rand(torch.Size([576])).to(torch.float32)
        self.bias5 = torch.rand(torch.Size([192])).to(torch.float32)
        self.relative_position_bias_table3 = torch.rand(torch.Size([169, 6])).to(torch.float32)
        self.relative_position_index3 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight6 = torch.rand(torch.Size([576, 192])).to(torch.float32)
        self.weight7 = torch.rand(torch.Size([192, 192])).to(torch.float32)
        self.bias6 = torch.rand(torch.Size([576])).to(torch.float32)
        self.bias7 = torch.rand(torch.Size([192])).to(torch.float32)
        self.relative_position_bias_table4 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index4 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight8 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight9 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias8 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias9 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table5 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index5 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight10 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight11 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias10 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias11 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table6 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index6 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight12 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight13 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias12 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias13 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table7 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index7 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight14 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight15 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias14 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias15 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table8 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index8 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight16 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight17 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias16 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias17 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table9 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index9 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight18 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight19 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias18 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias19 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table10 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index10 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight20 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight21 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias20 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias21 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table11 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index11 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight22 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight23 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias22 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias23 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table12 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index12 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight24 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight25 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias24 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias25 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table13 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index13 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight26 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight27 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias26 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias27 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table14 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index14 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight28 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight29 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias28 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias29 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table15 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index15 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight30 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight31 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias30 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias31 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table16 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index16 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight32 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight33 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias32 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias33 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table17 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index17 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight34 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight35 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias34 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias35 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table18 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index18 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight36 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight37 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias36 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias37 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table19 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index19 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight38 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight39 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias38 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias39 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table20 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index20 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight40 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight41 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias40 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias41 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table21 = torch.rand(torch.Size([169, 12])).to(torch.float32)
        self.relative_position_index21 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight42 = torch.rand(torch.Size([1152, 384])).to(torch.float32)
        self.weight43 = torch.rand(torch.Size([384, 384])).to(torch.float32)
        self.bias42 = torch.rand(torch.Size([1152])).to(torch.float32)
        self.bias43 = torch.rand(torch.Size([384])).to(torch.float32)
        self.relative_position_bias_table22 = torch.rand(torch.Size([169, 24])).to(torch.float32)
        self.relative_position_index22 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight44 = torch.rand(torch.Size([2304, 768])).to(torch.float32)
        self.weight45 = torch.rand(torch.Size([768, 768])).to(torch.float32)
        self.bias44 = torch.rand(torch.Size([2304])).to(torch.float32)
        self.bias45 = torch.rand(torch.Size([768])).to(torch.float32)
        self.relative_position_bias_table23 = torch.rand(torch.Size([169, 24])).to(torch.float32)
        self.relative_position_index23 = torch.rand(torch.Size([2401])).to(torch.int64)
        self.weight46 = torch.rand(torch.Size([2304, 768])).to(torch.float32)
        self.weight47 = torch.rand(torch.Size([768, 768])).to(torch.float32)
        self.bias46 = torch.rand(torch.Size([2304])).to(torch.float32)
        self.bias47 = torch.rand(torch.Size([768])).to(torch.float32)

    def forward(self, x):
        x0=x
        x1=self.conv2d0(x0)
        x2=torch.permute(x1, [0, 2, 3, 1])
        x3=self.layernorm0(x2)
        x4=self.layernorm1(x3)
        x7=operator.getitem(self.relative_position_bias_table0, self.relative_position_index0)
        x8=x7.view(49, 49, -1)
        x9=x8.permute(2, 0, 1)
        x10=x9.contiguous()
        x11=x10.unsqueeze(0)
        x16=torchvision.models.swin_transformer.shifted_window_attention(x4, self.weight0, self.weight1, x11, [7, 7], 3,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias0, proj_bias=self.bias1)
        x17=stochastic_depth(x16, 0.0, 'row', False)
        x18=operator.add(x3, x17)
        x19=self.layernorm2(x18)
        x20=self.linear0(x19)
        x21=self.gelu0(x20)
        x22=self.dropout0(x21)
        x23=self.linear1(x22)
        x24=self.dropout1(x23)
        x25=stochastic_depth(x24, 0.0, 'row', False)
        x26=operator.add(x18, x25)
        x27=self.layernorm3(x26)
        x30=operator.getitem(self.relative_position_bias_table1, self.relative_position_index1)
        x31=x30.view(49, 49, -1)
        x32=x31.permute(2, 0, 1)
        x33=x32.contiguous()
        x34=x33.unsqueeze(0)
        x39=torchvision.models.swin_transformer.shifted_window_attention(x27, self.weight2, self.weight3, x34, [7, 7], 3,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias2, proj_bias=self.bias3)
        x40=stochastic_depth(x39, 0.013043478260869565, 'row', False)
        x41=operator.add(x26, x40)
        x42=self.layernorm4(x41)
        x43=self.linear2(x42)
        x44=self.gelu1(x43)
        x45=self.dropout2(x44)
        x46=self.linear3(x45)
        x47=self.dropout3(x46)
        x48=stochastic_depth(x47, 0.013043478260869565, 'row', False)
        x49=operator.add(x41, x48)
        x50=torchvision.models.swin_transformer._patch_merging_pad(x49)
        x51=operator.getitem(x50, (Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None, None, None)))
        x52=operator.getitem(x50, (Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None, None, None)))
        x53=operator.getitem(x50, (Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None, None, None)))
        x54=operator.getitem(x50, (Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None, None, None)))
        x55=torch.cat([x51, x52, x53, x54], -1)
        x56=self.layernorm5(x55)
        x57=self.linear4(x56)
        x58=self.layernorm6(x57)
        x61=operator.getitem(self.relative_position_bias_table2, self.relative_position_index2)
        x62=x61.view(49, 49, -1)
        x63=x62.permute(2, 0, 1)
        x64=x63.contiguous()
        x65=x64.unsqueeze(0)
        x70=torchvision.models.swin_transformer.shifted_window_attention(x58, self.weight4, self.weight5, x65, [7, 7], 6,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias4, proj_bias=self.bias5)
        x71=stochastic_depth(x70, 0.02608695652173913, 'row', False)
        x72=operator.add(x57, x71)
        x73=self.layernorm7(x72)
        x74=self.linear5(x73)
        x75=self.gelu2(x74)
        x76=self.dropout4(x75)
        x77=self.linear6(x76)
        x78=self.dropout5(x77)
        x79=stochastic_depth(x78, 0.02608695652173913, 'row', False)
        x80=operator.add(x72, x79)
        x81=self.layernorm8(x80)
        x84=operator.getitem(self.relative_position_bias_table3, self.relative_position_index3)
        x85=x84.view(49, 49, -1)
        x86=x85.permute(2, 0, 1)
        x87=x86.contiguous()
        x88=x87.unsqueeze(0)
        x93=torchvision.models.swin_transformer.shifted_window_attention(x81, self.weight6, self.weight7, x88, [7, 7], 6,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias6, proj_bias=self.bias7)
        x94=stochastic_depth(x93, 0.03913043478260869, 'row', False)
        x95=operator.add(x80, x94)
        x96=self.layernorm9(x95)
        x97=self.linear7(x96)
        x98=self.gelu3(x97)
        x99=self.dropout6(x98)
        x100=self.linear8(x99)
        x101=self.dropout7(x100)
        x102=stochastic_depth(x101, 0.03913043478260869, 'row', False)
        x103=operator.add(x95, x102)
        x104=torchvision.models.swin_transformer._patch_merging_pad(x103)
        x105=operator.getitem(x104, (Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None, None, None)))
        x106=operator.getitem(x104, (Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None, None, None)))
        x107=operator.getitem(x104, (Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None, None, None)))
        x108=operator.getitem(x104, (Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None, None, None)))
        x109=torch.cat([x105, x106, x107, x108], -1)
        x110=self.layernorm10(x109)
        x111=self.linear9(x110)
        x112=self.layernorm11(x111)
        x115=operator.getitem(self.relative_position_bias_table4, self.relative_position_index4)
        x116=x115.view(49, 49, -1)
        x117=x116.permute(2, 0, 1)
        x118=x117.contiguous()
        x119=x118.unsqueeze(0)
        x124=torchvision.models.swin_transformer.shifted_window_attention(x112, self.weight8, self.weight9, x119, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias8, proj_bias=self.bias9)
        x125=stochastic_depth(x124, 0.05217391304347826, 'row', False)
        x126=operator.add(x111, x125)
        x127=self.layernorm12(x126)
        x128=self.linear10(x127)
        x129=self.gelu4(x128)
        x130=self.dropout8(x129)
        x131=self.linear11(x130)
        x132=self.dropout9(x131)
        x133=stochastic_depth(x132, 0.05217391304347826, 'row', False)
        x134=operator.add(x126, x133)
        x135=self.layernorm13(x134)
        x138=operator.getitem(self.relative_position_bias_table5, self.relative_position_index5)
        x139=x138.view(49, 49, -1)
        x140=x139.permute(2, 0, 1)
        x141=x140.contiguous()
        x142=x141.unsqueeze(0)
        x147=torchvision.models.swin_transformer.shifted_window_attention(x135, self.weight10, self.weight11, x142, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias10, proj_bias=self.bias11)
        x148=stochastic_depth(x147, 0.06521739130434782, 'row', False)
        x149=operator.add(x134, x148)
        x150=self.layernorm14(x149)
        x151=self.linear12(x150)
        x152=self.gelu5(x151)
        x153=self.dropout10(x152)
        x154=self.linear13(x153)
        x155=self.dropout11(x154)
        x156=stochastic_depth(x155, 0.06521739130434782, 'row', False)
        x157=operator.add(x149, x156)
        x158=self.layernorm15(x157)
        x161=operator.getitem(self.relative_position_bias_table6, self.relative_position_index6)
        x162=x161.view(49, 49, -1)
        x163=x162.permute(2, 0, 1)
        x164=x163.contiguous()
        x165=x164.unsqueeze(0)
        x170=torchvision.models.swin_transformer.shifted_window_attention(x158, self.weight12, self.weight13, x165, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias12, proj_bias=self.bias13)
        x171=stochastic_depth(x170, 0.07826086956521738, 'row', False)
        x172=operator.add(x157, x171)
        x173=self.layernorm16(x172)
        x174=self.linear14(x173)
        x175=self.gelu6(x174)
        x176=self.dropout12(x175)
        x177=self.linear15(x176)
        x178=self.dropout13(x177)
        x179=stochastic_depth(x178, 0.07826086956521738, 'row', False)
        x180=operator.add(x172, x179)
        x181=self.layernorm17(x180)
        x184=operator.getitem(self.relative_position_bias_table7, self.relative_position_index7)
        x185=x184.view(49, 49, -1)
        x186=x185.permute(2, 0, 1)
        x187=x186.contiguous()
        x188=x187.unsqueeze(0)
        x193=torchvision.models.swin_transformer.shifted_window_attention(x181, self.weight14, self.weight15, x188, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias14, proj_bias=self.bias15)
        x194=stochastic_depth(x193, 0.09130434782608696, 'row', False)
        x195=operator.add(x180, x194)
        x196=self.layernorm18(x195)
        x197=self.linear16(x196)
        x198=self.gelu7(x197)
        x199=self.dropout14(x198)
        x200=self.linear17(x199)
        x201=self.dropout15(x200)
        x202=stochastic_depth(x201, 0.09130434782608696, 'row', False)
        x203=operator.add(x195, x202)
        x204=self.layernorm19(x203)
        x207=operator.getitem(self.relative_position_bias_table8, self.relative_position_index8)
        x208=x207.view(49, 49, -1)
        x209=x208.permute(2, 0, 1)
        x210=x209.contiguous()
        x211=x210.unsqueeze(0)
        x216=torchvision.models.swin_transformer.shifted_window_attention(x204, self.weight16, self.weight17, x211, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias16, proj_bias=self.bias17)
        x217=stochastic_depth(x216, 0.10434782608695652, 'row', False)
        x218=operator.add(x203, x217)
        x219=self.layernorm20(x218)
        x220=self.linear18(x219)
        x221=self.gelu8(x220)
        x222=self.dropout16(x221)
        x223=self.linear19(x222)
        x224=self.dropout17(x223)
        x225=stochastic_depth(x224, 0.10434782608695652, 'row', False)
        x226=operator.add(x218, x225)
        x227=self.layernorm21(x226)
        x230=operator.getitem(self.relative_position_bias_table9, self.relative_position_index9)
        x231=x230.view(49, 49, -1)
        x232=x231.permute(2, 0, 1)
        x233=x232.contiguous()
        x234=x233.unsqueeze(0)
        x239=torchvision.models.swin_transformer.shifted_window_attention(x227, self.weight18, self.weight19, x234, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias18, proj_bias=self.bias19)
        x240=stochastic_depth(x239, 0.11739130434782608, 'row', False)
        x241=operator.add(x226, x240)
        x242=self.layernorm22(x241)
        x243=self.linear20(x242)
        x244=self.gelu9(x243)
        x245=self.dropout18(x244)
        x246=self.linear21(x245)
        x247=self.dropout19(x246)
        x248=stochastic_depth(x247, 0.11739130434782608, 'row', False)
        x249=operator.add(x241, x248)
        x250=self.layernorm23(x249)
        x253=operator.getitem(self.relative_position_bias_table10, self.relative_position_index10)
        x254=x253.view(49, 49, -1)
        x255=x254.permute(2, 0, 1)
        x256=x255.contiguous()
        x257=x256.unsqueeze(0)
        x262=torchvision.models.swin_transformer.shifted_window_attention(x250, self.weight20, self.weight21, x257, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias20, proj_bias=self.bias21)
        x263=stochastic_depth(x262, 0.13043478260869565, 'row', False)
        x264=operator.add(x249, x263)
        x265=self.layernorm24(x264)
        x266=self.linear22(x265)
        x267=self.gelu10(x266)
        x268=self.dropout20(x267)
        x269=self.linear23(x268)
        x270=self.dropout21(x269)
        x271=stochastic_depth(x270, 0.13043478260869565, 'row', False)
        x272=operator.add(x264, x271)
        x273=self.layernorm25(x272)
        x276=operator.getitem(self.relative_position_bias_table11, self.relative_position_index11)
        x277=x276.view(49, 49, -1)
        x278=x277.permute(2, 0, 1)
        x279=x278.contiguous()
        x280=x279.unsqueeze(0)
        x285=torchvision.models.swin_transformer.shifted_window_attention(x273, self.weight22, self.weight23, x280, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias22, proj_bias=self.bias23)
        x286=stochastic_depth(x285, 0.14347826086956522, 'row', False)
        x287=operator.add(x272, x286)
        x288=self.layernorm26(x287)
        x289=self.linear24(x288)
        x290=self.gelu11(x289)
        x291=self.dropout22(x290)
        x292=self.linear25(x291)
        x293=self.dropout23(x292)
        x294=stochastic_depth(x293, 0.14347826086956522, 'row', False)
        x295=operator.add(x287, x294)
        x296=self.layernorm27(x295)
        x299=operator.getitem(self.relative_position_bias_table12, self.relative_position_index12)
        x300=x299.view(49, 49, -1)
        x301=x300.permute(2, 0, 1)
        x302=x301.contiguous()
        x303=x302.unsqueeze(0)
        x308=torchvision.models.swin_transformer.shifted_window_attention(x296, self.weight24, self.weight25, x303, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias24, proj_bias=self.bias25)
        x309=stochastic_depth(x308, 0.15652173913043477, 'row', False)
        x310=operator.add(x295, x309)
        x311=self.layernorm28(x310)
        x312=self.linear26(x311)
        x313=self.gelu12(x312)
        x314=self.dropout24(x313)
        x315=self.linear27(x314)
        x316=self.dropout25(x315)
        x317=stochastic_depth(x316, 0.15652173913043477, 'row', False)
        x318=operator.add(x310, x317)
        x319=self.layernorm29(x318)
        x322=operator.getitem(self.relative_position_bias_table13, self.relative_position_index13)
        x323=x322.view(49, 49, -1)
        x324=x323.permute(2, 0, 1)
        x325=x324.contiguous()
        x326=x325.unsqueeze(0)
        x331=torchvision.models.swin_transformer.shifted_window_attention(x319, self.weight26, self.weight27, x326, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias26, proj_bias=self.bias27)
        x332=stochastic_depth(x331, 0.16956521739130434, 'row', False)
        x333=operator.add(x318, x332)
        x334=self.layernorm30(x333)
        x335=self.linear28(x334)
        x336=self.gelu13(x335)
        x337=self.dropout26(x336)
        x338=self.linear29(x337)
        x339=self.dropout27(x338)
        x340=stochastic_depth(x339, 0.16956521739130434, 'row', False)
        x341=operator.add(x333, x340)
        x342=self.layernorm31(x341)
        x345=operator.getitem(self.relative_position_bias_table14, self.relative_position_index14)
        x346=x345.view(49, 49, -1)
        x347=x346.permute(2, 0, 1)
        x348=x347.contiguous()
        x349=x348.unsqueeze(0)
        x354=torchvision.models.swin_transformer.shifted_window_attention(x342, self.weight28, self.weight29, x349, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias28, proj_bias=self.bias29)
        x355=stochastic_depth(x354, 0.1826086956521739, 'row', False)
        x356=operator.add(x341, x355)
        x357=self.layernorm32(x356)
        x358=self.linear30(x357)
        x359=self.gelu14(x358)
        x360=self.dropout28(x359)
        x361=self.linear31(x360)
        x362=self.dropout29(x361)
        x363=stochastic_depth(x362, 0.1826086956521739, 'row', False)
        x364=operator.add(x356, x363)
        x365=self.layernorm33(x364)
        x368=operator.getitem(self.relative_position_bias_table15, self.relative_position_index15)
        x369=x368.view(49, 49, -1)
        x370=x369.permute(2, 0, 1)
        x371=x370.contiguous()
        x372=x371.unsqueeze(0)
        x377=torchvision.models.swin_transformer.shifted_window_attention(x365, self.weight30, self.weight31, x372, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias30, proj_bias=self.bias31)
        x378=stochastic_depth(x377, 0.1956521739130435, 'row', False)
        x379=operator.add(x364, x378)
        x380=self.layernorm34(x379)
        x381=self.linear32(x380)
        x382=self.gelu15(x381)
        x383=self.dropout30(x382)
        x384=self.linear33(x383)
        x385=self.dropout31(x384)
        x386=stochastic_depth(x385, 0.1956521739130435, 'row', False)
        x387=operator.add(x379, x386)
        x388=self.layernorm35(x387)
        x391=operator.getitem(self.relative_position_bias_table16, self.relative_position_index16)
        x392=x391.view(49, 49, -1)
        x393=x392.permute(2, 0, 1)
        x394=x393.contiguous()
        x395=x394.unsqueeze(0)
        x400=torchvision.models.swin_transformer.shifted_window_attention(x388, self.weight32, self.weight33, x395, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias32, proj_bias=self.bias33)
        x401=stochastic_depth(x400, 0.20869565217391303, 'row', False)
        x402=operator.add(x387, x401)
        x403=self.layernorm36(x402)
        x404=self.linear34(x403)
        x405=self.gelu16(x404)
        x406=self.dropout32(x405)
        x407=self.linear35(x406)
        x408=self.dropout33(x407)
        x409=stochastic_depth(x408, 0.20869565217391303, 'row', False)
        x410=operator.add(x402, x409)
        x411=self.layernorm37(x410)
        x414=operator.getitem(self.relative_position_bias_table17, self.relative_position_index17)
        x415=x414.view(49, 49, -1)
        x416=x415.permute(2, 0, 1)
        x417=x416.contiguous()
        x418=x417.unsqueeze(0)
        x423=torchvision.models.swin_transformer.shifted_window_attention(x411, self.weight34, self.weight35, x418, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias34, proj_bias=self.bias35)
        x424=stochastic_depth(x423, 0.2217391304347826, 'row', False)
        x425=operator.add(x410, x424)
        x426=self.layernorm38(x425)
        x427=self.linear36(x426)
        x428=self.gelu17(x427)
        x429=self.dropout34(x428)
        x430=self.linear37(x429)
        x431=self.dropout35(x430)
        x432=stochastic_depth(x431, 0.2217391304347826, 'row', False)
        x433=operator.add(x425, x432)
        x434=self.layernorm39(x433)
        x437=operator.getitem(self.relative_position_bias_table18, self.relative_position_index18)
        x438=x437.view(49, 49, -1)
        x439=x438.permute(2, 0, 1)
        x440=x439.contiguous()
        x441=x440.unsqueeze(0)
        x446=torchvision.models.swin_transformer.shifted_window_attention(x434, self.weight36, self.weight37, x441, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias36, proj_bias=self.bias37)
        x447=stochastic_depth(x446, 0.23478260869565215, 'row', False)
        x448=operator.add(x433, x447)
        x449=self.layernorm40(x448)
        x450=self.linear38(x449)
        x451=self.gelu18(x450)
        x452=self.dropout36(x451)
        x453=self.linear39(x452)
        x454=self.dropout37(x453)
        x455=stochastic_depth(x454, 0.23478260869565215, 'row', False)
        x456=operator.add(x448, x455)
        x457=self.layernorm41(x456)
        x460=operator.getitem(self.relative_position_bias_table19, self.relative_position_index19)
        x461=x460.view(49, 49, -1)
        x462=x461.permute(2, 0, 1)
        x463=x462.contiguous()
        x464=x463.unsqueeze(0)
        x469=torchvision.models.swin_transformer.shifted_window_attention(x457, self.weight38, self.weight39, x464, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias38, proj_bias=self.bias39)
        x470=stochastic_depth(x469, 0.24782608695652175, 'row', False)
        x471=operator.add(x456, x470)
        x472=self.layernorm42(x471)
        x473=self.linear40(x472)
        x474=self.gelu19(x473)
        x475=self.dropout38(x474)
        x476=self.linear41(x475)
        x477=self.dropout39(x476)
        x478=stochastic_depth(x477, 0.24782608695652175, 'row', False)
        x479=operator.add(x471, x478)
        x480=self.layernorm43(x479)
        x483=operator.getitem(self.relative_position_bias_table20, self.relative_position_index20)
        x484=x483.view(49, 49, -1)
        x485=x484.permute(2, 0, 1)
        x486=x485.contiguous()
        x487=x486.unsqueeze(0)
        x492=torchvision.models.swin_transformer.shifted_window_attention(x480, self.weight40, self.weight41, x487, [7, 7], 12,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias40, proj_bias=self.bias41)
        x493=stochastic_depth(x492, 0.2608695652173913, 'row', False)
        x494=operator.add(x479, x493)
        x495=self.layernorm44(x494)
        x496=self.linear42(x495)
        x497=self.gelu20(x496)
        x498=self.dropout40(x497)
        x499=self.linear43(x498)
        x500=self.dropout41(x499)
        x501=stochastic_depth(x500, 0.2608695652173913, 'row', False)
        x502=operator.add(x494, x501)
        x503=self.layernorm45(x502)
        x506=operator.getitem(self.relative_position_bias_table21, self.relative_position_index21)
        x507=x506.view(49, 49, -1)
        x508=x507.permute(2, 0, 1)
        x509=x508.contiguous()
        x510=x509.unsqueeze(0)
        x515=torchvision.models.swin_transformer.shifted_window_attention(x503, self.weight42, self.weight43, x510, [7, 7], 12,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias42, proj_bias=self.bias43)
        x516=stochastic_depth(x515, 0.27391304347826084, 'row', False)
        x517=operator.add(x502, x516)
        x518=self.layernorm46(x517)
        x519=self.linear44(x518)
        x520=self.gelu21(x519)
        x521=self.dropout42(x520)
        x522=self.linear45(x521)
        x523=self.dropout43(x522)
        x524=stochastic_depth(x523, 0.27391304347826084, 'row', False)
        x525=operator.add(x517, x524)
        x526=torchvision.models.swin_transformer._patch_merging_pad(x525)
        x527=operator.getitem(x526, (Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None, None, None)))
        x528=operator.getitem(x526, (Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None, None, None)))
        x529=operator.getitem(x526, (Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None, None, None)))
        x530=operator.getitem(x526, (Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None, None, None)))
        x531=torch.cat([x527, x528, x529, x530], -1)
        x532=self.layernorm47(x531)
        x533=self.linear46(x532)
        x534=self.layernorm48(x533)
        x537=operator.getitem(self.relative_position_bias_table22, self.relative_position_index22)
        x538=x537.view(49, 49, -1)
        x539=x538.permute(2, 0, 1)
        x540=x539.contiguous()
        x541=x540.unsqueeze(0)
        x546=torchvision.models.swin_transformer.shifted_window_attention(x534, self.weight44, self.weight45, x541, [7, 7], 24,shift_size=[0, 0], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias44, proj_bias=self.bias45)
        x547=stochastic_depth(x546, 0.28695652173913044, 'row', False)
        x548=operator.add(x533, x547)
        x549=self.layernorm49(x548)
        x550=self.linear47(x549)
        x551=self.gelu22(x550)
        x552=self.dropout44(x551)
        x553=self.linear48(x552)
        x554=self.dropout45(x553)
        x555=stochastic_depth(x554, 0.28695652173913044, 'row', False)
        x556=operator.add(x548, x555)
        x557=self.layernorm50(x556)
        x560=operator.getitem(self.relative_position_bias_table23, self.relative_position_index23)
        x561=x560.view(49, 49, -1)
        x562=x561.permute(2, 0, 1)
        x563=x562.contiguous()
        x564=x563.unsqueeze(0)
        x569=torchvision.models.swin_transformer.shifted_window_attention(x557, self.weight46, self.weight47, x564, [7, 7], 24,shift_size=[3, 3], attention_dropout=0.0, dropout=0.0, qkv_bias=self.bias46, proj_bias=self.bias47)
        x570=stochastic_depth(x569, 0.3, 'row', False)
        x571=operator.add(x556, x570)
        x572=self.layernorm51(x571)
        x573=self.linear49(x572)
        x574=self.gelu23(x573)
        x575=self.dropout46(x574)
        x576=self.linear50(x575)
        x577=self.dropout47(x576)
        x578=stochastic_depth(x577, 0.3, 'row', False)
        x579=operator.add(x571, x578)
        x580=self.layernorm52(x579)
        x581=x580.permute(0, 3, 1, 2)
        x582=self.adaptiveavgpool2d0(x581)
        x583=torch.flatten(x582, 1)
        x584=self.linear51(x583)

m = M().eval()
x = torch.rand(1, 3, 224, 224)
start = time.time()
output = m(x)
end = time.time()
print(end-start)
