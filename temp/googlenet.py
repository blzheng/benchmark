import torch
from torch import tensor
import torch.nn as nn
from torch.nn import *
import torchvision
import torchvision.models as models
from torchvision.ops.stochastic_depth import stochastic_depth
import time
import builtins
import operator
import sys
import os

class M(torch.nn.Module):
    def __init__(self):
        super(M, self).__init__()
        self.conv2d0 = Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        self.batchnorm2d0 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d0 = MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
        self.conv2d1 = Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d1 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d2 = Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d2 = BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d1 = MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
        self.conv2d3 = Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d3 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d4 = Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d4 = BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d5 = Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d5 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d6 = Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d6 = BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d7 = Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d7 = BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d2 = MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
        self.conv2d8 = Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d8 = BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d9 = Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d9 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d10 = Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d10 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d11 = Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d11 = BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d12 = Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d12 = BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d13 = Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d13 = BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d3 = MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
        self.conv2d14 = Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d14 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d4 = MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
        self.conv2d15 = Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d15 = BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d16 = Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d16 = BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d17 = Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d17 = BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d18 = Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d18 = BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d19 = Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d19 = BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d5 = MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
        self.conv2d20 = Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d20 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d21 = Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d21 = BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d22 = Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d22 = BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d23 = Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d23 = BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d24 = Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d24 = BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d25 = Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d25 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d6 = MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
        self.conv2d26 = Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d26 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d27 = Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d27 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d28 = Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d28 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d29 = Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d29 = BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d30 = Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d30 = BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d31 = Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d31 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d7 = MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
        self.conv2d32 = Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d32 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d33 = Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d33 = BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d34 = Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d34 = BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d35 = Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d35 = BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d36 = Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d36 = BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d37 = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d37 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d8 = MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
        self.conv2d38 = Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d38 = BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d39 = Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d39 = BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d40 = Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d40 = BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d41 = Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d41 = BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d42 = Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d42 = BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d43 = Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d43 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d9 = MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
        self.conv2d44 = Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d44 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d10 = MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)
        self.conv2d45 = Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d45 = BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d46 = Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d46 = BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d47 = Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d47 = BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d48 = Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d48 = BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d49 = Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d49 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d11 = MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
        self.conv2d50 = Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d50 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d51 = Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d51 = BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d52 = Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d52 = BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d53 = Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d53 = BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d54 = Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d54 = BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.conv2d55 = Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d55 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.maxpool2d12 = MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
        self.conv2d56 = Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d56 = BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        self.adaptiveavgpool2d0 = AdaptiveAvgPool2d(output_size=(1, 1))
        self.dropout0 = Dropout(p=0.2, inplace=False)
        self.linear0 = Linear(in_features=1024, out_features=1000, bias=True)

    def forward(self, x):
        x0=x
        print('x0: {}'.format(x0.shape))
        x1=operator.getitem(x0, (slice(None, None, None), 0))
        print('x1: {}'.format(x1.shape))
        x2=torch.unsqueeze(x1, 1)
        print('x2: {}'.format(x2.shape))
        x3=operator.mul(x2, 0.458)
        print('x3: {}'.format(x3.shape))
        x4=operator.add(x3, -0.030000000000000027)
        print('x4: {}'.format(x4.shape))
        x5=operator.getitem(x0, (slice(None, None, None), 1))
        print('x5: {}'.format(x5.shape))
        x6=torch.unsqueeze(x5, 1)
        print('x6: {}'.format(x6.shape))
        x7=operator.mul(x6, 0.448)
        print('x7: {}'.format(x7.shape))
        x8=operator.add(x7, -0.08799999999999997)
        print('x8: {}'.format(x8.shape))
        x9=operator.getitem(x0, (slice(None, None, None), 2))
        print('x9: {}'.format(x9.shape))
        x10=torch.unsqueeze(x9, 1)
        print('x10: {}'.format(x10.shape))
        x11=operator.mul(x10, 0.45)
        print('x11: {}'.format(x11.shape))
        x12=operator.add(x11, -0.18799999999999994)
        print('x12: {}'.format(x12.shape))
        x13=torch.cat((x4, x8, x12), 1)
        print('x13: {}'.format(x13.shape))
        x14=self.conv2d0(x13)
        print('x14: {}'.format(x14.shape))
        x15=self.batchnorm2d0(x14)
        print('x15: {}'.format(x15.shape))
        x16=torch.nn.functional.relu(x15,inplace=True)
        print('x16: {}'.format(x16.shape))
        x17=self.maxpool2d0(x16)
        print('x17: {}'.format(x17.shape))
        x18=self.conv2d1(x17)
        print('x18: {}'.format(x18.shape))
        x19=self.batchnorm2d1(x18)
        print('x19: {}'.format(x19.shape))
        x20=torch.nn.functional.relu(x19,inplace=True)
        print('x20: {}'.format(x20.shape))
        x21=self.conv2d2(x20)
        print('x21: {}'.format(x21.shape))
        x22=self.batchnorm2d2(x21)
        print('x22: {}'.format(x22.shape))
        x23=torch.nn.functional.relu(x22,inplace=True)
        print('x23: {}'.format(x23.shape))
        x24=self.maxpool2d1(x23)
        print('x24: {}'.format(x24.shape))
        x25=self.conv2d3(x24)
        print('x25: {}'.format(x25.shape))
        x26=self.batchnorm2d3(x25)
        print('x26: {}'.format(x26.shape))
        x27=torch.nn.functional.relu(x26,inplace=True)
        print('x27: {}'.format(x27.shape))
        x28=self.conv2d4(x24)
        print('x28: {}'.format(x28.shape))
        x29=self.batchnorm2d4(x28)
        print('x29: {}'.format(x29.shape))
        x30=torch.nn.functional.relu(x29,inplace=True)
        print('x30: {}'.format(x30.shape))
        x31=self.conv2d5(x30)
        print('x31: {}'.format(x31.shape))
        x32=self.batchnorm2d5(x31)
        print('x32: {}'.format(x32.shape))
        x33=torch.nn.functional.relu(x32,inplace=True)
        print('x33: {}'.format(x33.shape))
        x34=self.conv2d6(x24)
        print('x34: {}'.format(x34.shape))
        x35=self.batchnorm2d6(x34)
        print('x35: {}'.format(x35.shape))
        x36=torch.nn.functional.relu(x35,inplace=True)
        print('x36: {}'.format(x36.shape))
        x37=self.conv2d7(x36)
        print('x37: {}'.format(x37.shape))
        x38=self.batchnorm2d7(x37)
        print('x38: {}'.format(x38.shape))
        x39=torch.nn.functional.relu(x38,inplace=True)
        print('x39: {}'.format(x39.shape))
        x40=self.maxpool2d2(x24)
        print('x40: {}'.format(x40.shape))
        x41=self.conv2d8(x40)
        print('x41: {}'.format(x41.shape))
        x42=self.batchnorm2d8(x41)
        print('x42: {}'.format(x42.shape))
        x43=torch.nn.functional.relu(x42,inplace=True)
        print('x43: {}'.format(x43.shape))
        x44=torch.cat([x27, x33, x39, x43], 1)
        print('x44: {}'.format(x44.shape))
        x45=self.conv2d9(x44)
        print('x45: {}'.format(x45.shape))
        x46=self.batchnorm2d9(x45)
        print('x46: {}'.format(x46.shape))
        x47=torch.nn.functional.relu(x46,inplace=True)
        print('x47: {}'.format(x47.shape))
        x48=self.conv2d10(x44)
        print('x48: {}'.format(x48.shape))
        x49=self.batchnorm2d10(x48)
        print('x49: {}'.format(x49.shape))
        x50=torch.nn.functional.relu(x49,inplace=True)
        print('x50: {}'.format(x50.shape))
        x51=self.conv2d11(x50)
        print('x51: {}'.format(x51.shape))
        x52=self.batchnorm2d11(x51)
        print('x52: {}'.format(x52.shape))
        x53=torch.nn.functional.relu(x52,inplace=True)
        print('x53: {}'.format(x53.shape))
        x54=self.conv2d12(x44)
        print('x54: {}'.format(x54.shape))
        x55=self.batchnorm2d12(x54)
        print('x55: {}'.format(x55.shape))
        x56=torch.nn.functional.relu(x55,inplace=True)
        print('x56: {}'.format(x56.shape))
        x57=self.conv2d13(x56)
        print('x57: {}'.format(x57.shape))
        x58=self.batchnorm2d13(x57)
        print('x58: {}'.format(x58.shape))
        x59=torch.nn.functional.relu(x58,inplace=True)
        print('x59: {}'.format(x59.shape))
        x60=self.maxpool2d3(x44)
        print('x60: {}'.format(x60.shape))
        x61=self.conv2d14(x60)
        print('x61: {}'.format(x61.shape))
        x62=self.batchnorm2d14(x61)
        print('x62: {}'.format(x62.shape))
        x63=torch.nn.functional.relu(x62,inplace=True)
        print('x63: {}'.format(x63.shape))
        x64=torch.cat([x47, x53, x59, x63], 1)
        print('x64: {}'.format(x64.shape))
        x65=self.maxpool2d4(x64)
        print('x65: {}'.format(x65.shape))
        x66=self.conv2d15(x65)
        print('x66: {}'.format(x66.shape))
        x67=self.batchnorm2d15(x66)
        print('x67: {}'.format(x67.shape))
        x68=torch.nn.functional.relu(x67,inplace=True)
        print('x68: {}'.format(x68.shape))
        x69=self.conv2d16(x65)
        print('x69: {}'.format(x69.shape))
        x70=self.batchnorm2d16(x69)
        print('x70: {}'.format(x70.shape))
        x71=torch.nn.functional.relu(x70,inplace=True)
        print('x71: {}'.format(x71.shape))
        x72=self.conv2d17(x71)
        print('x72: {}'.format(x72.shape))
        x73=self.batchnorm2d17(x72)
        print('x73: {}'.format(x73.shape))
        x74=torch.nn.functional.relu(x73,inplace=True)
        print('x74: {}'.format(x74.shape))
        x75=self.conv2d18(x65)
        print('x75: {}'.format(x75.shape))
        x76=self.batchnorm2d18(x75)
        print('x76: {}'.format(x76.shape))
        x77=torch.nn.functional.relu(x76,inplace=True)
        print('x77: {}'.format(x77.shape))
        x78=self.conv2d19(x77)
        print('x78: {}'.format(x78.shape))
        x79=self.batchnorm2d19(x78)
        print('x79: {}'.format(x79.shape))
        x80=torch.nn.functional.relu(x79,inplace=True)
        print('x80: {}'.format(x80.shape))
        x81=self.maxpool2d5(x65)
        print('x81: {}'.format(x81.shape))
        x82=self.conv2d20(x81)
        print('x82: {}'.format(x82.shape))
        x83=self.batchnorm2d20(x82)
        print('x83: {}'.format(x83.shape))
        x84=torch.nn.functional.relu(x83,inplace=True)
        print('x84: {}'.format(x84.shape))
        x85=torch.cat([x68, x74, x80, x84], 1)
        print('x85: {}'.format(x85.shape))
        x86=self.conv2d21(x85)
        print('x86: {}'.format(x86.shape))
        x87=self.batchnorm2d21(x86)
        print('x87: {}'.format(x87.shape))
        x88=torch.nn.functional.relu(x87,inplace=True)
        print('x88: {}'.format(x88.shape))
        x89=self.conv2d22(x85)
        print('x89: {}'.format(x89.shape))
        x90=self.batchnorm2d22(x89)
        print('x90: {}'.format(x90.shape))
        x91=torch.nn.functional.relu(x90,inplace=True)
        print('x91: {}'.format(x91.shape))
        x92=self.conv2d23(x91)
        print('x92: {}'.format(x92.shape))
        x93=self.batchnorm2d23(x92)
        print('x93: {}'.format(x93.shape))
        x94=torch.nn.functional.relu(x93,inplace=True)
        print('x94: {}'.format(x94.shape))
        x95=self.conv2d24(x85)
        print('x95: {}'.format(x95.shape))
        x96=self.batchnorm2d24(x95)
        print('x96: {}'.format(x96.shape))
        x97=torch.nn.functional.relu(x96,inplace=True)
        print('x97: {}'.format(x97.shape))
        x98=self.conv2d25(x97)
        print('x98: {}'.format(x98.shape))
        x99=self.batchnorm2d25(x98)
        print('x99: {}'.format(x99.shape))
        x100=torch.nn.functional.relu(x99,inplace=True)
        print('x100: {}'.format(x100.shape))
        x101=self.maxpool2d6(x85)
        print('x101: {}'.format(x101.shape))
        x102=self.conv2d26(x101)
        print('x102: {}'.format(x102.shape))
        x103=self.batchnorm2d26(x102)
        print('x103: {}'.format(x103.shape))
        x104=torch.nn.functional.relu(x103,inplace=True)
        print('x104: {}'.format(x104.shape))
        x105=torch.cat([x88, x94, x100, x104], 1)
        print('x105: {}'.format(x105.shape))
        x106=self.conv2d27(x105)
        print('x106: {}'.format(x106.shape))
        x107=self.batchnorm2d27(x106)
        print('x107: {}'.format(x107.shape))
        x108=torch.nn.functional.relu(x107,inplace=True)
        print('x108: {}'.format(x108.shape))
        x109=self.conv2d28(x105)
        print('x109: {}'.format(x109.shape))
        x110=self.batchnorm2d28(x109)
        print('x110: {}'.format(x110.shape))
        x111=torch.nn.functional.relu(x110,inplace=True)
        print('x111: {}'.format(x111.shape))
        x112=self.conv2d29(x111)
        print('x112: {}'.format(x112.shape))
        x113=self.batchnorm2d29(x112)
        print('x113: {}'.format(x113.shape))
        x114=torch.nn.functional.relu(x113,inplace=True)
        print('x114: {}'.format(x114.shape))
        x115=self.conv2d30(x105)
        print('x115: {}'.format(x115.shape))
        x116=self.batchnorm2d30(x115)
        print('x116: {}'.format(x116.shape))
        x117=torch.nn.functional.relu(x116,inplace=True)
        print('x117: {}'.format(x117.shape))
        x118=self.conv2d31(x117)
        print('x118: {}'.format(x118.shape))
        x119=self.batchnorm2d31(x118)
        print('x119: {}'.format(x119.shape))
        x120=torch.nn.functional.relu(x119,inplace=True)
        print('x120: {}'.format(x120.shape))
        x121=self.maxpool2d7(x105)
        print('x121: {}'.format(x121.shape))
        x122=self.conv2d32(x121)
        print('x122: {}'.format(x122.shape))
        x123=self.batchnorm2d32(x122)
        print('x123: {}'.format(x123.shape))
        x124=torch.nn.functional.relu(x123,inplace=True)
        print('x124: {}'.format(x124.shape))
        x125=torch.cat([x108, x114, x120, x124], 1)
        print('x125: {}'.format(x125.shape))
        x126=self.conv2d33(x125)
        print('x126: {}'.format(x126.shape))
        x127=self.batchnorm2d33(x126)
        print('x127: {}'.format(x127.shape))
        x128=torch.nn.functional.relu(x127,inplace=True)
        print('x128: {}'.format(x128.shape))
        x129=self.conv2d34(x125)
        print('x129: {}'.format(x129.shape))
        x130=self.batchnorm2d34(x129)
        print('x130: {}'.format(x130.shape))
        x131=torch.nn.functional.relu(x130,inplace=True)
        print('x131: {}'.format(x131.shape))
        x132=self.conv2d35(x131)
        print('x132: {}'.format(x132.shape))
        x133=self.batchnorm2d35(x132)
        print('x133: {}'.format(x133.shape))
        x134=torch.nn.functional.relu(x133,inplace=True)
        print('x134: {}'.format(x134.shape))
        x135=self.conv2d36(x125)
        print('x135: {}'.format(x135.shape))
        x136=self.batchnorm2d36(x135)
        print('x136: {}'.format(x136.shape))
        x137=torch.nn.functional.relu(x136,inplace=True)
        print('x137: {}'.format(x137.shape))
        x138=self.conv2d37(x137)
        print('x138: {}'.format(x138.shape))
        x139=self.batchnorm2d37(x138)
        print('x139: {}'.format(x139.shape))
        x140=torch.nn.functional.relu(x139,inplace=True)
        print('x140: {}'.format(x140.shape))
        x141=self.maxpool2d8(x125)
        print('x141: {}'.format(x141.shape))
        x142=self.conv2d38(x141)
        print('x142: {}'.format(x142.shape))
        x143=self.batchnorm2d38(x142)
        print('x143: {}'.format(x143.shape))
        x144=torch.nn.functional.relu(x143,inplace=True)
        print('x144: {}'.format(x144.shape))
        x145=torch.cat([x128, x134, x140, x144], 1)
        print('x145: {}'.format(x145.shape))
        x146=self.conv2d39(x145)
        print('x146: {}'.format(x146.shape))
        x147=self.batchnorm2d39(x146)
        print('x147: {}'.format(x147.shape))
        x148=torch.nn.functional.relu(x147,inplace=True)
        print('x148: {}'.format(x148.shape))
        x149=self.conv2d40(x145)
        print('x149: {}'.format(x149.shape))
        x150=self.batchnorm2d40(x149)
        print('x150: {}'.format(x150.shape))
        x151=torch.nn.functional.relu(x150,inplace=True)
        print('x151: {}'.format(x151.shape))
        x152=self.conv2d41(x151)
        print('x152: {}'.format(x152.shape))
        x153=self.batchnorm2d41(x152)
        print('x153: {}'.format(x153.shape))
        x154=torch.nn.functional.relu(x153,inplace=True)
        print('x154: {}'.format(x154.shape))
        x155=self.conv2d42(x145)
        print('x155: {}'.format(x155.shape))
        x156=self.batchnorm2d42(x155)
        print('x156: {}'.format(x156.shape))
        x157=torch.nn.functional.relu(x156,inplace=True)
        print('x157: {}'.format(x157.shape))
        x158=self.conv2d43(x157)
        print('x158: {}'.format(x158.shape))
        x159=self.batchnorm2d43(x158)
        print('x159: {}'.format(x159.shape))
        x160=torch.nn.functional.relu(x159,inplace=True)
        print('x160: {}'.format(x160.shape))
        x161=self.maxpool2d9(x145)
        print('x161: {}'.format(x161.shape))
        x162=self.conv2d44(x161)
        print('x162: {}'.format(x162.shape))
        x163=self.batchnorm2d44(x162)
        print('x163: {}'.format(x163.shape))
        x164=torch.nn.functional.relu(x163,inplace=True)
        print('x164: {}'.format(x164.shape))
        x165=torch.cat([x148, x154, x160, x164], 1)
        print('x165: {}'.format(x165.shape))
        x166=self.maxpool2d10(x165)
        print('x166: {}'.format(x166.shape))
        x167=self.conv2d45(x166)
        print('x167: {}'.format(x167.shape))
        x168=self.batchnorm2d45(x167)
        print('x168: {}'.format(x168.shape))
        x169=torch.nn.functional.relu(x168,inplace=True)
        print('x169: {}'.format(x169.shape))
        x170=self.conv2d46(x166)
        print('x170: {}'.format(x170.shape))
        x171=self.batchnorm2d46(x170)
        print('x171: {}'.format(x171.shape))
        x172=torch.nn.functional.relu(x171,inplace=True)
        print('x172: {}'.format(x172.shape))
        x173=self.conv2d47(x172)
        print('x173: {}'.format(x173.shape))
        x174=self.batchnorm2d47(x173)
        print('x174: {}'.format(x174.shape))
        x175=torch.nn.functional.relu(x174,inplace=True)
        print('x175: {}'.format(x175.shape))
        x176=self.conv2d48(x166)
        print('x176: {}'.format(x176.shape))
        x177=self.batchnorm2d48(x176)
        print('x177: {}'.format(x177.shape))
        x178=torch.nn.functional.relu(x177,inplace=True)
        print('x178: {}'.format(x178.shape))
        x179=self.conv2d49(x178)
        print('x179: {}'.format(x179.shape))
        x180=self.batchnorm2d49(x179)
        print('x180: {}'.format(x180.shape))
        x181=torch.nn.functional.relu(x180,inplace=True)
        print('x181: {}'.format(x181.shape))
        x182=self.maxpool2d11(x166)
        print('x182: {}'.format(x182.shape))
        x183=self.conv2d50(x182)
        print('x183: {}'.format(x183.shape))
        x184=self.batchnorm2d50(x183)
        print('x184: {}'.format(x184.shape))
        x185=torch.nn.functional.relu(x184,inplace=True)
        print('x185: {}'.format(x185.shape))
        x186=torch.cat([x169, x175, x181, x185], 1)
        print('x186: {}'.format(x186.shape))
        x187=self.conv2d51(x186)
        print('x187: {}'.format(x187.shape))
        x188=self.batchnorm2d51(x187)
        print('x188: {}'.format(x188.shape))
        x189=torch.nn.functional.relu(x188,inplace=True)
        print('x189: {}'.format(x189.shape))
        x190=self.conv2d52(x186)
        print('x190: {}'.format(x190.shape))
        x191=self.batchnorm2d52(x190)
        print('x191: {}'.format(x191.shape))
        x192=torch.nn.functional.relu(x191,inplace=True)
        print('x192: {}'.format(x192.shape))
        x193=self.conv2d53(x192)
        print('x193: {}'.format(x193.shape))
        x194=self.batchnorm2d53(x193)
        print('x194: {}'.format(x194.shape))
        x195=torch.nn.functional.relu(x194,inplace=True)
        print('x195: {}'.format(x195.shape))
        x196=self.conv2d54(x186)
        print('x196: {}'.format(x196.shape))
        x197=self.batchnorm2d54(x196)
        print('x197: {}'.format(x197.shape))
        x198=torch.nn.functional.relu(x197,inplace=True)
        print('x198: {}'.format(x198.shape))
        x199=self.conv2d55(x198)
        print('x199: {}'.format(x199.shape))
        x200=self.batchnorm2d55(x199)
        print('x200: {}'.format(x200.shape))
        x201=torch.nn.functional.relu(x200,inplace=True)
        print('x201: {}'.format(x201.shape))
        x202=self.maxpool2d12(x186)
        print('x202: {}'.format(x202.shape))
        x203=self.conv2d56(x202)
        print('x203: {}'.format(x203.shape))
        x204=self.batchnorm2d56(x203)
        print('x204: {}'.format(x204.shape))
        x205=torch.nn.functional.relu(x204,inplace=True)
        print('x205: {}'.format(x205.shape))
        x206=torch.cat([x189, x195, x201, x205], 1)
        print('x206: {}'.format(x206.shape))
        x207=self.adaptiveavgpool2d0(x206)
        print('x207: {}'.format(x207.shape))
        x208=torch.flatten(x207, 1)
        print('x208: {}'.format(x208.shape))
        x209=self.dropout0(x208)
        print('x209: {}'.format(x209.shape))
        x210=self.linear0(x209)
        print('x210: {}'.format(x210.shape))

m = M().eval()
CORES=os.popen("lscpu | grep Core | awk '{print $4}'").readlines()
SOCKETS=os.popen("lscpu | grep Socket | awk '{print $2}'").readlines()
BS=int(CORES[0])*int(SOCKETS[0])
batch_size=BS
x = torch.randn(batch_size, 3, 224, 224)
start_time=time.time()
for i in range(10):
    output = m(x)
total_iter_time = time.time() - start_time
Throughput = batch_size * 10 / total_iter_time
file_current = os.path.basename(__file__)
print(file_current,',',BS,',',Throughput) 
