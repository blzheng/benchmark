import torch
from torch import tensor
import torch.nn as nn
from torch.nn import *
import torchvision
import torchvision.models as models
from torchvision.ops.stochastic_depth import stochastic_depth
import time
import builtins
import operator

class M(torch.nn.Module):
    def __init__(self):
        super(M, self).__init__()
        self.conv2d0 = Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
        self.conv2d1 = Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        self.layernorm0 = LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        self.linear0 = Linear(in_features=128, out_features=512, bias=True)
        self.gelu0 = GELU(approximate='none')
        self.linear1 = Linear(in_features=512, out_features=128, bias=True)
        self.conv2d2 = Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        self.layernorm1 = LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        self.linear2 = Linear(in_features=128, out_features=512, bias=True)
        self.gelu1 = GELU(approximate='none')
        self.linear3 = Linear(in_features=512, out_features=128, bias=True)
        self.conv2d3 = Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        self.layernorm2 = LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        self.linear4 = Linear(in_features=128, out_features=512, bias=True)
        self.gelu2 = GELU(approximate='none')
        self.linear5 = Linear(in_features=512, out_features=128, bias=True)
        self.conv2d4 = Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
        self.conv2d5 = Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        self.layernorm3 = LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        self.linear6 = Linear(in_features=256, out_features=1024, bias=True)
        self.gelu3 = GELU(approximate='none')
        self.linear7 = Linear(in_features=1024, out_features=256, bias=True)
        self.conv2d6 = Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        self.layernorm4 = LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        self.linear8 = Linear(in_features=256, out_features=1024, bias=True)
        self.gelu4 = GELU(approximate='none')
        self.linear9 = Linear(in_features=1024, out_features=256, bias=True)
        self.conv2d7 = Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        self.layernorm5 = LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        self.linear10 = Linear(in_features=256, out_features=1024, bias=True)
        self.gelu5 = GELU(approximate='none')
        self.linear11 = Linear(in_features=1024, out_features=256, bias=True)
        self.conv2d8 = Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
        self.conv2d9 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm6 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear12 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu6 = GELU(approximate='none')
        self.linear13 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d10 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm7 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear14 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu7 = GELU(approximate='none')
        self.linear15 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d11 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm8 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear16 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu8 = GELU(approximate='none')
        self.linear17 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d12 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm9 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear18 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu9 = GELU(approximate='none')
        self.linear19 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d13 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm10 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear20 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu10 = GELU(approximate='none')
        self.linear21 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d14 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm11 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear22 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu11 = GELU(approximate='none')
        self.linear23 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d15 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm12 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear24 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu12 = GELU(approximate='none')
        self.linear25 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d16 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm13 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear26 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu13 = GELU(approximate='none')
        self.linear27 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d17 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm14 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear28 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu14 = GELU(approximate='none')
        self.linear29 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d18 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm15 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear30 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu15 = GELU(approximate='none')
        self.linear31 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d19 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm16 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear32 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu16 = GELU(approximate='none')
        self.linear33 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d20 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm17 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear34 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu17 = GELU(approximate='none')
        self.linear35 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d21 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm18 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear36 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu18 = GELU(approximate='none')
        self.linear37 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d22 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm19 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear38 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu19 = GELU(approximate='none')
        self.linear39 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d23 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm20 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear40 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu20 = GELU(approximate='none')
        self.linear41 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d24 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm21 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear42 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu21 = GELU(approximate='none')
        self.linear43 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d25 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm22 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear44 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu22 = GELU(approximate='none')
        self.linear45 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d26 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm23 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear46 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu23 = GELU(approximate='none')
        self.linear47 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d27 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm24 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear48 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu24 = GELU(approximate='none')
        self.linear49 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d28 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm25 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear50 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu25 = GELU(approximate='none')
        self.linear51 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d29 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm26 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear52 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu26 = GELU(approximate='none')
        self.linear53 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d30 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm27 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear54 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu27 = GELU(approximate='none')
        self.linear55 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d31 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm28 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear56 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu28 = GELU(approximate='none')
        self.linear57 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d32 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm29 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear58 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu29 = GELU(approximate='none')
        self.linear59 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d33 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm30 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear60 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu30 = GELU(approximate='none')
        self.linear61 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d34 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm31 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear62 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu31 = GELU(approximate='none')
        self.linear63 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d35 = Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        self.layernorm32 = LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        self.linear64 = Linear(in_features=512, out_features=2048, bias=True)
        self.gelu32 = GELU(approximate='none')
        self.linear65 = Linear(in_features=2048, out_features=512, bias=True)
        self.conv2d36 = Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
        self.conv2d37 = Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        self.layernorm33 = LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        self.linear66 = Linear(in_features=1024, out_features=4096, bias=True)
        self.gelu33 = GELU(approximate='none')
        self.linear67 = Linear(in_features=4096, out_features=1024, bias=True)
        self.conv2d38 = Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        self.layernorm34 = LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        self.linear68 = Linear(in_features=1024, out_features=4096, bias=True)
        self.gelu34 = GELU(approximate='none')
        self.linear69 = Linear(in_features=4096, out_features=1024, bias=True)
        self.conv2d39 = Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        self.layernorm35 = LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        self.linear70 = Linear(in_features=1024, out_features=4096, bias=True)
        self.gelu35 = GELU(approximate='none')
        self.linear71 = Linear(in_features=4096, out_features=1024, bias=True)
        self.adaptiveavgpool2d0 = AdaptiveAvgPool2d(output_size=1)
        self.flatten0 = Flatten(start_dim=1, end_dim=-1)
        self.linear72 = Linear(in_features=1024, out_features=1000, bias=True)
        self.weight0 = torch.rand(torch.Size([128])).to(torch.float32)
        self.bias0 = torch.rand(torch.Size([128])).to(torch.float32)
        self.layer_scale0 = torch.rand(torch.Size([128, 1, 1])).to(torch.float32)
        self.layer_scale1 = torch.rand(torch.Size([128, 1, 1])).to(torch.float32)
        self.layer_scale2 = torch.rand(torch.Size([128, 1, 1])).to(torch.float32)
        self.weight1 = torch.rand(torch.Size([128])).to(torch.float32)
        self.bias1 = torch.rand(torch.Size([128])).to(torch.float32)
        self.layer_scale3 = torch.rand(torch.Size([256, 1, 1])).to(torch.float32)
        self.layer_scale4 = torch.rand(torch.Size([256, 1, 1])).to(torch.float32)
        self.layer_scale5 = torch.rand(torch.Size([256, 1, 1])).to(torch.float32)
        self.weight2 = torch.rand(torch.Size([256])).to(torch.float32)
        self.bias2 = torch.rand(torch.Size([256])).to(torch.float32)
        self.layer_scale6 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale7 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale8 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale9 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale10 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale11 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale12 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale13 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale14 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale15 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale16 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale17 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale18 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale19 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale20 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale21 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale22 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale23 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale24 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale25 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale26 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale27 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale28 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale29 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale30 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale31 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.layer_scale32 = torch.rand(torch.Size([512, 1, 1])).to(torch.float32)
        self.weight3 = torch.rand(torch.Size([512])).to(torch.float32)
        self.bias3 = torch.rand(torch.Size([512])).to(torch.float32)
        self.layer_scale33 = torch.rand(torch.Size([1024, 1, 1])).to(torch.float32)
        self.layer_scale34 = torch.rand(torch.Size([1024, 1, 1])).to(torch.float32)
        self.layer_scale35 = torch.rand(torch.Size([1024, 1, 1])).to(torch.float32)
        self.weight4 = torch.rand(torch.Size([1024])).to(torch.float32)
        self.bias4 = torch.rand(torch.Size([1024])).to(torch.float32)

    def forward(self, x):
        x0=x
        print('x0: {}'.format(x0.shape))
        x1=self.conv2d0(x0)
        print('x1: {}'.format(x1.shape))
        x2=x1.permute(0, 2, 3, 1)
        print('x2: {}'.format(x2.shape))
        x5=torch.nn.functional.layer_norm(x2, (128,),weight=self.weight0, bias=self.bias0, eps=1e-06)
        print('x5: {}'.format(x5.shape))
        x6=x5.permute(0, 3, 1, 2)
        print('x6: {}'.format(x6.shape))
        x8=self.conv2d1(x6)
        print('x8: {}'.format(x8.shape))
        x9=torch.permute(x8, [0, 2, 3, 1])
        print('x9: {}'.format(x9.shape))
        x10=self.layernorm0(x9)
        print('x10: {}'.format(x10.shape))
        x11=self.linear0(x10)
        print('x11: {}'.format(x11.shape))
        x12=self.gelu0(x11)
        print('x12: {}'.format(x12.shape))
        x13=self.linear1(x12)
        print('x13: {}'.format(x13.shape))
        x14=torch.permute(x13, [0, 3, 1, 2])
        print('x14: {}'.format(x14.shape))
        x15=operator.mul(self.layer_scale0, x14)
        print('x15: {}'.format(x15.shape))
        x16=stochastic_depth(x15, 0.0, 'row', False)
        print('x16: {}'.format(x16.shape))
        x17=operator.add(x16, x6)
        print('x17: {}'.format(x17.shape))
        x19=self.conv2d2(x17)
        print('x19: {}'.format(x19.shape))
        x20=torch.permute(x19, [0, 2, 3, 1])
        print('x20: {}'.format(x20.shape))
        x21=self.layernorm1(x20)
        print('x21: {}'.format(x21.shape))
        x22=self.linear2(x21)
        print('x22: {}'.format(x22.shape))
        x23=self.gelu1(x22)
        print('x23: {}'.format(x23.shape))
        x24=self.linear3(x23)
        print('x24: {}'.format(x24.shape))
        x25=torch.permute(x24, [0, 3, 1, 2])
        print('x25: {}'.format(x25.shape))
        x26=operator.mul(self.layer_scale1, x25)
        print('x26: {}'.format(x26.shape))
        x27=stochastic_depth(x26, 0.014285714285714285, 'row', False)
        print('x27: {}'.format(x27.shape))
        x28=operator.add(x27, x17)
        print('x28: {}'.format(x28.shape))
        x30=self.conv2d3(x28)
        print('x30: {}'.format(x30.shape))
        x31=torch.permute(x30, [0, 2, 3, 1])
        print('x31: {}'.format(x31.shape))
        x32=self.layernorm2(x31)
        print('x32: {}'.format(x32.shape))
        x33=self.linear4(x32)
        print('x33: {}'.format(x33.shape))
        x34=self.gelu2(x33)
        print('x34: {}'.format(x34.shape))
        x35=self.linear5(x34)
        print('x35: {}'.format(x35.shape))
        x36=torch.permute(x35, [0, 3, 1, 2])
        print('x36: {}'.format(x36.shape))
        x37=operator.mul(self.layer_scale2, x36)
        print('x37: {}'.format(x37.shape))
        x38=stochastic_depth(x37, 0.02857142857142857, 'row', False)
        print('x38: {}'.format(x38.shape))
        x39=operator.add(x38, x28)
        print('x39: {}'.format(x39.shape))
        x40=x39.permute(0, 2, 3, 1)
        print('x40: {}'.format(x40.shape))
        x43=torch.nn.functional.layer_norm(x40, (128,),weight=self.weight1, bias=self.bias1, eps=1e-06)
        print('x43: {}'.format(x43.shape))
        x44=x43.permute(0, 3, 1, 2)
        print('x44: {}'.format(x44.shape))
        x45=self.conv2d4(x44)
        print('x45: {}'.format(x45.shape))
        x47=self.conv2d5(x45)
        print('x47: {}'.format(x47.shape))
        x48=torch.permute(x47, [0, 2, 3, 1])
        print('x48: {}'.format(x48.shape))
        x49=self.layernorm3(x48)
        print('x49: {}'.format(x49.shape))
        x50=self.linear6(x49)
        print('x50: {}'.format(x50.shape))
        x51=self.gelu3(x50)
        print('x51: {}'.format(x51.shape))
        x52=self.linear7(x51)
        print('x52: {}'.format(x52.shape))
        x53=torch.permute(x52, [0, 3, 1, 2])
        print('x53: {}'.format(x53.shape))
        x54=operator.mul(self.layer_scale3, x53)
        print('x54: {}'.format(x54.shape))
        x55=stochastic_depth(x54, 0.04285714285714286, 'row', False)
        print('x55: {}'.format(x55.shape))
        x56=operator.add(x55, x45)
        print('x56: {}'.format(x56.shape))
        x58=self.conv2d6(x56)
        print('x58: {}'.format(x58.shape))
        x59=torch.permute(x58, [0, 2, 3, 1])
        print('x59: {}'.format(x59.shape))
        x60=self.layernorm4(x59)
        print('x60: {}'.format(x60.shape))
        x61=self.linear8(x60)
        print('x61: {}'.format(x61.shape))
        x62=self.gelu4(x61)
        print('x62: {}'.format(x62.shape))
        x63=self.linear9(x62)
        print('x63: {}'.format(x63.shape))
        x64=torch.permute(x63, [0, 3, 1, 2])
        print('x64: {}'.format(x64.shape))
        x65=operator.mul(self.layer_scale4, x64)
        print('x65: {}'.format(x65.shape))
        x66=stochastic_depth(x65, 0.05714285714285714, 'row', False)
        print('x66: {}'.format(x66.shape))
        x67=operator.add(x66, x56)
        print('x67: {}'.format(x67.shape))
        x69=self.conv2d7(x67)
        print('x69: {}'.format(x69.shape))
        x70=torch.permute(x69, [0, 2, 3, 1])
        print('x70: {}'.format(x70.shape))
        x71=self.layernorm5(x70)
        print('x71: {}'.format(x71.shape))
        x72=self.linear10(x71)
        print('x72: {}'.format(x72.shape))
        x73=self.gelu5(x72)
        print('x73: {}'.format(x73.shape))
        x74=self.linear11(x73)
        print('x74: {}'.format(x74.shape))
        x75=torch.permute(x74, [0, 3, 1, 2])
        print('x75: {}'.format(x75.shape))
        x76=operator.mul(self.layer_scale5, x75)
        print('x76: {}'.format(x76.shape))
        x77=stochastic_depth(x76, 0.07142857142857142, 'row', False)
        print('x77: {}'.format(x77.shape))
        x78=operator.add(x77, x67)
        print('x78: {}'.format(x78.shape))
        x79=x78.permute(0, 2, 3, 1)
        print('x79: {}'.format(x79.shape))
        x82=torch.nn.functional.layer_norm(x79, (256,),weight=self.weight2, bias=self.bias2, eps=1e-06)
        print('x82: {}'.format(x82.shape))
        x83=x82.permute(0, 3, 1, 2)
        print('x83: {}'.format(x83.shape))
        x84=self.conv2d8(x83)
        print('x84: {}'.format(x84.shape))
        x86=self.conv2d9(x84)
        print('x86: {}'.format(x86.shape))
        x87=torch.permute(x86, [0, 2, 3, 1])
        print('x87: {}'.format(x87.shape))
        x88=self.layernorm6(x87)
        print('x88: {}'.format(x88.shape))
        x89=self.linear12(x88)
        print('x89: {}'.format(x89.shape))
        x90=self.gelu6(x89)
        print('x90: {}'.format(x90.shape))
        x91=self.linear13(x90)
        print('x91: {}'.format(x91.shape))
        x92=torch.permute(x91, [0, 3, 1, 2])
        print('x92: {}'.format(x92.shape))
        x93=operator.mul(self.layer_scale6, x92)
        print('x93: {}'.format(x93.shape))
        x94=stochastic_depth(x93, 0.08571428571428572, 'row', False)
        print('x94: {}'.format(x94.shape))
        x95=operator.add(x94, x84)
        print('x95: {}'.format(x95.shape))
        x97=self.conv2d10(x95)
        print('x97: {}'.format(x97.shape))
        x98=torch.permute(x97, [0, 2, 3, 1])
        print('x98: {}'.format(x98.shape))
        x99=self.layernorm7(x98)
        print('x99: {}'.format(x99.shape))
        x100=self.linear14(x99)
        print('x100: {}'.format(x100.shape))
        x101=self.gelu7(x100)
        print('x101: {}'.format(x101.shape))
        x102=self.linear15(x101)
        print('x102: {}'.format(x102.shape))
        x103=torch.permute(x102, [0, 3, 1, 2])
        print('x103: {}'.format(x103.shape))
        x104=operator.mul(self.layer_scale7, x103)
        print('x104: {}'.format(x104.shape))
        x105=stochastic_depth(x104, 0.1, 'row', False)
        print('x105: {}'.format(x105.shape))
        x106=operator.add(x105, x95)
        print('x106: {}'.format(x106.shape))
        x108=self.conv2d11(x106)
        print('x108: {}'.format(x108.shape))
        x109=torch.permute(x108, [0, 2, 3, 1])
        print('x109: {}'.format(x109.shape))
        x110=self.layernorm8(x109)
        print('x110: {}'.format(x110.shape))
        x111=self.linear16(x110)
        print('x111: {}'.format(x111.shape))
        x112=self.gelu8(x111)
        print('x112: {}'.format(x112.shape))
        x113=self.linear17(x112)
        print('x113: {}'.format(x113.shape))
        x114=torch.permute(x113, [0, 3, 1, 2])
        print('x114: {}'.format(x114.shape))
        x115=operator.mul(self.layer_scale8, x114)
        print('x115: {}'.format(x115.shape))
        x116=stochastic_depth(x115, 0.11428571428571428, 'row', False)
        print('x116: {}'.format(x116.shape))
        x117=operator.add(x116, x106)
        print('x117: {}'.format(x117.shape))
        x119=self.conv2d12(x117)
        print('x119: {}'.format(x119.shape))
        x120=torch.permute(x119, [0, 2, 3, 1])
        print('x120: {}'.format(x120.shape))
        x121=self.layernorm9(x120)
        print('x121: {}'.format(x121.shape))
        x122=self.linear18(x121)
        print('x122: {}'.format(x122.shape))
        x123=self.gelu9(x122)
        print('x123: {}'.format(x123.shape))
        x124=self.linear19(x123)
        print('x124: {}'.format(x124.shape))
        x125=torch.permute(x124, [0, 3, 1, 2])
        print('x125: {}'.format(x125.shape))
        x126=operator.mul(self.layer_scale9, x125)
        print('x126: {}'.format(x126.shape))
        x127=stochastic_depth(x126, 0.12857142857142856, 'row', False)
        print('x127: {}'.format(x127.shape))
        x128=operator.add(x127, x117)
        print('x128: {}'.format(x128.shape))
        x130=self.conv2d13(x128)
        print('x130: {}'.format(x130.shape))
        x131=torch.permute(x130, [0, 2, 3, 1])
        print('x131: {}'.format(x131.shape))
        x132=self.layernorm10(x131)
        print('x132: {}'.format(x132.shape))
        x133=self.linear20(x132)
        print('x133: {}'.format(x133.shape))
        x134=self.gelu10(x133)
        print('x134: {}'.format(x134.shape))
        x135=self.linear21(x134)
        print('x135: {}'.format(x135.shape))
        x136=torch.permute(x135, [0, 3, 1, 2])
        print('x136: {}'.format(x136.shape))
        x137=operator.mul(self.layer_scale10, x136)
        print('x137: {}'.format(x137.shape))
        x138=stochastic_depth(x137, 0.14285714285714285, 'row', False)
        print('x138: {}'.format(x138.shape))
        x139=operator.add(x138, x128)
        print('x139: {}'.format(x139.shape))
        x141=self.conv2d14(x139)
        print('x141: {}'.format(x141.shape))
        x142=torch.permute(x141, [0, 2, 3, 1])
        print('x142: {}'.format(x142.shape))
        x143=self.layernorm11(x142)
        print('x143: {}'.format(x143.shape))
        x144=self.linear22(x143)
        print('x144: {}'.format(x144.shape))
        x145=self.gelu11(x144)
        print('x145: {}'.format(x145.shape))
        x146=self.linear23(x145)
        print('x146: {}'.format(x146.shape))
        x147=torch.permute(x146, [0, 3, 1, 2])
        print('x147: {}'.format(x147.shape))
        x148=operator.mul(self.layer_scale11, x147)
        print('x148: {}'.format(x148.shape))
        x149=stochastic_depth(x148, 0.15714285714285714, 'row', False)
        print('x149: {}'.format(x149.shape))
        x150=operator.add(x149, x139)
        print('x150: {}'.format(x150.shape))
        x152=self.conv2d15(x150)
        print('x152: {}'.format(x152.shape))
        x153=torch.permute(x152, [0, 2, 3, 1])
        print('x153: {}'.format(x153.shape))
        x154=self.layernorm12(x153)
        print('x154: {}'.format(x154.shape))
        x155=self.linear24(x154)
        print('x155: {}'.format(x155.shape))
        x156=self.gelu12(x155)
        print('x156: {}'.format(x156.shape))
        x157=self.linear25(x156)
        print('x157: {}'.format(x157.shape))
        x158=torch.permute(x157, [0, 3, 1, 2])
        print('x158: {}'.format(x158.shape))
        x159=operator.mul(self.layer_scale12, x158)
        print('x159: {}'.format(x159.shape))
        x160=stochastic_depth(x159, 0.17142857142857143, 'row', False)
        print('x160: {}'.format(x160.shape))
        x161=operator.add(x160, x150)
        print('x161: {}'.format(x161.shape))
        x163=self.conv2d16(x161)
        print('x163: {}'.format(x163.shape))
        x164=torch.permute(x163, [0, 2, 3, 1])
        print('x164: {}'.format(x164.shape))
        x165=self.layernorm13(x164)
        print('x165: {}'.format(x165.shape))
        x166=self.linear26(x165)
        print('x166: {}'.format(x166.shape))
        x167=self.gelu13(x166)
        print('x167: {}'.format(x167.shape))
        x168=self.linear27(x167)
        print('x168: {}'.format(x168.shape))
        x169=torch.permute(x168, [0, 3, 1, 2])
        print('x169: {}'.format(x169.shape))
        x170=operator.mul(self.layer_scale13, x169)
        print('x170: {}'.format(x170.shape))
        x171=stochastic_depth(x170, 0.18571428571428572, 'row', False)
        print('x171: {}'.format(x171.shape))
        x172=operator.add(x171, x161)
        print('x172: {}'.format(x172.shape))
        x174=self.conv2d17(x172)
        print('x174: {}'.format(x174.shape))
        x175=torch.permute(x174, [0, 2, 3, 1])
        print('x175: {}'.format(x175.shape))
        x176=self.layernorm14(x175)
        print('x176: {}'.format(x176.shape))
        x177=self.linear28(x176)
        print('x177: {}'.format(x177.shape))
        x178=self.gelu14(x177)
        print('x178: {}'.format(x178.shape))
        x179=self.linear29(x178)
        print('x179: {}'.format(x179.shape))
        x180=torch.permute(x179, [0, 3, 1, 2])
        print('x180: {}'.format(x180.shape))
        x181=operator.mul(self.layer_scale14, x180)
        print('x181: {}'.format(x181.shape))
        x182=stochastic_depth(x181, 0.2, 'row', False)
        print('x182: {}'.format(x182.shape))
        x183=operator.add(x182, x172)
        print('x183: {}'.format(x183.shape))
        x185=self.conv2d18(x183)
        print('x185: {}'.format(x185.shape))
        x186=torch.permute(x185, [0, 2, 3, 1])
        print('x186: {}'.format(x186.shape))
        x187=self.layernorm15(x186)
        print('x187: {}'.format(x187.shape))
        x188=self.linear30(x187)
        print('x188: {}'.format(x188.shape))
        x189=self.gelu15(x188)
        print('x189: {}'.format(x189.shape))
        x190=self.linear31(x189)
        print('x190: {}'.format(x190.shape))
        x191=torch.permute(x190, [0, 3, 1, 2])
        print('x191: {}'.format(x191.shape))
        x192=operator.mul(self.layer_scale15, x191)
        print('x192: {}'.format(x192.shape))
        x193=stochastic_depth(x192, 0.21428571428571427, 'row', False)
        print('x193: {}'.format(x193.shape))
        x194=operator.add(x193, x183)
        print('x194: {}'.format(x194.shape))
        x196=self.conv2d19(x194)
        print('x196: {}'.format(x196.shape))
        x197=torch.permute(x196, [0, 2, 3, 1])
        print('x197: {}'.format(x197.shape))
        x198=self.layernorm16(x197)
        print('x198: {}'.format(x198.shape))
        x199=self.linear32(x198)
        print('x199: {}'.format(x199.shape))
        x200=self.gelu16(x199)
        print('x200: {}'.format(x200.shape))
        x201=self.linear33(x200)
        print('x201: {}'.format(x201.shape))
        x202=torch.permute(x201, [0, 3, 1, 2])
        print('x202: {}'.format(x202.shape))
        x203=operator.mul(self.layer_scale16, x202)
        print('x203: {}'.format(x203.shape))
        x204=stochastic_depth(x203, 0.22857142857142856, 'row', False)
        print('x204: {}'.format(x204.shape))
        x205=operator.add(x204, x194)
        print('x205: {}'.format(x205.shape))
        x207=self.conv2d20(x205)
        print('x207: {}'.format(x207.shape))
        x208=torch.permute(x207, [0, 2, 3, 1])
        print('x208: {}'.format(x208.shape))
        x209=self.layernorm17(x208)
        print('x209: {}'.format(x209.shape))
        x210=self.linear34(x209)
        print('x210: {}'.format(x210.shape))
        x211=self.gelu17(x210)
        print('x211: {}'.format(x211.shape))
        x212=self.linear35(x211)
        print('x212: {}'.format(x212.shape))
        x213=torch.permute(x212, [0, 3, 1, 2])
        print('x213: {}'.format(x213.shape))
        x214=operator.mul(self.layer_scale17, x213)
        print('x214: {}'.format(x214.shape))
        x215=stochastic_depth(x214, 0.24285714285714285, 'row', False)
        print('x215: {}'.format(x215.shape))
        x216=operator.add(x215, x205)
        print('x216: {}'.format(x216.shape))
        x218=self.conv2d21(x216)
        print('x218: {}'.format(x218.shape))
        x219=torch.permute(x218, [0, 2, 3, 1])
        print('x219: {}'.format(x219.shape))
        x220=self.layernorm18(x219)
        print('x220: {}'.format(x220.shape))
        x221=self.linear36(x220)
        print('x221: {}'.format(x221.shape))
        x222=self.gelu18(x221)
        print('x222: {}'.format(x222.shape))
        x223=self.linear37(x222)
        print('x223: {}'.format(x223.shape))
        x224=torch.permute(x223, [0, 3, 1, 2])
        print('x224: {}'.format(x224.shape))
        x225=operator.mul(self.layer_scale18, x224)
        print('x225: {}'.format(x225.shape))
        x226=stochastic_depth(x225, 0.2571428571428571, 'row', False)
        print('x226: {}'.format(x226.shape))
        x227=operator.add(x226, x216)
        print('x227: {}'.format(x227.shape))
        x229=self.conv2d22(x227)
        print('x229: {}'.format(x229.shape))
        x230=torch.permute(x229, [0, 2, 3, 1])
        print('x230: {}'.format(x230.shape))
        x231=self.layernorm19(x230)
        print('x231: {}'.format(x231.shape))
        x232=self.linear38(x231)
        print('x232: {}'.format(x232.shape))
        x233=self.gelu19(x232)
        print('x233: {}'.format(x233.shape))
        x234=self.linear39(x233)
        print('x234: {}'.format(x234.shape))
        x235=torch.permute(x234, [0, 3, 1, 2])
        print('x235: {}'.format(x235.shape))
        x236=operator.mul(self.layer_scale19, x235)
        print('x236: {}'.format(x236.shape))
        x237=stochastic_depth(x236, 0.2714285714285714, 'row', False)
        print('x237: {}'.format(x237.shape))
        x238=operator.add(x237, x227)
        print('x238: {}'.format(x238.shape))
        x240=self.conv2d23(x238)
        print('x240: {}'.format(x240.shape))
        x241=torch.permute(x240, [0, 2, 3, 1])
        print('x241: {}'.format(x241.shape))
        x242=self.layernorm20(x241)
        print('x242: {}'.format(x242.shape))
        x243=self.linear40(x242)
        print('x243: {}'.format(x243.shape))
        x244=self.gelu20(x243)
        print('x244: {}'.format(x244.shape))
        x245=self.linear41(x244)
        print('x245: {}'.format(x245.shape))
        x246=torch.permute(x245, [0, 3, 1, 2])
        print('x246: {}'.format(x246.shape))
        x247=operator.mul(self.layer_scale20, x246)
        print('x247: {}'.format(x247.shape))
        x248=stochastic_depth(x247, 0.2857142857142857, 'row', False)
        print('x248: {}'.format(x248.shape))
        x249=operator.add(x248, x238)
        print('x249: {}'.format(x249.shape))
        x251=self.conv2d24(x249)
        print('x251: {}'.format(x251.shape))
        x252=torch.permute(x251, [0, 2, 3, 1])
        print('x252: {}'.format(x252.shape))
        x253=self.layernorm21(x252)
        print('x253: {}'.format(x253.shape))
        x254=self.linear42(x253)
        print('x254: {}'.format(x254.shape))
        x255=self.gelu21(x254)
        print('x255: {}'.format(x255.shape))
        x256=self.linear43(x255)
        print('x256: {}'.format(x256.shape))
        x257=torch.permute(x256, [0, 3, 1, 2])
        print('x257: {}'.format(x257.shape))
        x258=operator.mul(self.layer_scale21, x257)
        print('x258: {}'.format(x258.shape))
        x259=stochastic_depth(x258, 0.3, 'row', False)
        print('x259: {}'.format(x259.shape))
        x260=operator.add(x259, x249)
        print('x260: {}'.format(x260.shape))
        x262=self.conv2d25(x260)
        print('x262: {}'.format(x262.shape))
        x263=torch.permute(x262, [0, 2, 3, 1])
        print('x263: {}'.format(x263.shape))
        x264=self.layernorm22(x263)
        print('x264: {}'.format(x264.shape))
        x265=self.linear44(x264)
        print('x265: {}'.format(x265.shape))
        x266=self.gelu22(x265)
        print('x266: {}'.format(x266.shape))
        x267=self.linear45(x266)
        print('x267: {}'.format(x267.shape))
        x268=torch.permute(x267, [0, 3, 1, 2])
        print('x268: {}'.format(x268.shape))
        x269=operator.mul(self.layer_scale22, x268)
        print('x269: {}'.format(x269.shape))
        x270=stochastic_depth(x269, 0.3142857142857143, 'row', False)
        print('x270: {}'.format(x270.shape))
        x271=operator.add(x270, x260)
        print('x271: {}'.format(x271.shape))
        x273=self.conv2d26(x271)
        print('x273: {}'.format(x273.shape))
        x274=torch.permute(x273, [0, 2, 3, 1])
        print('x274: {}'.format(x274.shape))
        x275=self.layernorm23(x274)
        print('x275: {}'.format(x275.shape))
        x276=self.linear46(x275)
        print('x276: {}'.format(x276.shape))
        x277=self.gelu23(x276)
        print('x277: {}'.format(x277.shape))
        x278=self.linear47(x277)
        print('x278: {}'.format(x278.shape))
        x279=torch.permute(x278, [0, 3, 1, 2])
        print('x279: {}'.format(x279.shape))
        x280=operator.mul(self.layer_scale23, x279)
        print('x280: {}'.format(x280.shape))
        x281=stochastic_depth(x280, 0.32857142857142857, 'row', False)
        print('x281: {}'.format(x281.shape))
        x282=operator.add(x281, x271)
        print('x282: {}'.format(x282.shape))
        x284=self.conv2d27(x282)
        print('x284: {}'.format(x284.shape))
        x285=torch.permute(x284, [0, 2, 3, 1])
        print('x285: {}'.format(x285.shape))
        x286=self.layernorm24(x285)
        print('x286: {}'.format(x286.shape))
        x287=self.linear48(x286)
        print('x287: {}'.format(x287.shape))
        x288=self.gelu24(x287)
        print('x288: {}'.format(x288.shape))
        x289=self.linear49(x288)
        print('x289: {}'.format(x289.shape))
        x290=torch.permute(x289, [0, 3, 1, 2])
        print('x290: {}'.format(x290.shape))
        x291=operator.mul(self.layer_scale24, x290)
        print('x291: {}'.format(x291.shape))
        x292=stochastic_depth(x291, 0.34285714285714286, 'row', False)
        print('x292: {}'.format(x292.shape))
        x293=operator.add(x292, x282)
        print('x293: {}'.format(x293.shape))
        x295=self.conv2d28(x293)
        print('x295: {}'.format(x295.shape))
        x296=torch.permute(x295, [0, 2, 3, 1])
        print('x296: {}'.format(x296.shape))
        x297=self.layernorm25(x296)
        print('x297: {}'.format(x297.shape))
        x298=self.linear50(x297)
        print('x298: {}'.format(x298.shape))
        x299=self.gelu25(x298)
        print('x299: {}'.format(x299.shape))
        x300=self.linear51(x299)
        print('x300: {}'.format(x300.shape))
        x301=torch.permute(x300, [0, 3, 1, 2])
        print('x301: {}'.format(x301.shape))
        x302=operator.mul(self.layer_scale25, x301)
        print('x302: {}'.format(x302.shape))
        x303=stochastic_depth(x302, 0.35714285714285715, 'row', False)
        print('x303: {}'.format(x303.shape))
        x304=operator.add(x303, x293)
        print('x304: {}'.format(x304.shape))
        x306=self.conv2d29(x304)
        print('x306: {}'.format(x306.shape))
        x307=torch.permute(x306, [0, 2, 3, 1])
        print('x307: {}'.format(x307.shape))
        x308=self.layernorm26(x307)
        print('x308: {}'.format(x308.shape))
        x309=self.linear52(x308)
        print('x309: {}'.format(x309.shape))
        x310=self.gelu26(x309)
        print('x310: {}'.format(x310.shape))
        x311=self.linear53(x310)
        print('x311: {}'.format(x311.shape))
        x312=torch.permute(x311, [0, 3, 1, 2])
        print('x312: {}'.format(x312.shape))
        x313=operator.mul(self.layer_scale26, x312)
        print('x313: {}'.format(x313.shape))
        x314=stochastic_depth(x313, 0.37142857142857144, 'row', False)
        print('x314: {}'.format(x314.shape))
        x315=operator.add(x314, x304)
        print('x315: {}'.format(x315.shape))
        x317=self.conv2d30(x315)
        print('x317: {}'.format(x317.shape))
        x318=torch.permute(x317, [0, 2, 3, 1])
        print('x318: {}'.format(x318.shape))
        x319=self.layernorm27(x318)
        print('x319: {}'.format(x319.shape))
        x320=self.linear54(x319)
        print('x320: {}'.format(x320.shape))
        x321=self.gelu27(x320)
        print('x321: {}'.format(x321.shape))
        x322=self.linear55(x321)
        print('x322: {}'.format(x322.shape))
        x323=torch.permute(x322, [0, 3, 1, 2])
        print('x323: {}'.format(x323.shape))
        x324=operator.mul(self.layer_scale27, x323)
        print('x324: {}'.format(x324.shape))
        x325=stochastic_depth(x324, 0.38571428571428573, 'row', False)
        print('x325: {}'.format(x325.shape))
        x326=operator.add(x325, x315)
        print('x326: {}'.format(x326.shape))
        x328=self.conv2d31(x326)
        print('x328: {}'.format(x328.shape))
        x329=torch.permute(x328, [0, 2, 3, 1])
        print('x329: {}'.format(x329.shape))
        x330=self.layernorm28(x329)
        print('x330: {}'.format(x330.shape))
        x331=self.linear56(x330)
        print('x331: {}'.format(x331.shape))
        x332=self.gelu28(x331)
        print('x332: {}'.format(x332.shape))
        x333=self.linear57(x332)
        print('x333: {}'.format(x333.shape))
        x334=torch.permute(x333, [0, 3, 1, 2])
        print('x334: {}'.format(x334.shape))
        x335=operator.mul(self.layer_scale28, x334)
        print('x335: {}'.format(x335.shape))
        x336=stochastic_depth(x335, 0.4, 'row', False)
        print('x336: {}'.format(x336.shape))
        x337=operator.add(x336, x326)
        print('x337: {}'.format(x337.shape))
        x339=self.conv2d32(x337)
        print('x339: {}'.format(x339.shape))
        x340=torch.permute(x339, [0, 2, 3, 1])
        print('x340: {}'.format(x340.shape))
        x341=self.layernorm29(x340)
        print('x341: {}'.format(x341.shape))
        x342=self.linear58(x341)
        print('x342: {}'.format(x342.shape))
        x343=self.gelu29(x342)
        print('x343: {}'.format(x343.shape))
        x344=self.linear59(x343)
        print('x344: {}'.format(x344.shape))
        x345=torch.permute(x344, [0, 3, 1, 2])
        print('x345: {}'.format(x345.shape))
        x346=operator.mul(self.layer_scale29, x345)
        print('x346: {}'.format(x346.shape))
        x347=stochastic_depth(x346, 0.4142857142857143, 'row', False)
        print('x347: {}'.format(x347.shape))
        x348=operator.add(x347, x337)
        print('x348: {}'.format(x348.shape))
        x350=self.conv2d33(x348)
        print('x350: {}'.format(x350.shape))
        x351=torch.permute(x350, [0, 2, 3, 1])
        print('x351: {}'.format(x351.shape))
        x352=self.layernorm30(x351)
        print('x352: {}'.format(x352.shape))
        x353=self.linear60(x352)
        print('x353: {}'.format(x353.shape))
        x354=self.gelu30(x353)
        print('x354: {}'.format(x354.shape))
        x355=self.linear61(x354)
        print('x355: {}'.format(x355.shape))
        x356=torch.permute(x355, [0, 3, 1, 2])
        print('x356: {}'.format(x356.shape))
        x357=operator.mul(self.layer_scale30, x356)
        print('x357: {}'.format(x357.shape))
        x358=stochastic_depth(x357, 0.42857142857142855, 'row', False)
        print('x358: {}'.format(x358.shape))
        x359=operator.add(x358, x348)
        print('x359: {}'.format(x359.shape))
        x361=self.conv2d34(x359)
        print('x361: {}'.format(x361.shape))
        x362=torch.permute(x361, [0, 2, 3, 1])
        print('x362: {}'.format(x362.shape))
        x363=self.layernorm31(x362)
        print('x363: {}'.format(x363.shape))
        x364=self.linear62(x363)
        print('x364: {}'.format(x364.shape))
        x365=self.gelu31(x364)
        print('x365: {}'.format(x365.shape))
        x366=self.linear63(x365)
        print('x366: {}'.format(x366.shape))
        x367=torch.permute(x366, [0, 3, 1, 2])
        print('x367: {}'.format(x367.shape))
        x368=operator.mul(self.layer_scale31, x367)
        print('x368: {}'.format(x368.shape))
        x369=stochastic_depth(x368, 0.44285714285714284, 'row', False)
        print('x369: {}'.format(x369.shape))
        x370=operator.add(x369, x359)
        print('x370: {}'.format(x370.shape))
        x372=self.conv2d35(x370)
        print('x372: {}'.format(x372.shape))
        x373=torch.permute(x372, [0, 2, 3, 1])
        print('x373: {}'.format(x373.shape))
        x374=self.layernorm32(x373)
        print('x374: {}'.format(x374.shape))
        x375=self.linear64(x374)
        print('x375: {}'.format(x375.shape))
        x376=self.gelu32(x375)
        print('x376: {}'.format(x376.shape))
        x377=self.linear65(x376)
        print('x377: {}'.format(x377.shape))
        x378=torch.permute(x377, [0, 3, 1, 2])
        print('x378: {}'.format(x378.shape))
        x379=operator.mul(self.layer_scale32, x378)
        print('x379: {}'.format(x379.shape))
        x380=stochastic_depth(x379, 0.45714285714285713, 'row', False)
        print('x380: {}'.format(x380.shape))
        x381=operator.add(x380, x370)
        print('x381: {}'.format(x381.shape))
        x382=x381.permute(0, 2, 3, 1)
        print('x382: {}'.format(x382.shape))
        x385=torch.nn.functional.layer_norm(x382, (512,),weight=self.weight3, bias=self.bias3, eps=1e-06)
        print('x385: {}'.format(x385.shape))
        x386=x385.permute(0, 3, 1, 2)
        print('x386: {}'.format(x386.shape))
        x387=self.conv2d36(x386)
        print('x387: {}'.format(x387.shape))
        x389=self.conv2d37(x387)
        print('x389: {}'.format(x389.shape))
        x390=torch.permute(x389, [0, 2, 3, 1])
        print('x390: {}'.format(x390.shape))
        x391=self.layernorm33(x390)
        print('x391: {}'.format(x391.shape))
        x392=self.linear66(x391)
        print('x392: {}'.format(x392.shape))
        x393=self.gelu33(x392)
        print('x393: {}'.format(x393.shape))
        x394=self.linear67(x393)
        print('x394: {}'.format(x394.shape))
        x395=torch.permute(x394, [0, 3, 1, 2])
        print('x395: {}'.format(x395.shape))
        x396=operator.mul(self.layer_scale33, x395)
        print('x396: {}'.format(x396.shape))
        x397=stochastic_depth(x396, 0.4714285714285714, 'row', False)
        print('x397: {}'.format(x397.shape))
        x398=operator.add(x397, x387)
        print('x398: {}'.format(x398.shape))
        x400=self.conv2d38(x398)
        print('x400: {}'.format(x400.shape))
        x401=torch.permute(x400, [0, 2, 3, 1])
        print('x401: {}'.format(x401.shape))
        x402=self.layernorm34(x401)
        print('x402: {}'.format(x402.shape))
        x403=self.linear68(x402)
        print('x403: {}'.format(x403.shape))
        x404=self.gelu34(x403)
        print('x404: {}'.format(x404.shape))
        x405=self.linear69(x404)
        print('x405: {}'.format(x405.shape))
        x406=torch.permute(x405, [0, 3, 1, 2])
        print('x406: {}'.format(x406.shape))
        x407=operator.mul(self.layer_scale34, x406)
        print('x407: {}'.format(x407.shape))
        x408=stochastic_depth(x407, 0.4857142857142857, 'row', False)
        print('x408: {}'.format(x408.shape))
        x409=operator.add(x408, x398)
        print('x409: {}'.format(x409.shape))
        x411=self.conv2d39(x409)
        print('x411: {}'.format(x411.shape))
        x412=torch.permute(x411, [0, 2, 3, 1])
        print('x412: {}'.format(x412.shape))
        x413=self.layernorm35(x412)
        print('x413: {}'.format(x413.shape))
        x414=self.linear70(x413)
        print('x414: {}'.format(x414.shape))
        x415=self.gelu35(x414)
        print('x415: {}'.format(x415.shape))
        x416=self.linear71(x415)
        print('x416: {}'.format(x416.shape))
        x417=torch.permute(x416, [0, 3, 1, 2])
        print('x417: {}'.format(x417.shape))
        x418=operator.mul(self.layer_scale35, x417)
        print('x418: {}'.format(x418.shape))
        x419=stochastic_depth(x418, 0.5, 'row', False)
        print('x419: {}'.format(x419.shape))
        x420=operator.add(x419, x409)
        print('x420: {}'.format(x420.shape))
        x421=self.adaptiveavgpool2d0(x420)
        print('x421: {}'.format(x421.shape))
        x422=x421.permute(0, 2, 3, 1)
        print('x422: {}'.format(x422.shape))
        x425=torch.nn.functional.layer_norm(x422, (1024,),weight=self.weight4, bias=self.bias4, eps=1e-06)
        print('x425: {}'.format(x425.shape))
        x426=x425.permute(0, 3, 1, 2)
        print('x426: {}'.format(x426.shape))
        x427=self.flatten0(x426)
        print('x427: {}'.format(x427.shape))
        x428=self.linear72(x427)
        print('x428: {}'.format(x428.shape))

m = M().eval()
x = torch.randn(1, 3, 224, 224)
output = m(x)
