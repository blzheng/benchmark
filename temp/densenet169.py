import torch
from torch import tensor
import torch.nn as nn
from torch.nn import *
import torchvision
import torchvision.models as models
from torchvision.ops.stochastic_depth import stochastic_depth
import time
import builtins
import operator

class M(torch.nn.Module):
    def __init__(self):
        super(M, self).__init__()
        self.conv2d0 = Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        self.batchnorm2d0 = BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu0 = ReLU(inplace=True)
        self.maxpool2d0 = MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        self.batchnorm2d1 = BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu1 = ReLU(inplace=True)
        self.conv2d1 = Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d2 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu2 = ReLU(inplace=True)
        self.conv2d2 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d3 = BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu3 = ReLU(inplace=True)
        self.conv2d3 = Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d4 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu4 = ReLU(inplace=True)
        self.conv2d4 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d5 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu5 = ReLU(inplace=True)
        self.conv2d5 = Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d6 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu6 = ReLU(inplace=True)
        self.conv2d6 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d7 = BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu7 = ReLU(inplace=True)
        self.conv2d7 = Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d8 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu8 = ReLU(inplace=True)
        self.conv2d8 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d9 = BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu9 = ReLU(inplace=True)
        self.conv2d9 = Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d10 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu10 = ReLU(inplace=True)
        self.conv2d10 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d11 = BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu11 = ReLU(inplace=True)
        self.conv2d11 = Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d12 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu12 = ReLU(inplace=True)
        self.conv2d12 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d13 = BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu13 = ReLU(inplace=True)
        self.conv2d13 = Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.avgpool2d0 = AvgPool2d(kernel_size=2, stride=2, padding=0)
        self.batchnorm2d14 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu14 = ReLU(inplace=True)
        self.conv2d14 = Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d15 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu15 = ReLU(inplace=True)
        self.conv2d15 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d16 = BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu16 = ReLU(inplace=True)
        self.conv2d16 = Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d17 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu17 = ReLU(inplace=True)
        self.conv2d17 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d18 = BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu18 = ReLU(inplace=True)
        self.conv2d18 = Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d19 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu19 = ReLU(inplace=True)
        self.conv2d19 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d20 = BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu20 = ReLU(inplace=True)
        self.conv2d20 = Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d21 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu21 = ReLU(inplace=True)
        self.conv2d21 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d22 = BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu22 = ReLU(inplace=True)
        self.conv2d22 = Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d23 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu23 = ReLU(inplace=True)
        self.conv2d23 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d24 = BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu24 = ReLU(inplace=True)
        self.conv2d24 = Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d25 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu25 = ReLU(inplace=True)
        self.conv2d25 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d26 = BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu26 = ReLU(inplace=True)
        self.conv2d26 = Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d27 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu27 = ReLU(inplace=True)
        self.conv2d27 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d28 = BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu28 = ReLU(inplace=True)
        self.conv2d28 = Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d29 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu29 = ReLU(inplace=True)
        self.conv2d29 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d30 = BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu30 = ReLU(inplace=True)
        self.conv2d30 = Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d31 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu31 = ReLU(inplace=True)
        self.conv2d31 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d32 = BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu32 = ReLU(inplace=True)
        self.conv2d32 = Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d33 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu33 = ReLU(inplace=True)
        self.conv2d33 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d34 = BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu34 = ReLU(inplace=True)
        self.conv2d34 = Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d35 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu35 = ReLU(inplace=True)
        self.conv2d35 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d36 = BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu36 = ReLU(inplace=True)
        self.conv2d36 = Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d37 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu37 = ReLU(inplace=True)
        self.conv2d37 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d38 = BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu38 = ReLU(inplace=True)
        self.conv2d38 = Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.avgpool2d1 = AvgPool2d(kernel_size=2, stride=2, padding=0)
        self.batchnorm2d39 = BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu39 = ReLU(inplace=True)
        self.conv2d39 = Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d40 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu40 = ReLU(inplace=True)
        self.conv2d40 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d41 = BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu41 = ReLU(inplace=True)
        self.conv2d41 = Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d42 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu42 = ReLU(inplace=True)
        self.conv2d42 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d43 = BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu43 = ReLU(inplace=True)
        self.conv2d43 = Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d44 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu44 = ReLU(inplace=True)
        self.conv2d44 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d45 = BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu45 = ReLU(inplace=True)
        self.conv2d45 = Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d46 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu46 = ReLU(inplace=True)
        self.conv2d46 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d47 = BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu47 = ReLU(inplace=True)
        self.conv2d47 = Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d48 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu48 = ReLU(inplace=True)
        self.conv2d48 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d49 = BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu49 = ReLU(inplace=True)
        self.conv2d49 = Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d50 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu50 = ReLU(inplace=True)
        self.conv2d50 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d51 = BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu51 = ReLU(inplace=True)
        self.conv2d51 = Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d52 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu52 = ReLU(inplace=True)
        self.conv2d52 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d53 = BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu53 = ReLU(inplace=True)
        self.conv2d53 = Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d54 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu54 = ReLU(inplace=True)
        self.conv2d54 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d55 = BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu55 = ReLU(inplace=True)
        self.conv2d55 = Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d56 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu56 = ReLU(inplace=True)
        self.conv2d56 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d57 = BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu57 = ReLU(inplace=True)
        self.conv2d57 = Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d58 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu58 = ReLU(inplace=True)
        self.conv2d58 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d59 = BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu59 = ReLU(inplace=True)
        self.conv2d59 = Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d60 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu60 = ReLU(inplace=True)
        self.conv2d60 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d61 = BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu61 = ReLU(inplace=True)
        self.conv2d61 = Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d62 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu62 = ReLU(inplace=True)
        self.conv2d62 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d63 = BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu63 = ReLU(inplace=True)
        self.conv2d63 = Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d64 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu64 = ReLU(inplace=True)
        self.conv2d64 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d65 = BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu65 = ReLU(inplace=True)
        self.conv2d65 = Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d66 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu66 = ReLU(inplace=True)
        self.conv2d66 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d67 = BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu67 = ReLU(inplace=True)
        self.conv2d67 = Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d68 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu68 = ReLU(inplace=True)
        self.conv2d68 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d69 = BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu69 = ReLU(inplace=True)
        self.conv2d69 = Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d70 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu70 = ReLU(inplace=True)
        self.conv2d70 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d71 = BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu71 = ReLU(inplace=True)
        self.conv2d71 = Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d72 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu72 = ReLU(inplace=True)
        self.conv2d72 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d73 = BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu73 = ReLU(inplace=True)
        self.conv2d73 = Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d74 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu74 = ReLU(inplace=True)
        self.conv2d74 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d75 = BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu75 = ReLU(inplace=True)
        self.conv2d75 = Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d76 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu76 = ReLU(inplace=True)
        self.conv2d76 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d77 = BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu77 = ReLU(inplace=True)
        self.conv2d77 = Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d78 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu78 = ReLU(inplace=True)
        self.conv2d78 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d79 = BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu79 = ReLU(inplace=True)
        self.conv2d79 = Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d80 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu80 = ReLU(inplace=True)
        self.conv2d80 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d81 = BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu81 = ReLU(inplace=True)
        self.conv2d81 = Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d82 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu82 = ReLU(inplace=True)
        self.conv2d82 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d83 = BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu83 = ReLU(inplace=True)
        self.conv2d83 = Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d84 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu84 = ReLU(inplace=True)
        self.conv2d84 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d85 = BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu85 = ReLU(inplace=True)
        self.conv2d85 = Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d86 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu86 = ReLU(inplace=True)
        self.conv2d86 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d87 = BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu87 = ReLU(inplace=True)
        self.conv2d87 = Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d88 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu88 = ReLU(inplace=True)
        self.conv2d88 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d89 = BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu89 = ReLU(inplace=True)
        self.conv2d89 = Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d90 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu90 = ReLU(inplace=True)
        self.conv2d90 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d91 = BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu91 = ReLU(inplace=True)
        self.conv2d91 = Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d92 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu92 = ReLU(inplace=True)
        self.conv2d92 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d93 = BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu93 = ReLU(inplace=True)
        self.conv2d93 = Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d94 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu94 = ReLU(inplace=True)
        self.conv2d94 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d95 = BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu95 = ReLU(inplace=True)
        self.conv2d95 = Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d96 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu96 = ReLU(inplace=True)
        self.conv2d96 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d97 = BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu97 = ReLU(inplace=True)
        self.conv2d97 = Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d98 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu98 = ReLU(inplace=True)
        self.conv2d98 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d99 = BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu99 = ReLU(inplace=True)
        self.conv2d99 = Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d100 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu100 = ReLU(inplace=True)
        self.conv2d100 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d101 = BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu101 = ReLU(inplace=True)
        self.conv2d101 = Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d102 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu102 = ReLU(inplace=True)
        self.conv2d102 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d103 = BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu103 = ReLU(inplace=True)
        self.conv2d103 = Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.avgpool2d2 = AvgPool2d(kernel_size=2, stride=2, padding=0)
        self.batchnorm2d104 = BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu104 = ReLU(inplace=True)
        self.conv2d104 = Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d105 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu105 = ReLU(inplace=True)
        self.conv2d105 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d106 = BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu106 = ReLU(inplace=True)
        self.conv2d106 = Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d107 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu107 = ReLU(inplace=True)
        self.conv2d107 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d108 = BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu108 = ReLU(inplace=True)
        self.conv2d108 = Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d109 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu109 = ReLU(inplace=True)
        self.conv2d109 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d110 = BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu110 = ReLU(inplace=True)
        self.conv2d110 = Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d111 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu111 = ReLU(inplace=True)
        self.conv2d111 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d112 = BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu112 = ReLU(inplace=True)
        self.conv2d112 = Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d113 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu113 = ReLU(inplace=True)
        self.conv2d113 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d114 = BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu114 = ReLU(inplace=True)
        self.conv2d114 = Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d115 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu115 = ReLU(inplace=True)
        self.conv2d115 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d116 = BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu116 = ReLU(inplace=True)
        self.conv2d116 = Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d117 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu117 = ReLU(inplace=True)
        self.conv2d117 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d118 = BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu118 = ReLU(inplace=True)
        self.conv2d118 = Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d119 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu119 = ReLU(inplace=True)
        self.conv2d119 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d120 = BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu120 = ReLU(inplace=True)
        self.conv2d120 = Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d121 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu121 = ReLU(inplace=True)
        self.conv2d121 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d122 = BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu122 = ReLU(inplace=True)
        self.conv2d122 = Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d123 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu123 = ReLU(inplace=True)
        self.conv2d123 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d124 = BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu124 = ReLU(inplace=True)
        self.conv2d124 = Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d125 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu125 = ReLU(inplace=True)
        self.conv2d125 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d126 = BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu126 = ReLU(inplace=True)
        self.conv2d126 = Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d127 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu127 = ReLU(inplace=True)
        self.conv2d127 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d128 = BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu128 = ReLU(inplace=True)
        self.conv2d128 = Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d129 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu129 = ReLU(inplace=True)
        self.conv2d129 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d130 = BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu130 = ReLU(inplace=True)
        self.conv2d130 = Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d131 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu131 = ReLU(inplace=True)
        self.conv2d131 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d132 = BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu132 = ReLU(inplace=True)
        self.conv2d132 = Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d133 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu133 = ReLU(inplace=True)
        self.conv2d133 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d134 = BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu134 = ReLU(inplace=True)
        self.conv2d134 = Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d135 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu135 = ReLU(inplace=True)
        self.conv2d135 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d136 = BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu136 = ReLU(inplace=True)
        self.conv2d136 = Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d137 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu137 = ReLU(inplace=True)
        self.conv2d137 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d138 = BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu138 = ReLU(inplace=True)
        self.conv2d138 = Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d139 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu139 = ReLU(inplace=True)
        self.conv2d139 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d140 = BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu140 = ReLU(inplace=True)
        self.conv2d140 = Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d141 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu141 = ReLU(inplace=True)
        self.conv2d141 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d142 = BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu142 = ReLU(inplace=True)
        self.conv2d142 = Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d143 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu143 = ReLU(inplace=True)
        self.conv2d143 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d144 = BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu144 = ReLU(inplace=True)
        self.conv2d144 = Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d145 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu145 = ReLU(inplace=True)
        self.conv2d145 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d146 = BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu146 = ReLU(inplace=True)
        self.conv2d146 = Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d147 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu147 = ReLU(inplace=True)
        self.conv2d147 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d148 = BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu148 = ReLU(inplace=True)
        self.conv2d148 = Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d149 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu149 = ReLU(inplace=True)
        self.conv2d149 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d150 = BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu150 = ReLU(inplace=True)
        self.conv2d150 = Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d151 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu151 = ReLU(inplace=True)
        self.conv2d151 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d152 = BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu152 = ReLU(inplace=True)
        self.conv2d152 = Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d153 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu153 = ReLU(inplace=True)
        self.conv2d153 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d154 = BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu154 = ReLU(inplace=True)
        self.conv2d154 = Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d155 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu155 = ReLU(inplace=True)
        self.conv2d155 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d156 = BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu156 = ReLU(inplace=True)
        self.conv2d156 = Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d157 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu157 = ReLU(inplace=True)
        self.conv2d157 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d158 = BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu158 = ReLU(inplace=True)
        self.conv2d158 = Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d159 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu159 = ReLU(inplace=True)
        self.conv2d159 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d160 = BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu160 = ReLU(inplace=True)
        self.conv2d160 = Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d161 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu161 = ReLU(inplace=True)
        self.conv2d161 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d162 = BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu162 = ReLU(inplace=True)
        self.conv2d162 = Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d163 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu163 = ReLU(inplace=True)
        self.conv2d163 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d164 = BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu164 = ReLU(inplace=True)
        self.conv2d164 = Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d165 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu165 = ReLU(inplace=True)
        self.conv2d165 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d166 = BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu166 = ReLU(inplace=True)
        self.conv2d166 = Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        self.batchnorm2d167 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu167 = ReLU(inplace=True)
        self.conv2d167 = Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        self.batchnorm2d168 = BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.linear0 = Linear(in_features=1664, out_features=1000, bias=True)

    def forward(self, x):
        x0=x
        print('x0: {}'.format(x0.shape))
        x1=self.conv2d0(x0)
        print('x1: {}'.format(x1.shape))
        x2=self.batchnorm2d0(x1)
        print('x2: {}'.format(x2.shape))
        x3=self.relu0(x2)
        print('x3: {}'.format(x3.shape))
        x4=self.maxpool2d0(x3)
        print('x4: {}'.format(x4.shape))
        x5=torch.cat([x4], 1)
        print('x5: {}'.format(x5.shape))
        x6=self.batchnorm2d1(x5)
        print('x6: {}'.format(x6.shape))
        x7=self.relu1(x6)
        print('x7: {}'.format(x7.shape))
        x8=self.conv2d1(x7)
        print('x8: {}'.format(x8.shape))
        x9=self.batchnorm2d2(x8)
        print('x9: {}'.format(x9.shape))
        x10=self.relu2(x9)
        print('x10: {}'.format(x10.shape))
        x11=self.conv2d2(x10)
        print('x11: {}'.format(x11.shape))
        x12=torch.cat([x4, x11], 1)
        print('x12: {}'.format(x12.shape))
        x13=self.batchnorm2d3(x12)
        print('x13: {}'.format(x13.shape))
        x14=self.relu3(x13)
        print('x14: {}'.format(x14.shape))
        x15=self.conv2d3(x14)
        print('x15: {}'.format(x15.shape))
        x16=self.batchnorm2d4(x15)
        print('x16: {}'.format(x16.shape))
        x17=self.relu4(x16)
        print('x17: {}'.format(x17.shape))
        x18=self.conv2d4(x17)
        print('x18: {}'.format(x18.shape))
        x19=torch.cat([x4, x11, x18], 1)
        print('x19: {}'.format(x19.shape))
        x20=self.batchnorm2d5(x19)
        print('x20: {}'.format(x20.shape))
        x21=self.relu5(x20)
        print('x21: {}'.format(x21.shape))
        x22=self.conv2d5(x21)
        print('x22: {}'.format(x22.shape))
        x23=self.batchnorm2d6(x22)
        print('x23: {}'.format(x23.shape))
        x24=self.relu6(x23)
        print('x24: {}'.format(x24.shape))
        x25=self.conv2d6(x24)
        print('x25: {}'.format(x25.shape))
        x26=torch.cat([x4, x11, x18, x25], 1)
        print('x26: {}'.format(x26.shape))
        x27=self.batchnorm2d7(x26)
        print('x27: {}'.format(x27.shape))
        x28=self.relu7(x27)
        print('x28: {}'.format(x28.shape))
        x29=self.conv2d7(x28)
        print('x29: {}'.format(x29.shape))
        x30=self.batchnorm2d8(x29)
        print('x30: {}'.format(x30.shape))
        x31=self.relu8(x30)
        print('x31: {}'.format(x31.shape))
        x32=self.conv2d8(x31)
        print('x32: {}'.format(x32.shape))
        x33=torch.cat([x4, x11, x18, x25, x32], 1)
        print('x33: {}'.format(x33.shape))
        x34=self.batchnorm2d9(x33)
        print('x34: {}'.format(x34.shape))
        x35=self.relu9(x34)
        print('x35: {}'.format(x35.shape))
        x36=self.conv2d9(x35)
        print('x36: {}'.format(x36.shape))
        x37=self.batchnorm2d10(x36)
        print('x37: {}'.format(x37.shape))
        x38=self.relu10(x37)
        print('x38: {}'.format(x38.shape))
        x39=self.conv2d10(x38)
        print('x39: {}'.format(x39.shape))
        x40=torch.cat([x4, x11, x18, x25, x32, x39], 1)
        print('x40: {}'.format(x40.shape))
        x41=self.batchnorm2d11(x40)
        print('x41: {}'.format(x41.shape))
        x42=self.relu11(x41)
        print('x42: {}'.format(x42.shape))
        x43=self.conv2d11(x42)
        print('x43: {}'.format(x43.shape))
        x44=self.batchnorm2d12(x43)
        print('x44: {}'.format(x44.shape))
        x45=self.relu12(x44)
        print('x45: {}'.format(x45.shape))
        x46=self.conv2d12(x45)
        print('x46: {}'.format(x46.shape))
        x47=torch.cat([x4, x11, x18, x25, x32, x39, x46], 1)
        print('x47: {}'.format(x47.shape))
        x48=self.batchnorm2d13(x47)
        print('x48: {}'.format(x48.shape))
        x49=self.relu13(x48)
        print('x49: {}'.format(x49.shape))
        x50=self.conv2d13(x49)
        print('x50: {}'.format(x50.shape))
        x51=self.avgpool2d0(x50)
        print('x51: {}'.format(x51.shape))
        x52=torch.cat([x51], 1)
        print('x52: {}'.format(x52.shape))
        x53=self.batchnorm2d14(x52)
        print('x53: {}'.format(x53.shape))
        x54=self.relu14(x53)
        print('x54: {}'.format(x54.shape))
        x55=self.conv2d14(x54)
        print('x55: {}'.format(x55.shape))
        x56=self.batchnorm2d15(x55)
        print('x56: {}'.format(x56.shape))
        x57=self.relu15(x56)
        print('x57: {}'.format(x57.shape))
        x58=self.conv2d15(x57)
        print('x58: {}'.format(x58.shape))
        x59=torch.cat([x51, x58], 1)
        print('x59: {}'.format(x59.shape))
        x60=self.batchnorm2d16(x59)
        print('x60: {}'.format(x60.shape))
        x61=self.relu16(x60)
        print('x61: {}'.format(x61.shape))
        x62=self.conv2d16(x61)
        print('x62: {}'.format(x62.shape))
        x63=self.batchnorm2d17(x62)
        print('x63: {}'.format(x63.shape))
        x64=self.relu17(x63)
        print('x64: {}'.format(x64.shape))
        x65=self.conv2d17(x64)
        print('x65: {}'.format(x65.shape))
        x66=torch.cat([x51, x58, x65], 1)
        print('x66: {}'.format(x66.shape))
        x67=self.batchnorm2d18(x66)
        print('x67: {}'.format(x67.shape))
        x68=self.relu18(x67)
        print('x68: {}'.format(x68.shape))
        x69=self.conv2d18(x68)
        print('x69: {}'.format(x69.shape))
        x70=self.batchnorm2d19(x69)
        print('x70: {}'.format(x70.shape))
        x71=self.relu19(x70)
        print('x71: {}'.format(x71.shape))
        x72=self.conv2d19(x71)
        print('x72: {}'.format(x72.shape))
        x73=torch.cat([x51, x58, x65, x72], 1)
        print('x73: {}'.format(x73.shape))
        x74=self.batchnorm2d20(x73)
        print('x74: {}'.format(x74.shape))
        x75=self.relu20(x74)
        print('x75: {}'.format(x75.shape))
        x76=self.conv2d20(x75)
        print('x76: {}'.format(x76.shape))
        x77=self.batchnorm2d21(x76)
        print('x77: {}'.format(x77.shape))
        x78=self.relu21(x77)
        print('x78: {}'.format(x78.shape))
        x79=self.conv2d21(x78)
        print('x79: {}'.format(x79.shape))
        x80=torch.cat([x51, x58, x65, x72, x79], 1)
        print('x80: {}'.format(x80.shape))
        x81=self.batchnorm2d22(x80)
        print('x81: {}'.format(x81.shape))
        x82=self.relu22(x81)
        print('x82: {}'.format(x82.shape))
        x83=self.conv2d22(x82)
        print('x83: {}'.format(x83.shape))
        x84=self.batchnorm2d23(x83)
        print('x84: {}'.format(x84.shape))
        x85=self.relu23(x84)
        print('x85: {}'.format(x85.shape))
        x86=self.conv2d23(x85)
        print('x86: {}'.format(x86.shape))
        x87=torch.cat([x51, x58, x65, x72, x79, x86], 1)
        print('x87: {}'.format(x87.shape))
        x88=self.batchnorm2d24(x87)
        print('x88: {}'.format(x88.shape))
        x89=self.relu24(x88)
        print('x89: {}'.format(x89.shape))
        x90=self.conv2d24(x89)
        print('x90: {}'.format(x90.shape))
        x91=self.batchnorm2d25(x90)
        print('x91: {}'.format(x91.shape))
        x92=self.relu25(x91)
        print('x92: {}'.format(x92.shape))
        x93=self.conv2d25(x92)
        print('x93: {}'.format(x93.shape))
        x94=torch.cat([x51, x58, x65, x72, x79, x86, x93], 1)
        print('x94: {}'.format(x94.shape))
        x95=self.batchnorm2d26(x94)
        print('x95: {}'.format(x95.shape))
        x96=self.relu26(x95)
        print('x96: {}'.format(x96.shape))
        x97=self.conv2d26(x96)
        print('x97: {}'.format(x97.shape))
        x98=self.batchnorm2d27(x97)
        print('x98: {}'.format(x98.shape))
        x99=self.relu27(x98)
        print('x99: {}'.format(x99.shape))
        x100=self.conv2d27(x99)
        print('x100: {}'.format(x100.shape))
        x101=torch.cat([x51, x58, x65, x72, x79, x86, x93, x100], 1)
        print('x101: {}'.format(x101.shape))
        x102=self.batchnorm2d28(x101)
        print('x102: {}'.format(x102.shape))
        x103=self.relu28(x102)
        print('x103: {}'.format(x103.shape))
        x104=self.conv2d28(x103)
        print('x104: {}'.format(x104.shape))
        x105=self.batchnorm2d29(x104)
        print('x105: {}'.format(x105.shape))
        x106=self.relu29(x105)
        print('x106: {}'.format(x106.shape))
        x107=self.conv2d29(x106)
        print('x107: {}'.format(x107.shape))
        x108=torch.cat([x51, x58, x65, x72, x79, x86, x93, x100, x107], 1)
        print('x108: {}'.format(x108.shape))
        x109=self.batchnorm2d30(x108)
        print('x109: {}'.format(x109.shape))
        x110=self.relu30(x109)
        print('x110: {}'.format(x110.shape))
        x111=self.conv2d30(x110)
        print('x111: {}'.format(x111.shape))
        x112=self.batchnorm2d31(x111)
        print('x112: {}'.format(x112.shape))
        x113=self.relu31(x112)
        print('x113: {}'.format(x113.shape))
        x114=self.conv2d31(x113)
        print('x114: {}'.format(x114.shape))
        x115=torch.cat([x51, x58, x65, x72, x79, x86, x93, x100, x107, x114], 1)
        print('x115: {}'.format(x115.shape))
        x116=self.batchnorm2d32(x115)
        print('x116: {}'.format(x116.shape))
        x117=self.relu32(x116)
        print('x117: {}'.format(x117.shape))
        x118=self.conv2d32(x117)
        print('x118: {}'.format(x118.shape))
        x119=self.batchnorm2d33(x118)
        print('x119: {}'.format(x119.shape))
        x120=self.relu33(x119)
        print('x120: {}'.format(x120.shape))
        x121=self.conv2d33(x120)
        print('x121: {}'.format(x121.shape))
        x122=torch.cat([x51, x58, x65, x72, x79, x86, x93, x100, x107, x114, x121], 1)
        print('x122: {}'.format(x122.shape))
        x123=self.batchnorm2d34(x122)
        print('x123: {}'.format(x123.shape))
        x124=self.relu34(x123)
        print('x124: {}'.format(x124.shape))
        x125=self.conv2d34(x124)
        print('x125: {}'.format(x125.shape))
        x126=self.batchnorm2d35(x125)
        print('x126: {}'.format(x126.shape))
        x127=self.relu35(x126)
        print('x127: {}'.format(x127.shape))
        x128=self.conv2d35(x127)
        print('x128: {}'.format(x128.shape))
        x129=torch.cat([x51, x58, x65, x72, x79, x86, x93, x100, x107, x114, x121, x128], 1)
        print('x129: {}'.format(x129.shape))
        x130=self.batchnorm2d36(x129)
        print('x130: {}'.format(x130.shape))
        x131=self.relu36(x130)
        print('x131: {}'.format(x131.shape))
        x132=self.conv2d36(x131)
        print('x132: {}'.format(x132.shape))
        x133=self.batchnorm2d37(x132)
        print('x133: {}'.format(x133.shape))
        x134=self.relu37(x133)
        print('x134: {}'.format(x134.shape))
        x135=self.conv2d37(x134)
        print('x135: {}'.format(x135.shape))
        x136=torch.cat([x51, x58, x65, x72, x79, x86, x93, x100, x107, x114, x121, x128, x135], 1)
        print('x136: {}'.format(x136.shape))
        x137=self.batchnorm2d38(x136)
        print('x137: {}'.format(x137.shape))
        x138=self.relu38(x137)
        print('x138: {}'.format(x138.shape))
        x139=self.conv2d38(x138)
        print('x139: {}'.format(x139.shape))
        x140=self.avgpool2d1(x139)
        print('x140: {}'.format(x140.shape))
        x141=torch.cat([x140], 1)
        print('x141: {}'.format(x141.shape))
        x142=self.batchnorm2d39(x141)
        print('x142: {}'.format(x142.shape))
        x143=self.relu39(x142)
        print('x143: {}'.format(x143.shape))
        x144=self.conv2d39(x143)
        print('x144: {}'.format(x144.shape))
        x145=self.batchnorm2d40(x144)
        print('x145: {}'.format(x145.shape))
        x146=self.relu40(x145)
        print('x146: {}'.format(x146.shape))
        x147=self.conv2d40(x146)
        print('x147: {}'.format(x147.shape))
        x148=torch.cat([x140, x147], 1)
        print('x148: {}'.format(x148.shape))
        x149=self.batchnorm2d41(x148)
        print('x149: {}'.format(x149.shape))
        x150=self.relu41(x149)
        print('x150: {}'.format(x150.shape))
        x151=self.conv2d41(x150)
        print('x151: {}'.format(x151.shape))
        x152=self.batchnorm2d42(x151)
        print('x152: {}'.format(x152.shape))
        x153=self.relu42(x152)
        print('x153: {}'.format(x153.shape))
        x154=self.conv2d42(x153)
        print('x154: {}'.format(x154.shape))
        x155=torch.cat([x140, x147, x154], 1)
        print('x155: {}'.format(x155.shape))
        x156=self.batchnorm2d43(x155)
        print('x156: {}'.format(x156.shape))
        x157=self.relu43(x156)
        print('x157: {}'.format(x157.shape))
        x158=self.conv2d43(x157)
        print('x158: {}'.format(x158.shape))
        x159=self.batchnorm2d44(x158)
        print('x159: {}'.format(x159.shape))
        x160=self.relu44(x159)
        print('x160: {}'.format(x160.shape))
        x161=self.conv2d44(x160)
        print('x161: {}'.format(x161.shape))
        x162=torch.cat([x140, x147, x154, x161], 1)
        print('x162: {}'.format(x162.shape))
        x163=self.batchnorm2d45(x162)
        print('x163: {}'.format(x163.shape))
        x164=self.relu45(x163)
        print('x164: {}'.format(x164.shape))
        x165=self.conv2d45(x164)
        print('x165: {}'.format(x165.shape))
        x166=self.batchnorm2d46(x165)
        print('x166: {}'.format(x166.shape))
        x167=self.relu46(x166)
        print('x167: {}'.format(x167.shape))
        x168=self.conv2d46(x167)
        print('x168: {}'.format(x168.shape))
        x169=torch.cat([x140, x147, x154, x161, x168], 1)
        print('x169: {}'.format(x169.shape))
        x170=self.batchnorm2d47(x169)
        print('x170: {}'.format(x170.shape))
        x171=self.relu47(x170)
        print('x171: {}'.format(x171.shape))
        x172=self.conv2d47(x171)
        print('x172: {}'.format(x172.shape))
        x173=self.batchnorm2d48(x172)
        print('x173: {}'.format(x173.shape))
        x174=self.relu48(x173)
        print('x174: {}'.format(x174.shape))
        x175=self.conv2d48(x174)
        print('x175: {}'.format(x175.shape))
        x176=torch.cat([x140, x147, x154, x161, x168, x175], 1)
        print('x176: {}'.format(x176.shape))
        x177=self.batchnorm2d49(x176)
        print('x177: {}'.format(x177.shape))
        x178=self.relu49(x177)
        print('x178: {}'.format(x178.shape))
        x179=self.conv2d49(x178)
        print('x179: {}'.format(x179.shape))
        x180=self.batchnorm2d50(x179)
        print('x180: {}'.format(x180.shape))
        x181=self.relu50(x180)
        print('x181: {}'.format(x181.shape))
        x182=self.conv2d50(x181)
        print('x182: {}'.format(x182.shape))
        x183=torch.cat([x140, x147, x154, x161, x168, x175, x182], 1)
        print('x183: {}'.format(x183.shape))
        x184=self.batchnorm2d51(x183)
        print('x184: {}'.format(x184.shape))
        x185=self.relu51(x184)
        print('x185: {}'.format(x185.shape))
        x186=self.conv2d51(x185)
        print('x186: {}'.format(x186.shape))
        x187=self.batchnorm2d52(x186)
        print('x187: {}'.format(x187.shape))
        x188=self.relu52(x187)
        print('x188: {}'.format(x188.shape))
        x189=self.conv2d52(x188)
        print('x189: {}'.format(x189.shape))
        x190=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189], 1)
        print('x190: {}'.format(x190.shape))
        x191=self.batchnorm2d53(x190)
        print('x191: {}'.format(x191.shape))
        x192=self.relu53(x191)
        print('x192: {}'.format(x192.shape))
        x193=self.conv2d53(x192)
        print('x193: {}'.format(x193.shape))
        x194=self.batchnorm2d54(x193)
        print('x194: {}'.format(x194.shape))
        x195=self.relu54(x194)
        print('x195: {}'.format(x195.shape))
        x196=self.conv2d54(x195)
        print('x196: {}'.format(x196.shape))
        x197=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196], 1)
        print('x197: {}'.format(x197.shape))
        x198=self.batchnorm2d55(x197)
        print('x198: {}'.format(x198.shape))
        x199=self.relu55(x198)
        print('x199: {}'.format(x199.shape))
        x200=self.conv2d55(x199)
        print('x200: {}'.format(x200.shape))
        x201=self.batchnorm2d56(x200)
        print('x201: {}'.format(x201.shape))
        x202=self.relu56(x201)
        print('x202: {}'.format(x202.shape))
        x203=self.conv2d56(x202)
        print('x203: {}'.format(x203.shape))
        x204=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203], 1)
        print('x204: {}'.format(x204.shape))
        x205=self.batchnorm2d57(x204)
        print('x205: {}'.format(x205.shape))
        x206=self.relu57(x205)
        print('x206: {}'.format(x206.shape))
        x207=self.conv2d57(x206)
        print('x207: {}'.format(x207.shape))
        x208=self.batchnorm2d58(x207)
        print('x208: {}'.format(x208.shape))
        x209=self.relu58(x208)
        print('x209: {}'.format(x209.shape))
        x210=self.conv2d58(x209)
        print('x210: {}'.format(x210.shape))
        x211=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210], 1)
        print('x211: {}'.format(x211.shape))
        x212=self.batchnorm2d59(x211)
        print('x212: {}'.format(x212.shape))
        x213=self.relu59(x212)
        print('x213: {}'.format(x213.shape))
        x214=self.conv2d59(x213)
        print('x214: {}'.format(x214.shape))
        x215=self.batchnorm2d60(x214)
        print('x215: {}'.format(x215.shape))
        x216=self.relu60(x215)
        print('x216: {}'.format(x216.shape))
        x217=self.conv2d60(x216)
        print('x217: {}'.format(x217.shape))
        x218=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217], 1)
        print('x218: {}'.format(x218.shape))
        x219=self.batchnorm2d61(x218)
        print('x219: {}'.format(x219.shape))
        x220=self.relu61(x219)
        print('x220: {}'.format(x220.shape))
        x221=self.conv2d61(x220)
        print('x221: {}'.format(x221.shape))
        x222=self.batchnorm2d62(x221)
        print('x222: {}'.format(x222.shape))
        x223=self.relu62(x222)
        print('x223: {}'.format(x223.shape))
        x224=self.conv2d62(x223)
        print('x224: {}'.format(x224.shape))
        x225=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224], 1)
        print('x225: {}'.format(x225.shape))
        x226=self.batchnorm2d63(x225)
        print('x226: {}'.format(x226.shape))
        x227=self.relu63(x226)
        print('x227: {}'.format(x227.shape))
        x228=self.conv2d63(x227)
        print('x228: {}'.format(x228.shape))
        x229=self.batchnorm2d64(x228)
        print('x229: {}'.format(x229.shape))
        x230=self.relu64(x229)
        print('x230: {}'.format(x230.shape))
        x231=self.conv2d64(x230)
        print('x231: {}'.format(x231.shape))
        x232=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231], 1)
        print('x232: {}'.format(x232.shape))
        x233=self.batchnorm2d65(x232)
        print('x233: {}'.format(x233.shape))
        x234=self.relu65(x233)
        print('x234: {}'.format(x234.shape))
        x235=self.conv2d65(x234)
        print('x235: {}'.format(x235.shape))
        x236=self.batchnorm2d66(x235)
        print('x236: {}'.format(x236.shape))
        x237=self.relu66(x236)
        print('x237: {}'.format(x237.shape))
        x238=self.conv2d66(x237)
        print('x238: {}'.format(x238.shape))
        x239=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238], 1)
        print('x239: {}'.format(x239.shape))
        x240=self.batchnorm2d67(x239)
        print('x240: {}'.format(x240.shape))
        x241=self.relu67(x240)
        print('x241: {}'.format(x241.shape))
        x242=self.conv2d67(x241)
        print('x242: {}'.format(x242.shape))
        x243=self.batchnorm2d68(x242)
        print('x243: {}'.format(x243.shape))
        x244=self.relu68(x243)
        print('x244: {}'.format(x244.shape))
        x245=self.conv2d68(x244)
        print('x245: {}'.format(x245.shape))
        x246=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245], 1)
        print('x246: {}'.format(x246.shape))
        x247=self.batchnorm2d69(x246)
        print('x247: {}'.format(x247.shape))
        x248=self.relu69(x247)
        print('x248: {}'.format(x248.shape))
        x249=self.conv2d69(x248)
        print('x249: {}'.format(x249.shape))
        x250=self.batchnorm2d70(x249)
        print('x250: {}'.format(x250.shape))
        x251=self.relu70(x250)
        print('x251: {}'.format(x251.shape))
        x252=self.conv2d70(x251)
        print('x252: {}'.format(x252.shape))
        x253=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252], 1)
        print('x253: {}'.format(x253.shape))
        x254=self.batchnorm2d71(x253)
        print('x254: {}'.format(x254.shape))
        x255=self.relu71(x254)
        print('x255: {}'.format(x255.shape))
        x256=self.conv2d71(x255)
        print('x256: {}'.format(x256.shape))
        x257=self.batchnorm2d72(x256)
        print('x257: {}'.format(x257.shape))
        x258=self.relu72(x257)
        print('x258: {}'.format(x258.shape))
        x259=self.conv2d72(x258)
        print('x259: {}'.format(x259.shape))
        x260=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259], 1)
        print('x260: {}'.format(x260.shape))
        x261=self.batchnorm2d73(x260)
        print('x261: {}'.format(x261.shape))
        x262=self.relu73(x261)
        print('x262: {}'.format(x262.shape))
        x263=self.conv2d73(x262)
        print('x263: {}'.format(x263.shape))
        x264=self.batchnorm2d74(x263)
        print('x264: {}'.format(x264.shape))
        x265=self.relu74(x264)
        print('x265: {}'.format(x265.shape))
        x266=self.conv2d74(x265)
        print('x266: {}'.format(x266.shape))
        x267=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266], 1)
        print('x267: {}'.format(x267.shape))
        x268=self.batchnorm2d75(x267)
        print('x268: {}'.format(x268.shape))
        x269=self.relu75(x268)
        print('x269: {}'.format(x269.shape))
        x270=self.conv2d75(x269)
        print('x270: {}'.format(x270.shape))
        x271=self.batchnorm2d76(x270)
        print('x271: {}'.format(x271.shape))
        x272=self.relu76(x271)
        print('x272: {}'.format(x272.shape))
        x273=self.conv2d76(x272)
        print('x273: {}'.format(x273.shape))
        x274=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273], 1)
        print('x274: {}'.format(x274.shape))
        x275=self.batchnorm2d77(x274)
        print('x275: {}'.format(x275.shape))
        x276=self.relu77(x275)
        print('x276: {}'.format(x276.shape))
        x277=self.conv2d77(x276)
        print('x277: {}'.format(x277.shape))
        x278=self.batchnorm2d78(x277)
        print('x278: {}'.format(x278.shape))
        x279=self.relu78(x278)
        print('x279: {}'.format(x279.shape))
        x280=self.conv2d78(x279)
        print('x280: {}'.format(x280.shape))
        x281=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280], 1)
        print('x281: {}'.format(x281.shape))
        x282=self.batchnorm2d79(x281)
        print('x282: {}'.format(x282.shape))
        x283=self.relu79(x282)
        print('x283: {}'.format(x283.shape))
        x284=self.conv2d79(x283)
        print('x284: {}'.format(x284.shape))
        x285=self.batchnorm2d80(x284)
        print('x285: {}'.format(x285.shape))
        x286=self.relu80(x285)
        print('x286: {}'.format(x286.shape))
        x287=self.conv2d80(x286)
        print('x287: {}'.format(x287.shape))
        x288=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287], 1)
        print('x288: {}'.format(x288.shape))
        x289=self.batchnorm2d81(x288)
        print('x289: {}'.format(x289.shape))
        x290=self.relu81(x289)
        print('x290: {}'.format(x290.shape))
        x291=self.conv2d81(x290)
        print('x291: {}'.format(x291.shape))
        x292=self.batchnorm2d82(x291)
        print('x292: {}'.format(x292.shape))
        x293=self.relu82(x292)
        print('x293: {}'.format(x293.shape))
        x294=self.conv2d82(x293)
        print('x294: {}'.format(x294.shape))
        x295=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294], 1)
        print('x295: {}'.format(x295.shape))
        x296=self.batchnorm2d83(x295)
        print('x296: {}'.format(x296.shape))
        x297=self.relu83(x296)
        print('x297: {}'.format(x297.shape))
        x298=self.conv2d83(x297)
        print('x298: {}'.format(x298.shape))
        x299=self.batchnorm2d84(x298)
        print('x299: {}'.format(x299.shape))
        x300=self.relu84(x299)
        print('x300: {}'.format(x300.shape))
        x301=self.conv2d84(x300)
        print('x301: {}'.format(x301.shape))
        x302=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301], 1)
        print('x302: {}'.format(x302.shape))
        x303=self.batchnorm2d85(x302)
        print('x303: {}'.format(x303.shape))
        x304=self.relu85(x303)
        print('x304: {}'.format(x304.shape))
        x305=self.conv2d85(x304)
        print('x305: {}'.format(x305.shape))
        x306=self.batchnorm2d86(x305)
        print('x306: {}'.format(x306.shape))
        x307=self.relu86(x306)
        print('x307: {}'.format(x307.shape))
        x308=self.conv2d86(x307)
        print('x308: {}'.format(x308.shape))
        x309=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301, x308], 1)
        print('x309: {}'.format(x309.shape))
        x310=self.batchnorm2d87(x309)
        print('x310: {}'.format(x310.shape))
        x311=self.relu87(x310)
        print('x311: {}'.format(x311.shape))
        x312=self.conv2d87(x311)
        print('x312: {}'.format(x312.shape))
        x313=self.batchnorm2d88(x312)
        print('x313: {}'.format(x313.shape))
        x314=self.relu88(x313)
        print('x314: {}'.format(x314.shape))
        x315=self.conv2d88(x314)
        print('x315: {}'.format(x315.shape))
        x316=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301, x308, x315], 1)
        print('x316: {}'.format(x316.shape))
        x317=self.batchnorm2d89(x316)
        print('x317: {}'.format(x317.shape))
        x318=self.relu89(x317)
        print('x318: {}'.format(x318.shape))
        x319=self.conv2d89(x318)
        print('x319: {}'.format(x319.shape))
        x320=self.batchnorm2d90(x319)
        print('x320: {}'.format(x320.shape))
        x321=self.relu90(x320)
        print('x321: {}'.format(x321.shape))
        x322=self.conv2d90(x321)
        print('x322: {}'.format(x322.shape))
        x323=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301, x308, x315, x322], 1)
        print('x323: {}'.format(x323.shape))
        x324=self.batchnorm2d91(x323)
        print('x324: {}'.format(x324.shape))
        x325=self.relu91(x324)
        print('x325: {}'.format(x325.shape))
        x326=self.conv2d91(x325)
        print('x326: {}'.format(x326.shape))
        x327=self.batchnorm2d92(x326)
        print('x327: {}'.format(x327.shape))
        x328=self.relu92(x327)
        print('x328: {}'.format(x328.shape))
        x329=self.conv2d92(x328)
        print('x329: {}'.format(x329.shape))
        x330=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301, x308, x315, x322, x329], 1)
        print('x330: {}'.format(x330.shape))
        x331=self.batchnorm2d93(x330)
        print('x331: {}'.format(x331.shape))
        x332=self.relu93(x331)
        print('x332: {}'.format(x332.shape))
        x333=self.conv2d93(x332)
        print('x333: {}'.format(x333.shape))
        x334=self.batchnorm2d94(x333)
        print('x334: {}'.format(x334.shape))
        x335=self.relu94(x334)
        print('x335: {}'.format(x335.shape))
        x336=self.conv2d94(x335)
        print('x336: {}'.format(x336.shape))
        x337=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301, x308, x315, x322, x329, x336], 1)
        print('x337: {}'.format(x337.shape))
        x338=self.batchnorm2d95(x337)
        print('x338: {}'.format(x338.shape))
        x339=self.relu95(x338)
        print('x339: {}'.format(x339.shape))
        x340=self.conv2d95(x339)
        print('x340: {}'.format(x340.shape))
        x341=self.batchnorm2d96(x340)
        print('x341: {}'.format(x341.shape))
        x342=self.relu96(x341)
        print('x342: {}'.format(x342.shape))
        x343=self.conv2d96(x342)
        print('x343: {}'.format(x343.shape))
        x344=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301, x308, x315, x322, x329, x336, x343], 1)
        print('x344: {}'.format(x344.shape))
        x345=self.batchnorm2d97(x344)
        print('x345: {}'.format(x345.shape))
        x346=self.relu97(x345)
        print('x346: {}'.format(x346.shape))
        x347=self.conv2d97(x346)
        print('x347: {}'.format(x347.shape))
        x348=self.batchnorm2d98(x347)
        print('x348: {}'.format(x348.shape))
        x349=self.relu98(x348)
        print('x349: {}'.format(x349.shape))
        x350=self.conv2d98(x349)
        print('x350: {}'.format(x350.shape))
        x351=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301, x308, x315, x322, x329, x336, x343, x350], 1)
        print('x351: {}'.format(x351.shape))
        x352=self.batchnorm2d99(x351)
        print('x352: {}'.format(x352.shape))
        x353=self.relu99(x352)
        print('x353: {}'.format(x353.shape))
        x354=self.conv2d99(x353)
        print('x354: {}'.format(x354.shape))
        x355=self.batchnorm2d100(x354)
        print('x355: {}'.format(x355.shape))
        x356=self.relu100(x355)
        print('x356: {}'.format(x356.shape))
        x357=self.conv2d100(x356)
        print('x357: {}'.format(x357.shape))
        x358=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301, x308, x315, x322, x329, x336, x343, x350, x357], 1)
        print('x358: {}'.format(x358.shape))
        x359=self.batchnorm2d101(x358)
        print('x359: {}'.format(x359.shape))
        x360=self.relu101(x359)
        print('x360: {}'.format(x360.shape))
        x361=self.conv2d101(x360)
        print('x361: {}'.format(x361.shape))
        x362=self.batchnorm2d102(x361)
        print('x362: {}'.format(x362.shape))
        x363=self.relu102(x362)
        print('x363: {}'.format(x363.shape))
        x364=self.conv2d102(x363)
        print('x364: {}'.format(x364.shape))
        x365=torch.cat([x140, x147, x154, x161, x168, x175, x182, x189, x196, x203, x210, x217, x224, x231, x238, x245, x252, x259, x266, x273, x280, x287, x294, x301, x308, x315, x322, x329, x336, x343, x350, x357, x364], 1)
        print('x365: {}'.format(x365.shape))
        x366=self.batchnorm2d103(x365)
        print('x366: {}'.format(x366.shape))
        x367=self.relu103(x366)
        print('x367: {}'.format(x367.shape))
        x368=self.conv2d103(x367)
        print('x368: {}'.format(x368.shape))
        x369=self.avgpool2d2(x368)
        print('x369: {}'.format(x369.shape))
        x370=torch.cat([x369], 1)
        print('x370: {}'.format(x370.shape))
        x371=self.batchnorm2d104(x370)
        print('x371: {}'.format(x371.shape))
        x372=self.relu104(x371)
        print('x372: {}'.format(x372.shape))
        x373=self.conv2d104(x372)
        print('x373: {}'.format(x373.shape))
        x374=self.batchnorm2d105(x373)
        print('x374: {}'.format(x374.shape))
        x375=self.relu105(x374)
        print('x375: {}'.format(x375.shape))
        x376=self.conv2d105(x375)
        print('x376: {}'.format(x376.shape))
        x377=torch.cat([x369, x376], 1)
        print('x377: {}'.format(x377.shape))
        x378=self.batchnorm2d106(x377)
        print('x378: {}'.format(x378.shape))
        x379=self.relu106(x378)
        print('x379: {}'.format(x379.shape))
        x380=self.conv2d106(x379)
        print('x380: {}'.format(x380.shape))
        x381=self.batchnorm2d107(x380)
        print('x381: {}'.format(x381.shape))
        x382=self.relu107(x381)
        print('x382: {}'.format(x382.shape))
        x383=self.conv2d107(x382)
        print('x383: {}'.format(x383.shape))
        x384=torch.cat([x369, x376, x383], 1)
        print('x384: {}'.format(x384.shape))
        x385=self.batchnorm2d108(x384)
        print('x385: {}'.format(x385.shape))
        x386=self.relu108(x385)
        print('x386: {}'.format(x386.shape))
        x387=self.conv2d108(x386)
        print('x387: {}'.format(x387.shape))
        x388=self.batchnorm2d109(x387)
        print('x388: {}'.format(x388.shape))
        x389=self.relu109(x388)
        print('x389: {}'.format(x389.shape))
        x390=self.conv2d109(x389)
        print('x390: {}'.format(x390.shape))
        x391=torch.cat([x369, x376, x383, x390], 1)
        print('x391: {}'.format(x391.shape))
        x392=self.batchnorm2d110(x391)
        print('x392: {}'.format(x392.shape))
        x393=self.relu110(x392)
        print('x393: {}'.format(x393.shape))
        x394=self.conv2d110(x393)
        print('x394: {}'.format(x394.shape))
        x395=self.batchnorm2d111(x394)
        print('x395: {}'.format(x395.shape))
        x396=self.relu111(x395)
        print('x396: {}'.format(x396.shape))
        x397=self.conv2d111(x396)
        print('x397: {}'.format(x397.shape))
        x398=torch.cat([x369, x376, x383, x390, x397], 1)
        print('x398: {}'.format(x398.shape))
        x399=self.batchnorm2d112(x398)
        print('x399: {}'.format(x399.shape))
        x400=self.relu112(x399)
        print('x400: {}'.format(x400.shape))
        x401=self.conv2d112(x400)
        print('x401: {}'.format(x401.shape))
        x402=self.batchnorm2d113(x401)
        print('x402: {}'.format(x402.shape))
        x403=self.relu113(x402)
        print('x403: {}'.format(x403.shape))
        x404=self.conv2d113(x403)
        print('x404: {}'.format(x404.shape))
        x405=torch.cat([x369, x376, x383, x390, x397, x404], 1)
        print('x405: {}'.format(x405.shape))
        x406=self.batchnorm2d114(x405)
        print('x406: {}'.format(x406.shape))
        x407=self.relu114(x406)
        print('x407: {}'.format(x407.shape))
        x408=self.conv2d114(x407)
        print('x408: {}'.format(x408.shape))
        x409=self.batchnorm2d115(x408)
        print('x409: {}'.format(x409.shape))
        x410=self.relu115(x409)
        print('x410: {}'.format(x410.shape))
        x411=self.conv2d115(x410)
        print('x411: {}'.format(x411.shape))
        x412=torch.cat([x369, x376, x383, x390, x397, x404, x411], 1)
        print('x412: {}'.format(x412.shape))
        x413=self.batchnorm2d116(x412)
        print('x413: {}'.format(x413.shape))
        x414=self.relu116(x413)
        print('x414: {}'.format(x414.shape))
        x415=self.conv2d116(x414)
        print('x415: {}'.format(x415.shape))
        x416=self.batchnorm2d117(x415)
        print('x416: {}'.format(x416.shape))
        x417=self.relu117(x416)
        print('x417: {}'.format(x417.shape))
        x418=self.conv2d117(x417)
        print('x418: {}'.format(x418.shape))
        x419=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418], 1)
        print('x419: {}'.format(x419.shape))
        x420=self.batchnorm2d118(x419)
        print('x420: {}'.format(x420.shape))
        x421=self.relu118(x420)
        print('x421: {}'.format(x421.shape))
        x422=self.conv2d118(x421)
        print('x422: {}'.format(x422.shape))
        x423=self.batchnorm2d119(x422)
        print('x423: {}'.format(x423.shape))
        x424=self.relu119(x423)
        print('x424: {}'.format(x424.shape))
        x425=self.conv2d119(x424)
        print('x425: {}'.format(x425.shape))
        x426=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425], 1)
        print('x426: {}'.format(x426.shape))
        x427=self.batchnorm2d120(x426)
        print('x427: {}'.format(x427.shape))
        x428=self.relu120(x427)
        print('x428: {}'.format(x428.shape))
        x429=self.conv2d120(x428)
        print('x429: {}'.format(x429.shape))
        x430=self.batchnorm2d121(x429)
        print('x430: {}'.format(x430.shape))
        x431=self.relu121(x430)
        print('x431: {}'.format(x431.shape))
        x432=self.conv2d121(x431)
        print('x432: {}'.format(x432.shape))
        x433=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432], 1)
        print('x433: {}'.format(x433.shape))
        x434=self.batchnorm2d122(x433)
        print('x434: {}'.format(x434.shape))
        x435=self.relu122(x434)
        print('x435: {}'.format(x435.shape))
        x436=self.conv2d122(x435)
        print('x436: {}'.format(x436.shape))
        x437=self.batchnorm2d123(x436)
        print('x437: {}'.format(x437.shape))
        x438=self.relu123(x437)
        print('x438: {}'.format(x438.shape))
        x439=self.conv2d123(x438)
        print('x439: {}'.format(x439.shape))
        x440=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439], 1)
        print('x440: {}'.format(x440.shape))
        x441=self.batchnorm2d124(x440)
        print('x441: {}'.format(x441.shape))
        x442=self.relu124(x441)
        print('x442: {}'.format(x442.shape))
        x443=self.conv2d124(x442)
        print('x443: {}'.format(x443.shape))
        x444=self.batchnorm2d125(x443)
        print('x444: {}'.format(x444.shape))
        x445=self.relu125(x444)
        print('x445: {}'.format(x445.shape))
        x446=self.conv2d125(x445)
        print('x446: {}'.format(x446.shape))
        x447=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446], 1)
        print('x447: {}'.format(x447.shape))
        x448=self.batchnorm2d126(x447)
        print('x448: {}'.format(x448.shape))
        x449=self.relu126(x448)
        print('x449: {}'.format(x449.shape))
        x450=self.conv2d126(x449)
        print('x450: {}'.format(x450.shape))
        x451=self.batchnorm2d127(x450)
        print('x451: {}'.format(x451.shape))
        x452=self.relu127(x451)
        print('x452: {}'.format(x452.shape))
        x453=self.conv2d127(x452)
        print('x453: {}'.format(x453.shape))
        x454=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453], 1)
        print('x454: {}'.format(x454.shape))
        x455=self.batchnorm2d128(x454)
        print('x455: {}'.format(x455.shape))
        x456=self.relu128(x455)
        print('x456: {}'.format(x456.shape))
        x457=self.conv2d128(x456)
        print('x457: {}'.format(x457.shape))
        x458=self.batchnorm2d129(x457)
        print('x458: {}'.format(x458.shape))
        x459=self.relu129(x458)
        print('x459: {}'.format(x459.shape))
        x460=self.conv2d129(x459)
        print('x460: {}'.format(x460.shape))
        x461=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460], 1)
        print('x461: {}'.format(x461.shape))
        x462=self.batchnorm2d130(x461)
        print('x462: {}'.format(x462.shape))
        x463=self.relu130(x462)
        print('x463: {}'.format(x463.shape))
        x464=self.conv2d130(x463)
        print('x464: {}'.format(x464.shape))
        x465=self.batchnorm2d131(x464)
        print('x465: {}'.format(x465.shape))
        x466=self.relu131(x465)
        print('x466: {}'.format(x466.shape))
        x467=self.conv2d131(x466)
        print('x467: {}'.format(x467.shape))
        x468=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467], 1)
        print('x468: {}'.format(x468.shape))
        x469=self.batchnorm2d132(x468)
        print('x469: {}'.format(x469.shape))
        x470=self.relu132(x469)
        print('x470: {}'.format(x470.shape))
        x471=self.conv2d132(x470)
        print('x471: {}'.format(x471.shape))
        x472=self.batchnorm2d133(x471)
        print('x472: {}'.format(x472.shape))
        x473=self.relu133(x472)
        print('x473: {}'.format(x473.shape))
        x474=self.conv2d133(x473)
        print('x474: {}'.format(x474.shape))
        x475=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474], 1)
        print('x475: {}'.format(x475.shape))
        x476=self.batchnorm2d134(x475)
        print('x476: {}'.format(x476.shape))
        x477=self.relu134(x476)
        print('x477: {}'.format(x477.shape))
        x478=self.conv2d134(x477)
        print('x478: {}'.format(x478.shape))
        x479=self.batchnorm2d135(x478)
        print('x479: {}'.format(x479.shape))
        x480=self.relu135(x479)
        print('x480: {}'.format(x480.shape))
        x481=self.conv2d135(x480)
        print('x481: {}'.format(x481.shape))
        x482=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481], 1)
        print('x482: {}'.format(x482.shape))
        x483=self.batchnorm2d136(x482)
        print('x483: {}'.format(x483.shape))
        x484=self.relu136(x483)
        print('x484: {}'.format(x484.shape))
        x485=self.conv2d136(x484)
        print('x485: {}'.format(x485.shape))
        x486=self.batchnorm2d137(x485)
        print('x486: {}'.format(x486.shape))
        x487=self.relu137(x486)
        print('x487: {}'.format(x487.shape))
        x488=self.conv2d137(x487)
        print('x488: {}'.format(x488.shape))
        x489=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488], 1)
        print('x489: {}'.format(x489.shape))
        x490=self.batchnorm2d138(x489)
        print('x490: {}'.format(x490.shape))
        x491=self.relu138(x490)
        print('x491: {}'.format(x491.shape))
        x492=self.conv2d138(x491)
        print('x492: {}'.format(x492.shape))
        x493=self.batchnorm2d139(x492)
        print('x493: {}'.format(x493.shape))
        x494=self.relu139(x493)
        print('x494: {}'.format(x494.shape))
        x495=self.conv2d139(x494)
        print('x495: {}'.format(x495.shape))
        x496=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495], 1)
        print('x496: {}'.format(x496.shape))
        x497=self.batchnorm2d140(x496)
        print('x497: {}'.format(x497.shape))
        x498=self.relu140(x497)
        print('x498: {}'.format(x498.shape))
        x499=self.conv2d140(x498)
        print('x499: {}'.format(x499.shape))
        x500=self.batchnorm2d141(x499)
        print('x500: {}'.format(x500.shape))
        x501=self.relu141(x500)
        print('x501: {}'.format(x501.shape))
        x502=self.conv2d141(x501)
        print('x502: {}'.format(x502.shape))
        x503=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502], 1)
        print('x503: {}'.format(x503.shape))
        x504=self.batchnorm2d142(x503)
        print('x504: {}'.format(x504.shape))
        x505=self.relu142(x504)
        print('x505: {}'.format(x505.shape))
        x506=self.conv2d142(x505)
        print('x506: {}'.format(x506.shape))
        x507=self.batchnorm2d143(x506)
        print('x507: {}'.format(x507.shape))
        x508=self.relu143(x507)
        print('x508: {}'.format(x508.shape))
        x509=self.conv2d143(x508)
        print('x509: {}'.format(x509.shape))
        x510=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509], 1)
        print('x510: {}'.format(x510.shape))
        x511=self.batchnorm2d144(x510)
        print('x511: {}'.format(x511.shape))
        x512=self.relu144(x511)
        print('x512: {}'.format(x512.shape))
        x513=self.conv2d144(x512)
        print('x513: {}'.format(x513.shape))
        x514=self.batchnorm2d145(x513)
        print('x514: {}'.format(x514.shape))
        x515=self.relu145(x514)
        print('x515: {}'.format(x515.shape))
        x516=self.conv2d145(x515)
        print('x516: {}'.format(x516.shape))
        x517=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516], 1)
        print('x517: {}'.format(x517.shape))
        x518=self.batchnorm2d146(x517)
        print('x518: {}'.format(x518.shape))
        x519=self.relu146(x518)
        print('x519: {}'.format(x519.shape))
        x520=self.conv2d146(x519)
        print('x520: {}'.format(x520.shape))
        x521=self.batchnorm2d147(x520)
        print('x521: {}'.format(x521.shape))
        x522=self.relu147(x521)
        print('x522: {}'.format(x522.shape))
        x523=self.conv2d147(x522)
        print('x523: {}'.format(x523.shape))
        x524=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523], 1)
        print('x524: {}'.format(x524.shape))
        x525=self.batchnorm2d148(x524)
        print('x525: {}'.format(x525.shape))
        x526=self.relu148(x525)
        print('x526: {}'.format(x526.shape))
        x527=self.conv2d148(x526)
        print('x527: {}'.format(x527.shape))
        x528=self.batchnorm2d149(x527)
        print('x528: {}'.format(x528.shape))
        x529=self.relu149(x528)
        print('x529: {}'.format(x529.shape))
        x530=self.conv2d149(x529)
        print('x530: {}'.format(x530.shape))
        x531=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530], 1)
        print('x531: {}'.format(x531.shape))
        x532=self.batchnorm2d150(x531)
        print('x532: {}'.format(x532.shape))
        x533=self.relu150(x532)
        print('x533: {}'.format(x533.shape))
        x534=self.conv2d150(x533)
        print('x534: {}'.format(x534.shape))
        x535=self.batchnorm2d151(x534)
        print('x535: {}'.format(x535.shape))
        x536=self.relu151(x535)
        print('x536: {}'.format(x536.shape))
        x537=self.conv2d151(x536)
        print('x537: {}'.format(x537.shape))
        x538=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530, x537], 1)
        print('x538: {}'.format(x538.shape))
        x539=self.batchnorm2d152(x538)
        print('x539: {}'.format(x539.shape))
        x540=self.relu152(x539)
        print('x540: {}'.format(x540.shape))
        x541=self.conv2d152(x540)
        print('x541: {}'.format(x541.shape))
        x542=self.batchnorm2d153(x541)
        print('x542: {}'.format(x542.shape))
        x543=self.relu153(x542)
        print('x543: {}'.format(x543.shape))
        x544=self.conv2d153(x543)
        print('x544: {}'.format(x544.shape))
        x545=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530, x537, x544], 1)
        print('x545: {}'.format(x545.shape))
        x546=self.batchnorm2d154(x545)
        print('x546: {}'.format(x546.shape))
        x547=self.relu154(x546)
        print('x547: {}'.format(x547.shape))
        x548=self.conv2d154(x547)
        print('x548: {}'.format(x548.shape))
        x549=self.batchnorm2d155(x548)
        print('x549: {}'.format(x549.shape))
        x550=self.relu155(x549)
        print('x550: {}'.format(x550.shape))
        x551=self.conv2d155(x550)
        print('x551: {}'.format(x551.shape))
        x552=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530, x537, x544, x551], 1)
        print('x552: {}'.format(x552.shape))
        x553=self.batchnorm2d156(x552)
        print('x553: {}'.format(x553.shape))
        x554=self.relu156(x553)
        print('x554: {}'.format(x554.shape))
        x555=self.conv2d156(x554)
        print('x555: {}'.format(x555.shape))
        x556=self.batchnorm2d157(x555)
        print('x556: {}'.format(x556.shape))
        x557=self.relu157(x556)
        print('x557: {}'.format(x557.shape))
        x558=self.conv2d157(x557)
        print('x558: {}'.format(x558.shape))
        x559=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530, x537, x544, x551, x558], 1)
        print('x559: {}'.format(x559.shape))
        x560=self.batchnorm2d158(x559)
        print('x560: {}'.format(x560.shape))
        x561=self.relu158(x560)
        print('x561: {}'.format(x561.shape))
        x562=self.conv2d158(x561)
        print('x562: {}'.format(x562.shape))
        x563=self.batchnorm2d159(x562)
        print('x563: {}'.format(x563.shape))
        x564=self.relu159(x563)
        print('x564: {}'.format(x564.shape))
        x565=self.conv2d159(x564)
        print('x565: {}'.format(x565.shape))
        x566=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530, x537, x544, x551, x558, x565], 1)
        print('x566: {}'.format(x566.shape))
        x567=self.batchnorm2d160(x566)
        print('x567: {}'.format(x567.shape))
        x568=self.relu160(x567)
        print('x568: {}'.format(x568.shape))
        x569=self.conv2d160(x568)
        print('x569: {}'.format(x569.shape))
        x570=self.batchnorm2d161(x569)
        print('x570: {}'.format(x570.shape))
        x571=self.relu161(x570)
        print('x571: {}'.format(x571.shape))
        x572=self.conv2d161(x571)
        print('x572: {}'.format(x572.shape))
        x573=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530, x537, x544, x551, x558, x565, x572], 1)
        print('x573: {}'.format(x573.shape))
        x574=self.batchnorm2d162(x573)
        print('x574: {}'.format(x574.shape))
        x575=self.relu162(x574)
        print('x575: {}'.format(x575.shape))
        x576=self.conv2d162(x575)
        print('x576: {}'.format(x576.shape))
        x577=self.batchnorm2d163(x576)
        print('x577: {}'.format(x577.shape))
        x578=self.relu163(x577)
        print('x578: {}'.format(x578.shape))
        x579=self.conv2d163(x578)
        print('x579: {}'.format(x579.shape))
        x580=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530, x537, x544, x551, x558, x565, x572, x579], 1)
        print('x580: {}'.format(x580.shape))
        x581=self.batchnorm2d164(x580)
        print('x581: {}'.format(x581.shape))
        x582=self.relu164(x581)
        print('x582: {}'.format(x582.shape))
        x583=self.conv2d164(x582)
        print('x583: {}'.format(x583.shape))
        x584=self.batchnorm2d165(x583)
        print('x584: {}'.format(x584.shape))
        x585=self.relu165(x584)
        print('x585: {}'.format(x585.shape))
        x586=self.conv2d165(x585)
        print('x586: {}'.format(x586.shape))
        x587=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530, x537, x544, x551, x558, x565, x572, x579, x586], 1)
        print('x587: {}'.format(x587.shape))
        x588=self.batchnorm2d166(x587)
        print('x588: {}'.format(x588.shape))
        x589=self.relu166(x588)
        print('x589: {}'.format(x589.shape))
        x590=self.conv2d166(x589)
        print('x590: {}'.format(x590.shape))
        x591=self.batchnorm2d167(x590)
        print('x591: {}'.format(x591.shape))
        x592=self.relu167(x591)
        print('x592: {}'.format(x592.shape))
        x593=self.conv2d167(x592)
        print('x593: {}'.format(x593.shape))
        x594=torch.cat([x369, x376, x383, x390, x397, x404, x411, x418, x425, x432, x439, x446, x453, x460, x467, x474, x481, x488, x495, x502, x509, x516, x523, x530, x537, x544, x551, x558, x565, x572, x579, x586, x593], 1)
        print('x594: {}'.format(x594.shape))
        x595=self.batchnorm2d168(x594)
        print('x595: {}'.format(x595.shape))
        x596=torch.nn.functional.relu(x595,inplace=True)
        print('x596: {}'.format(x596.shape))
        x597=torch.nn.functional.adaptive_avg_pool2d(x596, (1, 1))
        print('x597: {}'.format(x597.shape))
        x598=torch.flatten(x597, 1)
        print('x598: {}'.format(x598.shape))
        x599=self.linear0(x598)
        print('x599: {}'.format(x599.shape))

m = M().eval()
x = torch.randn(1, 3, 224, 224)
output = m(x)
