import torch
from torch import tensor
import torch.nn as nn
from torch.nn import *
import torchvision
import torchvision.models as models
from torchvision.ops.stochastic_depth import stochastic_depth
import time
import builtins
import operator
import sys
import os

class M(torch.nn.Module):
    def __init__(self):
        super(M, self).__init__()
        self.conv2d0 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu0 = ReLU(inplace=True)
        self.conv2d1 = Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu1 = ReLU(inplace=True)
        self.maxpool2d0 = MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        self.conv2d2 = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu2 = ReLU(inplace=True)
        self.conv2d3 = Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu3 = ReLU(inplace=True)
        self.maxpool2d1 = MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        self.conv2d4 = Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu4 = ReLU(inplace=True)
        self.conv2d5 = Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu5 = ReLU(inplace=True)
        self.conv2d6 = Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu6 = ReLU(inplace=True)
        self.conv2d7 = Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu7 = ReLU(inplace=True)
        self.maxpool2d2 = MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        self.conv2d8 = Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu8 = ReLU(inplace=True)
        self.conv2d9 = Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu9 = ReLU(inplace=True)
        self.conv2d10 = Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu10 = ReLU(inplace=True)
        self.conv2d11 = Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu11 = ReLU(inplace=True)
        self.maxpool2d3 = MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        self.conv2d12 = Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu12 = ReLU(inplace=True)
        self.conv2d13 = Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu13 = ReLU(inplace=True)
        self.conv2d14 = Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu14 = ReLU(inplace=True)
        self.conv2d15 = Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        self.relu15 = ReLU(inplace=True)
        self.maxpool2d4 = MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        self.adaptiveavgpool2d0 = AdaptiveAvgPool2d(output_size=(7, 7))
        self.linear0 = Linear(in_features=25088, out_features=4096, bias=True)
        self.relu16 = ReLU(inplace=True)
        self.dropout0 = Dropout(p=0.5, inplace=False)
        self.linear1 = Linear(in_features=4096, out_features=4096, bias=True)
        self.relu17 = ReLU(inplace=True)
        self.dropout1 = Dropout(p=0.5, inplace=False)
        self.linear2 = Linear(in_features=4096, out_features=1000, bias=True)

    def forward(self, x):
        x0=x
        print('x0: {}'.format(x0.shape))
        x1=self.conv2d0(x0)
        print('x1: {}'.format(x1.shape))
        x2=self.relu0(x1)
        print('x2: {}'.format(x2.shape))
        x3=self.conv2d1(x2)
        print('x3: {}'.format(x3.shape))
        x4=self.relu1(x3)
        print('x4: {}'.format(x4.shape))
        x5=self.maxpool2d0(x4)
        print('x5: {}'.format(x5.shape))
        x6=self.conv2d2(x5)
        print('x6: {}'.format(x6.shape))
        x7=self.relu2(x6)
        print('x7: {}'.format(x7.shape))
        x8=self.conv2d3(x7)
        print('x8: {}'.format(x8.shape))
        x9=self.relu3(x8)
        print('x9: {}'.format(x9.shape))
        x10=self.maxpool2d1(x9)
        print('x10: {}'.format(x10.shape))
        x11=self.conv2d4(x10)
        print('x11: {}'.format(x11.shape))
        x12=self.relu4(x11)
        print('x12: {}'.format(x12.shape))
        x13=self.conv2d5(x12)
        print('x13: {}'.format(x13.shape))
        x14=self.relu5(x13)
        print('x14: {}'.format(x14.shape))
        x15=self.conv2d6(x14)
        print('x15: {}'.format(x15.shape))
        x16=self.relu6(x15)
        print('x16: {}'.format(x16.shape))
        x17=self.conv2d7(x16)
        print('x17: {}'.format(x17.shape))
        x18=self.relu7(x17)
        print('x18: {}'.format(x18.shape))
        x19=self.maxpool2d2(x18)
        print('x19: {}'.format(x19.shape))
        x20=self.conv2d8(x19)
        print('x20: {}'.format(x20.shape))
        x21=self.relu8(x20)
        print('x21: {}'.format(x21.shape))
        x22=self.conv2d9(x21)
        print('x22: {}'.format(x22.shape))
        x23=self.relu9(x22)
        print('x23: {}'.format(x23.shape))
        x24=self.conv2d10(x23)
        print('x24: {}'.format(x24.shape))
        x25=self.relu10(x24)
        print('x25: {}'.format(x25.shape))
        x26=self.conv2d11(x25)
        print('x26: {}'.format(x26.shape))
        x27=self.relu11(x26)
        print('x27: {}'.format(x27.shape))
        x28=self.maxpool2d3(x27)
        print('x28: {}'.format(x28.shape))
        x29=self.conv2d12(x28)
        print('x29: {}'.format(x29.shape))
        x30=self.relu12(x29)
        print('x30: {}'.format(x30.shape))
        x31=self.conv2d13(x30)
        print('x31: {}'.format(x31.shape))
        x32=self.relu13(x31)
        print('x32: {}'.format(x32.shape))
        x33=self.conv2d14(x32)
        print('x33: {}'.format(x33.shape))
        x34=self.relu14(x33)
        print('x34: {}'.format(x34.shape))
        x35=self.conv2d15(x34)
        print('x35: {}'.format(x35.shape))
        x36=self.relu15(x35)
        print('x36: {}'.format(x36.shape))
        x37=self.maxpool2d4(x36)
        print('x37: {}'.format(x37.shape))
        x38=self.adaptiveavgpool2d0(x37)
        print('x38: {}'.format(x38.shape))
        x39=torch.flatten(x38, 1)
        print('x39: {}'.format(x39.shape))
        x40=self.linear0(x39)
        print('x40: {}'.format(x40.shape))
        x41=self.relu16(x40)
        print('x41: {}'.format(x41.shape))
        x42=self.dropout0(x41)
        print('x42: {}'.format(x42.shape))
        x43=self.linear1(x42)
        print('x43: {}'.format(x43.shape))
        x44=self.relu17(x43)
        print('x44: {}'.format(x44.shape))
        x45=self.dropout1(x44)
        print('x45: {}'.format(x45.shape))
        x46=self.linear2(x45)
        print('x46: {}'.format(x46.shape))

m = M().eval()
CORES=os.popen("lscpu | grep Core | awk '{print $4}'").readlines()
SOCKETS=os.popen("lscpu | grep Socket | awk '{print $2}'").readlines()
BS=int(CORES[0])*int(SOCKETS[0])
batch_size=BS
x = torch.randn(batch_size, 3, 224, 224)
start_time=time.time()
for i in range(10):
    output = m(x)
total_iter_time = time.time() - start_time
Throughput = batch_size * 10 / total_iter_time
file_current = os.path.basename(__file__)
print(file_current,',',BS,',',Throughput) 
